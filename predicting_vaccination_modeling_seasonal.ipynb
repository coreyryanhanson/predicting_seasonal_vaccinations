{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Vaccination: Modeling H1N1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by Corey Hanson & Frank Flavell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/pred_vacc_model_h1n1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U.S. Department of Health & Human Services alomg with the National Center for Health Statistics launched a national telephone survey to gather data from a sample of the U.S. population in order to make predictions about H1N1 and Seasonal Flu vaccinations.\n",
    "\n",
    "**Target:**\n",
    "  * H1N1 Vaccination: Did the survey respondant receive the vaccine or not?\n",
    "  * Seasonal Flue Vaccination: Did the survey respondant receive the vaccine or not?\n",
    "\n",
    "We have been tasked with developing a classification model to make the predictions based on the survey results.  The specific end goal has not yet been determined, as this information may have many different uses in policy making, business, and non-profit health work.  Therefore, we are keeping an open mind when modeling to determine a few different possible models that would be appropriate in different contexts.\n",
    "\n",
    "The survey data can be found at this link: [National 2009 H1N1 Survey](https://www.drivendata.org/competitions/66/flu-shot-learning/page/210/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents<span id=\"0\"></span>\n",
    "\n",
    "1. [**Train/ Test Split, Class Imbalance & Standardization**](#1)\n",
    "    * User Defined Function for splitting, standardizing and correcting class imbalance\n",
    "    * Train/test set relabeling\n",
    "2. [**Logisitic Regression**](#2)\n",
    "    * Baseline\n",
    "    * Optimized Models\n",
    "3. [**K-Nearest Neighbor**](#3)\n",
    "    * Baseline\n",
    "    * Determine Best K\n",
    "    * Optimized Model\n",
    "4. [**Decision Tree**](#4)\n",
    "    * Baseline\n",
    "    * Determine Best Depth\n",
    "    * Optimized Model\n",
    "5. [**Random Forest**](#5)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Model\n",
    "6. [**AdaBoost**](#6)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Model\n",
    "7. [**XGBoost**](#7)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Models\n",
    "8. [**Support Vector Machine**](#8)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Models\n",
    "9. [**Best Model**](#9)\n",
    "    * Analysis\n",
    "    * Recommendations\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "\n",
    "from cleaning_functions import *\n",
    "from eda import *\n",
    "\n",
    "from random_lumberjacks.src.random_lumberjacks.model.model_classes import *\n",
    "from random_lumberjacks.src.random_lumberjacks.visualization.visualization_functions import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>homeowner</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>missing_doctor_recc</th>\n",
       "      <th>missing_health_insurance</th>\n",
       "      <th>missing_homeowner</th>\n",
       "      <th>missing_household</th>\n",
       "      <th>missing_opinion</th>\n",
       "      <th>missing_demographics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55_to_64 Years</td>\n",
       "      <td>&lt; 12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35_to_44 Years</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18_to_34 Years</td>\n",
       "      <td>College Graduate</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Over_65</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45_to_54 Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "respondent_id                                                            \n",
       "0                       1.0             0.0                        0.0   \n",
       "1                       3.0             2.0                        0.0   \n",
       "2                       1.0             1.0                        0.0   \n",
       "3                       1.0             1.0                        0.0   \n",
       "4                       2.0             1.0                        0.0   \n",
       "\n",
       "               behavioral_avoidance  behavioral_face_mask  \\\n",
       "respondent_id                                               \n",
       "0                               0.0                   0.0   \n",
       "1                               1.0                   0.0   \n",
       "2                               1.0                   0.0   \n",
       "3                               1.0                   0.0   \n",
       "4                               1.0                   0.0   \n",
       "\n",
       "               behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "respondent_id                                                       \n",
       "0                                0.0                          0.0   \n",
       "1                                1.0                          0.0   \n",
       "2                                0.0                          0.0   \n",
       "3                                1.0                          1.0   \n",
       "4                                1.0                          1.0   \n",
       "\n",
       "               behavioral_outside_home  behavioral_touch_face  \\\n",
       "respondent_id                                                   \n",
       "0                                  1.0                    1.0   \n",
       "1                                  1.0                    1.0   \n",
       "2                                  0.0                    0.0   \n",
       "3                                  0.0                    0.0   \n",
       "4                                  0.0                    1.0   \n",
       "\n",
       "               doctor_recc_h1n1  doctor_recc_seasonal  chronic_med_condition  \\\n",
       "respondent_id                                                                  \n",
       "0                           0.0                   0.0                    0.0   \n",
       "1                           0.0                   0.0                    0.0   \n",
       "2                           0.0                   0.0                    1.0   \n",
       "3                           0.0                   1.0                    1.0   \n",
       "4                           0.0                   0.0                    0.0   \n",
       "\n",
       "               child_under_6_months  health_worker  health_insurance  \\\n",
       "respondent_id                                                          \n",
       "0                               0.0            0.0               1.0   \n",
       "1                               0.0            0.0               1.0   \n",
       "2                               0.0            0.0               1.0   \n",
       "3                               0.0            0.0               1.0   \n",
       "4                               0.0            0.0               1.0   \n",
       "\n",
       "               opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
       "respondent_id                                                   \n",
       "0                                      3.0                1.0   \n",
       "1                                      5.0                4.0   \n",
       "2                                      3.0                1.0   \n",
       "3                                      3.0                3.0   \n",
       "4                                      3.0                3.0   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "respondent_id                                                             \n",
       "0                                      2.0                          2.0   \n",
       "1                                      4.0                          4.0   \n",
       "2                                      1.0                          4.0   \n",
       "3                                      5.0                          5.0   \n",
       "4                                      2.0                          3.0   \n",
       "\n",
       "               opinion_seas_risk  opinion_seas_sick_from_vacc       age_group  \\\n",
       "respondent_id                                                                   \n",
       "0                            1.0                          2.0  55_to_64 Years   \n",
       "1                            2.0                          4.0  35_to_44 Years   \n",
       "2                            1.0                          2.0  18_to_34 Years   \n",
       "3                            4.0                          1.0         Over_65   \n",
       "4                            1.0                          4.0  45_to_54 Years   \n",
       "\n",
       "                      education   race     sex income_poverty marital_status  \\\n",
       "respondent_id                                                                  \n",
       "0                    < 12 Years  White  Female  Below Poverty    Not Married   \n",
       "1                      12 Years  White    Male  Below Poverty    Not Married   \n",
       "2              College Graduate  White    Male  Above Poverty    Not Married   \n",
       "3                      12 Years  White  Female  Below Poverty    Not Married   \n",
       "4                  Some College  White  Female  Above Poverty        Married   \n",
       "\n",
       "               homeowner   employment_status hhs_geo_region  \\\n",
       "respondent_id                                                 \n",
       "0                    1.0  Not in Labor Force       oxchjgsf   \n",
       "1                    0.0            Employed       bhuqouqj   \n",
       "2                    1.0            Employed       qufhixun   \n",
       "3                    0.0  Not in Labor Force       lrircsnp   \n",
       "4                    1.0            Employed       qufhixun   \n",
       "\n",
       "                             census_msa  household_adults  household_children  \\\n",
       "respondent_id                                                                   \n",
       "0                               Non-MSA               0.0                 0.0   \n",
       "1              MSA, Not Principle  City               0.0                 0.0   \n",
       "2              MSA, Not Principle  City               2.0                 0.0   \n",
       "3                   MSA, Principle City               0.0                 0.0   \n",
       "4              MSA, Not Principle  City               1.0                 0.0   \n",
       "\n",
       "              employment_industry employment_occupation  h1n1_vaccine  \\\n",
       "respondent_id                                                           \n",
       "0                         unknown               unknown             0   \n",
       "1                        pxcmvdjn              xgwztkwe             0   \n",
       "2                        rucpziij              xtkaffoo             0   \n",
       "3                         unknown               unknown             0   \n",
       "4                        wxleyezf              emcorrxb             0   \n",
       "\n",
       "               seasonal_vaccine  missing_doctor_recc  \\\n",
       "respondent_id                                          \n",
       "0                             0                    0   \n",
       "1                             1                    0   \n",
       "2                             0                    1   \n",
       "3                             1                    0   \n",
       "4                             0                    0   \n",
       "\n",
       "               missing_health_insurance  missing_homeowner  missing_household  \\\n",
       "respondent_id                                                                   \n",
       "0                                     0                  0                  0   \n",
       "1                                     0                  0                  0   \n",
       "2                                     1                  0                  0   \n",
       "3                                     1                  0                  0   \n",
       "4                                     1                  0                  0   \n",
       "\n",
       "               missing_opinion  missing_demographics  \n",
       "respondent_id                                         \n",
       "0                            0                     0  \n",
       "1                            0                     0  \n",
       "2                            0                     0  \n",
       "3                            0                     0  \n",
       "4                            0                     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 43 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26707 non-null  float64\n",
      " 1   h1n1_knowledge               26707 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26707 non-null  float64\n",
      " 3   behavioral_avoidance         26707 non-null  float64\n",
      " 4   behavioral_face_mask         26707 non-null  float64\n",
      " 5   behavioral_wash_hands        26707 non-null  float64\n",
      " 6   behavioral_large_gatherings  26707 non-null  float64\n",
      " 7   behavioral_outside_home      26707 non-null  float64\n",
      " 8   behavioral_touch_face        26707 non-null  float64\n",
      " 9   doctor_recc_h1n1             26707 non-null  float64\n",
      " 10  doctor_recc_seasonal         26707 non-null  float64\n",
      " 11  chronic_med_condition        26707 non-null  float64\n",
      " 12  child_under_6_months         26707 non-null  float64\n",
      " 13  health_worker                26707 non-null  float64\n",
      " 14  health_insurance             26707 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26707 non-null  float64\n",
      " 16  opinion_h1n1_risk            26707 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26707 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26707 non-null  float64\n",
      " 19  opinion_seas_risk            26707 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26707 non-null  float64\n",
      " 21  age_group                    26707 non-null  object \n",
      " 22  education                    26707 non-null  object \n",
      " 23  race                         26707 non-null  object \n",
      " 24  sex                          26707 non-null  object \n",
      " 25  income_poverty               26707 non-null  object \n",
      " 26  marital_status               26707 non-null  object \n",
      " 27  homeowner                    26707 non-null  float64\n",
      " 28  employment_status            26707 non-null  object \n",
      " 29  hhs_geo_region               26707 non-null  object \n",
      " 30  census_msa                   26707 non-null  object \n",
      " 31  household_adults             26707 non-null  float64\n",
      " 32  household_children           26707 non-null  float64\n",
      " 33  employment_industry          26707 non-null  object \n",
      " 34  employment_occupation        26707 non-null  object \n",
      " 35  h1n1_vaccine                 26707 non-null  int64  \n",
      " 36  seasonal_vaccine             26707 non-null  int64  \n",
      " 37  missing_doctor_recc          26707 non-null  int64  \n",
      " 38  missing_health_insurance     26707 non-null  int64  \n",
      " 39  missing_homeowner            26707 non-null  int64  \n",
      " 40  missing_household            26707 non-null  int64  \n",
      " 41  missing_opinion              26707 non-null  int64  \n",
      " 42  missing_demographics         26707 non-null  int64  \n",
      "dtypes: float64(24), int64(8), object(11)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>homeowner</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>missing_doctor_recc</th>\n",
       "      <th>missing_health_insurance</th>\n",
       "      <th>missing_homeowner</th>\n",
       "      <th>missing_household</th>\n",
       "      <th>missing_opinion</th>\n",
       "      <th>missing_demographics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.619800</td>\n",
       "      <td>1.261392</td>\n",
       "      <td>0.048714</td>\n",
       "      <td>0.727749</td>\n",
       "      <td>0.068933</td>\n",
       "      <td>0.825888</td>\n",
       "      <td>0.357472</td>\n",
       "      <td>0.336279</td>\n",
       "      <td>0.678811</td>\n",
       "      <td>0.202494</td>\n",
       "      <td>0.303067</td>\n",
       "      <td>0.272962</td>\n",
       "      <td>0.080054</td>\n",
       "      <td>0.108548</td>\n",
       "      <td>0.934998</td>\n",
       "      <td>3.852810</td>\n",
       "      <td>2.337589</td>\n",
       "      <td>2.352380</td>\n",
       "      <td>4.025536</td>\n",
       "      <td>2.705321</td>\n",
       "      <td>2.115737</td>\n",
       "      <td>0.777998</td>\n",
       "      <td>0.887558</td>\n",
       "      <td>0.529599</td>\n",
       "      <td>0.212454</td>\n",
       "      <td>0.465608</td>\n",
       "      <td>0.080878</td>\n",
       "      <td>0.459580</td>\n",
       "      <td>0.076459</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.026398</td>\n",
       "      <td>0.065114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.909016</td>\n",
       "      <td>0.617047</td>\n",
       "      <td>0.215273</td>\n",
       "      <td>0.445127</td>\n",
       "      <td>0.253345</td>\n",
       "      <td>0.379213</td>\n",
       "      <td>0.479264</td>\n",
       "      <td>0.472444</td>\n",
       "      <td>0.466942</td>\n",
       "      <td>0.401866</td>\n",
       "      <td>0.459592</td>\n",
       "      <td>0.445490</td>\n",
       "      <td>0.271382</td>\n",
       "      <td>0.311077</td>\n",
       "      <td>0.246533</td>\n",
       "      <td>1.000195</td>\n",
       "      <td>1.276825</td>\n",
       "      <td>1.353339</td>\n",
       "      <td>1.077131</td>\n",
       "      <td>1.375216</td>\n",
       "      <td>1.319585</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.749980</td>\n",
       "      <td>0.925264</td>\n",
       "      <td>0.409052</td>\n",
       "      <td>0.498825</td>\n",
       "      <td>0.272652</td>\n",
       "      <td>0.498373</td>\n",
       "      <td>0.265737</td>\n",
       "      <td>0.096108</td>\n",
       "      <td>0.160318</td>\n",
       "      <td>0.246732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "count  26707.000000    26707.000000               26707.000000   \n",
       "mean       1.619800        1.261392                   0.048714   \n",
       "std        0.909016        0.617047                   0.215273   \n",
       "min        0.000000        0.000000                   0.000000   \n",
       "25%        1.000000        1.000000                   0.000000   \n",
       "50%        2.000000        1.000000                   0.000000   \n",
       "75%        2.000000        2.000000                   0.000000   \n",
       "max        3.000000        2.000000                   1.000000   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "count          26707.000000          26707.000000           26707.000000   \n",
       "mean               0.727749              0.068933               0.825888   \n",
       "std                0.445127              0.253345               0.379213   \n",
       "min                0.000000              0.000000               0.000000   \n",
       "25%                0.000000              0.000000               1.000000   \n",
       "50%                1.000000              0.000000               1.000000   \n",
       "75%                1.000000              0.000000               1.000000   \n",
       "max                1.000000              1.000000               1.000000   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "count                 26707.000000             26707.000000   \n",
       "mean                      0.357472                 0.336279   \n",
       "std                       0.479264                 0.472444   \n",
       "min                       0.000000                 0.000000   \n",
       "25%                       0.000000                 0.000000   \n",
       "50%                       0.000000                 0.000000   \n",
       "75%                       1.000000                 1.000000   \n",
       "max                       1.000000                 1.000000   \n",
       "\n",
       "       behavioral_touch_face  doctor_recc_h1n1  doctor_recc_seasonal  \\\n",
       "count           26707.000000      26707.000000          26707.000000   \n",
       "mean                0.678811          0.202494              0.303067   \n",
       "std                 0.466942          0.401866              0.459592   \n",
       "min                 0.000000          0.000000              0.000000   \n",
       "25%                 0.000000          0.000000              0.000000   \n",
       "50%                 1.000000          0.000000              0.000000   \n",
       "75%                 1.000000          0.000000              1.000000   \n",
       "max                 1.000000          1.000000              1.000000   \n",
       "\n",
       "       chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "count           26707.000000          26707.000000   26707.000000   \n",
       "mean                0.272962              0.080054       0.108548   \n",
       "std                 0.445490              0.271382       0.311077   \n",
       "min                 0.000000              0.000000       0.000000   \n",
       "25%                 0.000000              0.000000       0.000000   \n",
       "50%                 0.000000              0.000000       0.000000   \n",
       "75%                 1.000000              0.000000       0.000000   \n",
       "max                 1.000000              1.000000       1.000000   \n",
       "\n",
       "       health_insurance  opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
       "count      26707.000000                 26707.000000       26707.000000   \n",
       "mean           0.934998                     3.852810           2.337589   \n",
       "std            0.246533                     1.000195           1.276825   \n",
       "min            0.000000                     1.000000           1.000000   \n",
       "25%            1.000000                     3.000000           1.000000   \n",
       "50%            1.000000                     4.000000           2.000000   \n",
       "75%            1.000000                     5.000000           4.000000   \n",
       "max            1.000000                     5.000000           5.000000   \n",
       "\n",
       "       opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "count                 26707.000000                 26707.000000   \n",
       "mean                      2.352380                     4.025536   \n",
       "std                       1.353339                     1.077131   \n",
       "min                       1.000000                     1.000000   \n",
       "25%                       1.000000                     4.000000   \n",
       "50%                       2.000000                     4.000000   \n",
       "75%                       4.000000                     5.000000   \n",
       "max                       5.000000                     5.000000   \n",
       "\n",
       "       opinion_seas_risk  opinion_seas_sick_from_vacc     homeowner  \\\n",
       "count       26707.000000                 26707.000000  26707.000000   \n",
       "mean            2.705321                     2.115737      0.777998   \n",
       "std             1.375216                     1.319585      0.415600   \n",
       "min             1.000000                     1.000000      0.000000   \n",
       "25%             2.000000                     1.000000      1.000000   \n",
       "50%             2.000000                     2.000000      1.000000   \n",
       "75%             4.000000                     2.000000      1.000000   \n",
       "max             5.000000                     5.000000      1.000000   \n",
       "\n",
       "       household_adults  household_children  h1n1_vaccine  seasonal_vaccine  \\\n",
       "count      26707.000000        26707.000000  26707.000000      26707.000000   \n",
       "mean           0.887558            0.529599      0.212454          0.465608   \n",
       "std            0.749980            0.925264      0.409052          0.498825   \n",
       "min            0.000000            0.000000      0.000000          0.000000   \n",
       "25%            0.000000            0.000000      0.000000          0.000000   \n",
       "50%            1.000000            0.000000      0.000000          0.000000   \n",
       "75%            1.000000            1.000000      0.000000          1.000000   \n",
       "max            3.000000            3.000000      1.000000          1.000000   \n",
       "\n",
       "       missing_doctor_recc  missing_health_insurance  missing_homeowner  \\\n",
       "count         26707.000000              26707.000000       26707.000000   \n",
       "mean              0.080878                  0.459580           0.076459   \n",
       "std               0.272652                  0.498373           0.265737   \n",
       "min               0.000000                  0.000000           0.000000   \n",
       "25%               0.000000                  0.000000           0.000000   \n",
       "50%               0.000000                  0.000000           0.000000   \n",
       "75%               0.000000                  1.000000           0.000000   \n",
       "max               1.000000                  1.000000           1.000000   \n",
       "\n",
       "       missing_household  missing_opinion  missing_demographics  \n",
       "count       26707.000000     26707.000000          26707.000000  \n",
       "mean            0.009323         0.026398              0.065114  \n",
       "std             0.096108         0.160318              0.246732  \n",
       "min             0.000000         0.000000              0.000000  \n",
       "25%             0.000000         0.000000              0.000000  \n",
       "50%             0.000000         0.000000              0.000000  \n",
       "75%             0.000000         0.000000              0.000000  \n",
       "max             1.000000         1.000000              1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"1\"></span>1. Train/ Test Split, Class Imbalance & Standardization\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the data for the H1N! the classes for the Seasonal Vaccine target variable were well balanced. We performed no resampling of the data in this case.\n",
    "\n",
    "The user-defined class below creates an object, 'data', that houses the original dataframe as well as any transformations we added including dummy variables, scaling, class imbalance correction and ploynomial features.  It also takes care of the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating column selection dictionaries for the data from lists of column names.\n",
    "\n",
    "#Lists to go in the dictionaries.\n",
    "binary_columns = ['behavioral_antiviral_meds',\n",
    "       'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands',\n",
    "       'behavioral_large_gatherings', 'behavioral_outside_home',\n",
    "       'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
    "       'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
    "       'health_insurance', 'homeowner']\n",
    "missing_dummies = extract_column_names(df, \"^missing\")\n",
    "target_col1 = \"h1n1_vaccine\"\n",
    "target_col2 = \"seasonal_vaccine\"\n",
    "target_cols = [target_col1, target_col2]\n",
    "untr = ['household_adults', 'household_children',]\n",
    "nom = df.columns.drop([*untr, *binary_columns, *target_cols, *missing_dummies])\n",
    "\n",
    "#The dicts that come into the arguments.\n",
    "categorical = {\n",
    "    \"nominal_features\":nom, \"standard_dummies\": binary_columns, \"impute_dummies\":missing_dummies\n",
    "}\n",
    "\n",
    "continuous = {\"untransformed\":untr}\n",
    "polynomial = {\"method\":\"choose\", \"columns\":['age_group', 'education', 'sex',\n",
    "                                            'doctor_recc_seasonal', 'income_poverty']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Skipping polynomial features\n",
      "Skipping class imbalance functions\n",
      "No scaling specified\n",
      "Skipping scaling\n",
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Skipping polynomial features\n",
      "Skipping class imbalance functions\n",
      "Using standard scaler\n",
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Skipping polynomial features\n",
      "Skipping class imbalance functions\n",
      "Using standard scaler\n",
      "Adding ['household_adults', 'household_children', 'behavioral_antiviral_meds', 'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands', 'behavioral_large_gatherings', 'behavioral_outside_home', 'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal', 'chronic_med_condition', 'child_under_6_months', 'health_worker', 'health_insurance', 'homeowner', 'missing_doctor_recc', 'missing_health_insurance', 'missing_homeowner', 'missing_household', 'missing_opinion', 'missing_demographics', 'h1n1_concern_1.0', 'h1n1_concern_2.0', 'h1n1_concern_3.0', 'h1n1_knowledge_1.0', 'h1n1_knowledge_2.0', 'opinion_h1n1_vacc_effective_2.0', 'opinion_h1n1_vacc_effective_3.0', 'opinion_h1n1_vacc_effective_4.0', 'opinion_h1n1_vacc_effective_5.0', 'opinion_h1n1_risk_2.0', 'opinion_h1n1_risk_3.0', 'opinion_h1n1_risk_4.0', 'opinion_h1n1_risk_5.0', 'opinion_h1n1_sick_from_vacc_2.0', 'opinion_h1n1_sick_from_vacc_3.0', 'opinion_h1n1_sick_from_vacc_4.0', 'opinion_h1n1_sick_from_vacc_5.0', 'opinion_seas_vacc_effective_2.0', 'opinion_seas_vacc_effective_3.0', 'opinion_seas_vacc_effective_4.0', 'opinion_seas_vacc_effective_5.0', 'opinion_seas_risk_2.0', 'opinion_seas_risk_3.0', 'opinion_seas_risk_4.0', 'opinion_seas_risk_5.0', 'opinion_seas_sick_from_vacc_2.0', 'opinion_seas_sick_from_vacc_3.0', 'opinion_seas_sick_from_vacc_4.0', 'opinion_seas_sick_from_vacc_5.0', 'age_group_35_to_44 Years', 'age_group_45_to_54 Years', 'age_group_55_to_64 Years', 'age_group_Over_65', 'education_< 12 Years', 'education_College Graduate', 'education_Some College', 'race_Hispanic', 'race_Other or Multiple', 'race_White', 'sex_Male', 'income_poverty_Above Poverty', 'income_poverty_Below Poverty', 'income_poverty_unknown', 'marital_status_Not Married', 'employment_status_Not in Labor Force', 'employment_status_Unemployed', 'hhs_geo_region_bhuqouqj', 'hhs_geo_region_dqpwygqj', 'hhs_geo_region_fpwskwrf', 'hhs_geo_region_kbazzjca', 'hhs_geo_region_lrircsnp', 'hhs_geo_region_lzgpxyit', 'hhs_geo_region_mlyzmhmf', 'hhs_geo_region_oxchjgsf', 'hhs_geo_region_qufhixun', 'census_msa_MSA, Principle City', 'census_msa_Non-MSA', 'employment_industry_atmlpfrs', 'employment_industry_cfqqtusy', 'employment_industry_dotnnunm', 'employment_industry_fcxhlnwr', 'employment_industry_haxffmxo', 'employment_industry_ldnlellj', 'employment_industry_mcubkhph', 'employment_industry_mfikgejo', 'employment_industry_msuufmds', 'employment_industry_nduyfdeo', 'employment_industry_phxvnwax', 'employment_industry_pxcmvdjn', 'employment_industry_qnlwzans', 'employment_industry_rucpziij', 'employment_industry_saaquncn', 'employment_industry_unknown', 'employment_industry_vjjrobsf', 'employment_industry_wlfvacwt', 'employment_industry_wxleyezf', 'employment_industry_xicduogh', 'employment_industry_xqicxuve', 'employment_occupation_ccgxvspp', 'employment_occupation_cmhcxjea', 'employment_occupation_dcjcmpih', 'employment_occupation_dlvbwzss', 'employment_occupation_emcorrxb', 'employment_occupation_haliazsg', 'employment_occupation_hfxkjkmi', 'employment_occupation_hodpvpew', 'employment_occupation_kldqjyjy', 'employment_occupation_mxkfnird', 'employment_occupation_oijqvulv', 'employment_occupation_pvmttkik', 'employment_occupation_qxajmpny', 'employment_occupation_rcertsgn', 'employment_occupation_tfqavkke', 'employment_occupation_ukymxvdu', 'employment_occupation_unknown', 'employment_occupation_uqqtjvyb', 'employment_occupation_vlluhbov', 'employment_occupation_xgwztkwe', 'employment_occupation_xqwwgdyp', 'employment_occupation_xtkaffoo', 'employment_occupation_xzmlyyjv']\n",
      "Removing ['household_adults', 'household_children', 'doctor_recc_seasonal', 'chronic_med_condition', 'opinion_seas_vacc_effective_5.0', 'opinion_seas_risk_4.0', 'opinion_seas_risk_5.0', 'age_group_Over_65']\n",
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Getting polynomial features of degree 2\n",
      "\n",
      "['age_group_35_to_44 Years age_group_45_to_54 Years', 'age_group_35_to_44 Years age_group_55_to_64 Years', 'age_group_35_to_44 Years age_group_Over_65', 'age_group_45_to_54 Years age_group_55_to_64 Years', 'age_group_45_to_54 Years age_group_Over_65', 'age_group_55_to_64 Years age_group_Over_65', 'education_< 12 Years education_College Graduate', 'education_< 12 Years education_Some College', 'education_College Graduate education_Some College', 'income_poverty_Above Poverty income_poverty_Below Poverty', 'income_poverty_Above Poverty income_poverty_unknown', 'income_poverty_Below Poverty income_poverty_unknown']\n",
      "were removed for containing 0 values\n",
      "\n",
      "Skipping class imbalance functions\n",
      "Using standard scaler\n",
      "Adding ['doctor_recc_seasonal^2', 'doctor_recc_seasonal age_group_35_to_44 Years', 'doctor_recc_seasonal age_group_45_to_54 Years', 'doctor_recc_seasonal age_group_55_to_64 Years', 'doctor_recc_seasonal age_group_Over_65', 'doctor_recc_seasonal education_< 12 Years', 'doctor_recc_seasonal education_College Graduate', 'doctor_recc_seasonal education_Some College', 'doctor_recc_seasonal sex_Male', 'doctor_recc_seasonal income_poverty_Above Poverty', 'doctor_recc_seasonal income_poverty_Below Poverty', 'doctor_recc_seasonal income_poverty_unknown', 'age_group_35_to_44 Years^2', 'age_group_35_to_44 Years education_< 12 Years', 'age_group_35_to_44 Years education_College Graduate', 'age_group_35_to_44 Years education_Some College', 'age_group_35_to_44 Years sex_Male', 'age_group_35_to_44 Years income_poverty_Above Poverty', 'age_group_35_to_44 Years income_poverty_Below Poverty', 'age_group_35_to_44 Years income_poverty_unknown', 'age_group_45_to_54 Years^2', 'age_group_45_to_54 Years education_< 12 Years', 'age_group_45_to_54 Years education_College Graduate', 'age_group_45_to_54 Years education_Some College', 'age_group_45_to_54 Years sex_Male', 'age_group_45_to_54 Years income_poverty_Above Poverty', 'age_group_45_to_54 Years income_poverty_Below Poverty', 'age_group_45_to_54 Years income_poverty_unknown', 'age_group_55_to_64 Years^2', 'age_group_55_to_64 Years education_< 12 Years', 'age_group_55_to_64 Years education_College Graduate', 'age_group_55_to_64 Years education_Some College', 'age_group_55_to_64 Years sex_Male', 'age_group_55_to_64 Years income_poverty_Above Poverty', 'age_group_55_to_64 Years income_poverty_Below Poverty', 'age_group_55_to_64 Years income_poverty_unknown', 'age_group_Over_65^2', 'age_group_Over_65 education_< 12 Years', 'age_group_Over_65 education_College Graduate', 'age_group_Over_65 education_Some College', 'age_group_Over_65 sex_Male', 'age_group_Over_65 income_poverty_Above Poverty', 'age_group_Over_65 income_poverty_Below Poverty', 'age_group_Over_65 income_poverty_unknown', 'education_< 12 Years^2', 'education_< 12 Years sex_Male', 'education_< 12 Years income_poverty_Above Poverty', 'education_< 12 Years income_poverty_Below Poverty', 'education_< 12 Years income_poverty_unknown', 'education_College Graduate^2', 'education_College Graduate sex_Male', 'education_College Graduate income_poverty_Above Poverty', 'education_College Graduate income_poverty_Below Poverty', 'education_College Graduate income_poverty_unknown', 'education_Some College^2', 'education_Some College sex_Male', 'education_Some College income_poverty_Above Poverty', 'education_Some College income_poverty_Below Poverty', 'education_Some College income_poverty_unknown', 'sex_Male^2', 'sex_Male income_poverty_Above Poverty', 'sex_Male income_poverty_Below Poverty', 'sex_Male income_poverty_unknown', 'income_poverty_Above Poverty^2', 'income_poverty_Below Poverty^2', 'income_poverty_unknown^2']\n",
      "Removing ['doctor_recc_seasonal age_group_45_to_54 Years', 'doctor_recc_seasonal education_Some College', 'doctor_recc_seasonal sex_Male', 'doctor_recc_seasonal income_poverty_unknown', 'age_group_Over_65 education_College Graduate', 'age_group_Over_65 sex_Male']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>homeowner</th>\n",
       "      <th>missing_doctor_recc</th>\n",
       "      <th>missing_health_insurance</th>\n",
       "      <th>missing_homeowner</th>\n",
       "      <th>missing_household</th>\n",
       "      <th>missing_opinion</th>\n",
       "      <th>missing_demographics</th>\n",
       "      <th>h1n1_concern_1.0</th>\n",
       "      <th>h1n1_concern_2.0</th>\n",
       "      <th>h1n1_concern_3.0</th>\n",
       "      <th>h1n1_knowledge_1.0</th>\n",
       "      <th>h1n1_knowledge_2.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_2.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_3.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_4.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_5.0</th>\n",
       "      <th>opinion_h1n1_risk_2.0</th>\n",
       "      <th>opinion_h1n1_risk_3.0</th>\n",
       "      <th>opinion_h1n1_risk_4.0</th>\n",
       "      <th>opinion_h1n1_risk_5.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_2.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_3.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_4.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_5.0</th>\n",
       "      <th>opinion_seas_vacc_effective_2.0</th>\n",
       "      <th>opinion_seas_vacc_effective_3.0</th>\n",
       "      <th>opinion_seas_vacc_effective_4.0</th>\n",
       "      <th>opinion_seas_vacc_effective_5.0</th>\n",
       "      <th>opinion_seas_risk_2.0</th>\n",
       "      <th>opinion_seas_risk_3.0</th>\n",
       "      <th>opinion_seas_risk_4.0</th>\n",
       "      <th>opinion_seas_risk_5.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_2.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_3.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_4.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_5.0</th>\n",
       "      <th>age_group_35_to_44 Years</th>\n",
       "      <th>age_group_45_to_54 Years</th>\n",
       "      <th>age_group_55_to_64 Years</th>\n",
       "      <th>age_group_Over_65</th>\n",
       "      <th>education_&lt; 12 Years</th>\n",
       "      <th>education_College Graduate</th>\n",
       "      <th>education_Some College</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>race_Other or Multiple</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>income_poverty_Above Poverty</th>\n",
       "      <th>income_poverty_Below Poverty</th>\n",
       "      <th>income_poverty_unknown</th>\n",
       "      <th>marital_status_Not Married</th>\n",
       "      <th>employment_status_Not in Labor Force</th>\n",
       "      <th>employment_status_Unemployed</th>\n",
       "      <th>hhs_geo_region_bhuqouqj</th>\n",
       "      <th>hhs_geo_region_dqpwygqj</th>\n",
       "      <th>hhs_geo_region_fpwskwrf</th>\n",
       "      <th>hhs_geo_region_kbazzjca</th>\n",
       "      <th>hhs_geo_region_lrircsnp</th>\n",
       "      <th>hhs_geo_region_lzgpxyit</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>hhs_geo_region_oxchjgsf</th>\n",
       "      <th>hhs_geo_region_qufhixun</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "      <th>employment_industry_atmlpfrs</th>\n",
       "      <th>employment_industry_cfqqtusy</th>\n",
       "      <th>employment_industry_dotnnunm</th>\n",
       "      <th>employment_industry_fcxhlnwr</th>\n",
       "      <th>employment_industry_haxffmxo</th>\n",
       "      <th>employment_industry_ldnlellj</th>\n",
       "      <th>employment_industry_mcubkhph</th>\n",
       "      <th>employment_industry_mfikgejo</th>\n",
       "      <th>employment_industry_msuufmds</th>\n",
       "      <th>employment_industry_nduyfdeo</th>\n",
       "      <th>employment_industry_phxvnwax</th>\n",
       "      <th>employment_industry_pxcmvdjn</th>\n",
       "      <th>employment_industry_qnlwzans</th>\n",
       "      <th>employment_industry_rucpziij</th>\n",
       "      <th>employment_industry_saaquncn</th>\n",
       "      <th>employment_industry_unknown</th>\n",
       "      <th>employment_industry_vjjrobsf</th>\n",
       "      <th>employment_industry_wlfvacwt</th>\n",
       "      <th>employment_industry_wxleyezf</th>\n",
       "      <th>employment_industry_xicduogh</th>\n",
       "      <th>employment_industry_xqicxuve</th>\n",
       "      <th>employment_occupation_ccgxvspp</th>\n",
       "      <th>employment_occupation_cmhcxjea</th>\n",
       "      <th>employment_occupation_dcjcmpih</th>\n",
       "      <th>employment_occupation_dlvbwzss</th>\n",
       "      <th>employment_occupation_emcorrxb</th>\n",
       "      <th>employment_occupation_haliazsg</th>\n",
       "      <th>employment_occupation_hfxkjkmi</th>\n",
       "      <th>employment_occupation_hodpvpew</th>\n",
       "      <th>employment_occupation_kldqjyjy</th>\n",
       "      <th>employment_occupation_mxkfnird</th>\n",
       "      <th>employment_occupation_oijqvulv</th>\n",
       "      <th>employment_occupation_pvmttkik</th>\n",
       "      <th>employment_occupation_qxajmpny</th>\n",
       "      <th>employment_occupation_rcertsgn</th>\n",
       "      <th>employment_occupation_tfqavkke</th>\n",
       "      <th>employment_occupation_ukymxvdu</th>\n",
       "      <th>employment_occupation_unknown</th>\n",
       "      <th>employment_occupation_uqqtjvyb</th>\n",
       "      <th>employment_occupation_vlluhbov</th>\n",
       "      <th>employment_occupation_xgwztkwe</th>\n",
       "      <th>employment_occupation_xqwwgdyp</th>\n",
       "      <th>employment_occupation_xtkaffoo</th>\n",
       "      <th>employment_occupation_xzmlyyjv</th>\n",
       "      <th>doctor_recc_seasonal age_group_45_to_54 Years</th>\n",
       "      <th>doctor_recc_seasonal education_Some College</th>\n",
       "      <th>doctor_recc_seasonal sex_Male</th>\n",
       "      <th>doctor_recc_seasonal income_poverty_unknown</th>\n",
       "      <th>age_group_Over_65 education_College Graduate</th>\n",
       "      <th>age_group_Over_65 sex_Male</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.151034</td>\n",
       "      <td>2.684344</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>-1.634308</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>-2.175076</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.710112</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>-0.505114</td>\n",
       "      <td>-0.657829</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>-0.922967</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>1.510254</td>\n",
       "      <td>-0.81578</td>\n",
       "      <td>-0.455790</td>\n",
       "      <td>-1.103584</td>\n",
       "      <td>1.341553</td>\n",
       "      <td>3.695083</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>-0.909914</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>-0.792031</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>1.991556</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>1.347591</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>-0.300085</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>1.095276</td>\n",
       "      <td>-0.769124</td>\n",
       "      <td>-0.740928</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>1.584643</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>1.505430</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>-0.261962</td>\n",
       "      <td>2.431921</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>-0.51153</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>1.144325</td>\n",
       "      <td>-0.598381</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>1.046039</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>-0.881482</td>\n",
       "      <td>-0.786876</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>-0.370681</td>\n",
       "      <td>2.886121</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>-0.438531</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>1.637401</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>-0.996496</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>3.700533</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>4.452369</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>-1.005962</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>-0.297110</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20097</th>\n",
       "      <td>0.151034</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>-1.634308</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.710112</td>\n",
       "      <td>-1.459119</td>\n",
       "      <td>-0.505114</td>\n",
       "      <td>-0.657829</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>-0.922967</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>1.510254</td>\n",
       "      <td>-0.81578</td>\n",
       "      <td>-0.455790</td>\n",
       "      <td>0.906139</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>3.695083</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>-0.909914</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>-0.792031</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>-0.502120</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>1.347591</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>-0.300085</td>\n",
       "      <td>3.350006</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>-0.913012</td>\n",
       "      <td>-0.769124</td>\n",
       "      <td>1.349659</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>-0.631057</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>2.132921</td>\n",
       "      <td>-0.261962</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>2.020711</td>\n",
       "      <td>-0.51153</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>1.144325</td>\n",
       "      <td>-0.598381</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>-0.955987</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>1.134453</td>\n",
       "      <td>-0.786876</td>\n",
       "      <td>4.194571</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>2.697740</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>-0.438531</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>1.551961</td>\n",
       "      <td>-0.610724</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>1.003517</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>0.994073</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>-0.297110</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24982</th>\n",
       "      <td>0.151034</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>0.611880</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>1.408228</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>1.979750</td>\n",
       "      <td>1.520152</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>-0.922967</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>1.22582</td>\n",
       "      <td>-0.455790</td>\n",
       "      <td>0.906139</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>-0.909914</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>1.262576</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>-0.502120</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>-0.742065</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>3.332389</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>1.095276</td>\n",
       "      <td>-0.769124</td>\n",
       "      <td>-0.740928</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>-0.631057</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>-0.261962</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>2.020711</td>\n",
       "      <td>-0.51153</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>-0.873877</td>\n",
       "      <td>1.671176</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>1.207246</td>\n",
       "      <td>-0.955987</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>-0.881482</td>\n",
       "      <td>-0.786876</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>-0.370681</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>2.280338</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>1.637401</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>8.889248</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>-0.996496</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>7.324066</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>-1.005962</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>4.327541</td>\n",
       "      <td>3.365759</td>\n",
       "      <td>2.866531</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12299</th>\n",
       "      <td>0.151034</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>4.438752</td>\n",
       "      <td>0.611880</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.710112</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>1.979750</td>\n",
       "      <td>1.520152</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>2.847960</td>\n",
       "      <td>-3.795227</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>-0.922967</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>-0.81578</td>\n",
       "      <td>2.193993</td>\n",
       "      <td>0.906139</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>-0.909914</td>\n",
       "      <td>1.649297</td>\n",
       "      <td>-0.792031</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>1.991556</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>-0.742065</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>3.332389</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>-0.913012</td>\n",
       "      <td>1.300180</td>\n",
       "      <td>-0.740928</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>-0.631057</td>\n",
       "      <td>2.837099</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>3.817350</td>\n",
       "      <td>2.431921</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>-0.51153</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>-0.873877</td>\n",
       "      <td>1.671176</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>-1.972059</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>-0.955987</td>\n",
       "      <td>3.002734</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>1.134453</td>\n",
       "      <td>-0.786876</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>2.697740</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>-0.438531</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>1.637401</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>3.103972</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>-0.996496</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>9.401771</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>-1.005962</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>3.365759</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>-1.184580</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>-1.634308</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>1.341963</td>\n",
       "      <td>1.408228</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>1.979750</td>\n",
       "      <td>1.520152</td>\n",
       "      <td>1.640894</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>-3.795227</td>\n",
       "      <td>-1.883529</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>-0.922967</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>-0.81578</td>\n",
       "      <td>2.193993</td>\n",
       "      <td>-1.103584</td>\n",
       "      <td>1.341553</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>-0.909914</td>\n",
       "      <td>1.649297</td>\n",
       "      <td>-0.792031</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>1.991556</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>-0.742065</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>3.332389</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>-0.913012</td>\n",
       "      <td>1.300180</td>\n",
       "      <td>-0.740928</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>-0.631057</td>\n",
       "      <td>2.837099</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>3.817350</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>2.020711</td>\n",
       "      <td>-0.51153</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>-0.873877</td>\n",
       "      <td>-0.598381</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>-0.955987</td>\n",
       "      <td>3.002734</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>1.134453</td>\n",
       "      <td>1.270848</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>2.884710</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>-0.370681</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>-0.438531</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>1.551961</td>\n",
       "      <td>-0.610724</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>1.003517</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>0.994073</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>4.327541</td>\n",
       "      <td>-0.297110</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>-1.184580</td>\n",
       "      <td>0.513971</td>\n",
       "      <td>4.438752</td>\n",
       "      <td>0.611880</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.710112</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>1.979750</td>\n",
       "      <td>1.520152</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>1.083462</td>\n",
       "      <td>3.462346</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>3.779226</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>-0.81578</td>\n",
       "      <td>2.193993</td>\n",
       "      <td>0.906139</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>1.099005</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>-0.792031</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>1.991556</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>-0.742065</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>1.897253</td>\n",
       "      <td>-0.300085</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>1.095276</td>\n",
       "      <td>-0.769124</td>\n",
       "      <td>-0.740928</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>1.584643</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>2.132921</td>\n",
       "      <td>-0.261962</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>-0.51153</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>1.144325</td>\n",
       "      <td>-0.598381</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>-0.955987</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>2.248519</td>\n",
       "      <td>-0.881482</td>\n",
       "      <td>-0.786876</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>2.697740</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>-0.438531</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>-0.610724</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>1.003517</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>0.994073</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>-0.297110</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>4.582913</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>0.151034</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>-1.634308</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.710112</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>1.979750</td>\n",
       "      <td>1.520152</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>3.371054</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>1.083462</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>1.22582</td>\n",
       "      <td>-0.455790</td>\n",
       "      <td>-1.103584</td>\n",
       "      <td>1.341553</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>1.099005</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>1.262576</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>-0.502120</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>1.347591</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>-0.300085</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>-0.913012</td>\n",
       "      <td>1.300180</td>\n",
       "      <td>-0.740928</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>1.584643</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>-0.261962</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>1.95492</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>-0.873877</td>\n",
       "      <td>1.671176</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>1.046039</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>-0.881482</td>\n",
       "      <td>1.270848</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>-0.370681</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>2.280338</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>-0.610724</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>1.003517</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>0.994073</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>3.365759</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16022</th>\n",
       "      <td>0.151034</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>0.611880</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>1.341963</td>\n",
       "      <td>1.408228</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>-0.505114</td>\n",
       "      <td>-0.657829</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>1.083462</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>1.22582</td>\n",
       "      <td>-0.455790</td>\n",
       "      <td>0.906139</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>1.099005</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>1.262576</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>-0.502120</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>1.347591</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>-0.300085</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>1.095276</td>\n",
       "      <td>-0.769124</td>\n",
       "      <td>1.349659</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>-0.631057</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>1.505430</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>-0.261962</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>1.95492</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>1.144325</td>\n",
       "      <td>-0.598381</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>-1.972059</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>-0.955987</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>-0.881482</td>\n",
       "      <td>1.270848</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>-0.370681</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>2.280338</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>-0.610724</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>1.003517</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>0.994073</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>-0.297110</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.151034</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>-1.634308</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>-2.175076</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.710112</td>\n",
       "      <td>-1.459119</td>\n",
       "      <td>-0.505114</td>\n",
       "      <td>-0.657829</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>-0.351129</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>-0.922967</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>1.22582</td>\n",
       "      <td>-0.455790</td>\n",
       "      <td>0.906139</td>\n",
       "      <td>-0.745405</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>2.158959</td>\n",
       "      <td>-0.909914</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>1.262576</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>-0.502120</td>\n",
       "      <td>-0.266624</td>\n",
       "      <td>-0.742065</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>-0.300085</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>-0.913012</td>\n",
       "      <td>1.300180</td>\n",
       "      <td>1.349659</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>-0.631057</td>\n",
       "      <td>-0.352473</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>-0.261962</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>-0.51153</td>\n",
       "      <td>1.701728</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>1.144325</td>\n",
       "      <td>-0.598381</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>-0.955987</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>-0.881482</td>\n",
       "      <td>1.270848</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>2.697740</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>-0.289677</td>\n",
       "      <td>-0.438531</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>-0.610724</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>-0.322168</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>1.003517</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>-0.244698</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>0.994073</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>-0.297110</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>3.169709</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14084</th>\n",
       "      <td>-1.184580</td>\n",
       "      <td>-0.571215</td>\n",
       "      <td>-0.225289</td>\n",
       "      <td>0.611880</td>\n",
       "      <td>-0.272716</td>\n",
       "      <td>0.459754</td>\n",
       "      <td>-0.745177</td>\n",
       "      <td>-0.710112</td>\n",
       "      <td>0.685345</td>\n",
       "      <td>1.979750</td>\n",
       "      <td>1.520152</td>\n",
       "      <td>-0.609424</td>\n",
       "      <td>-0.296643</td>\n",
       "      <td>2.847960</td>\n",
       "      <td>0.263489</td>\n",
       "      <td>0.530918</td>\n",
       "      <td>-0.297483</td>\n",
       "      <td>1.083462</td>\n",
       "      <td>-0.288821</td>\n",
       "      <td>-0.097454</td>\n",
       "      <td>-0.165412</td>\n",
       "      <td>-0.264604</td>\n",
       "      <td>-0.662140</td>\n",
       "      <td>-0.81578</td>\n",
       "      <td>2.193993</td>\n",
       "      <td>-1.103584</td>\n",
       "      <td>1.341553</td>\n",
       "      <td>-0.270630</td>\n",
       "      <td>-0.463186</td>\n",
       "      <td>1.099005</td>\n",
       "      <td>-0.606319</td>\n",
       "      <td>-0.792031</td>\n",
       "      <td>-0.211405</td>\n",
       "      <td>-0.502120</td>\n",
       "      <td>3.750599</td>\n",
       "      <td>-0.742065</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.527078</td>\n",
       "      <td>3.332389</td>\n",
       "      <td>-0.298507</td>\n",
       "      <td>-0.217613</td>\n",
       "      <td>-0.913012</td>\n",
       "      <td>1.300180</td>\n",
       "      <td>-0.740928</td>\n",
       "      <td>-0.162401</td>\n",
       "      <td>-0.631057</td>\n",
       "      <td>2.837099</td>\n",
       "      <td>-0.664262</td>\n",
       "      <td>-0.057334</td>\n",
       "      <td>-0.468841</td>\n",
       "      <td>3.817350</td>\n",
       "      <td>-0.411198</td>\n",
       "      <td>-0.494875</td>\n",
       "      <td>1.95492</td>\n",
       "      <td>-0.587638</td>\n",
       "      <td>-0.309077</td>\n",
       "      <td>-0.873877</td>\n",
       "      <td>-0.598381</td>\n",
       "      <td>-0.265918</td>\n",
       "      <td>-0.253912</td>\n",
       "      <td>0.507084</td>\n",
       "      <td>-0.828332</td>\n",
       "      <td>1.046039</td>\n",
       "      <td>-0.333030</td>\n",
       "      <td>-0.444737</td>\n",
       "      <td>1.134453</td>\n",
       "      <td>-0.786876</td>\n",
       "      <td>-0.238403</td>\n",
       "      <td>-0.346655</td>\n",
       "      <td>-0.207877</td>\n",
       "      <td>-0.370681</td>\n",
       "      <td>-0.346486</td>\n",
       "      <td>3.452126</td>\n",
       "      <td>-0.438531</td>\n",
       "      <td>-0.303409</td>\n",
       "      <td>-0.34784</td>\n",
       "      <td>-0.363621</td>\n",
       "      <td>-0.644346</td>\n",
       "      <td>1.637401</td>\n",
       "      <td>-0.190343</td>\n",
       "      <td>-0.112495</td>\n",
       "      <td>-0.083803</td>\n",
       "      <td>3.103972</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.220312</td>\n",
       "      <td>-0.102469</td>\n",
       "      <td>-0.151763</td>\n",
       "      <td>-0.065403</td>\n",
       "      <td>-0.105686</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.199527</td>\n",
       "      <td>-0.02164</td>\n",
       "      <td>-0.138128</td>\n",
       "      <td>-0.112068</td>\n",
       "      <td>-0.996496</td>\n",
       "      <td>-0.142976</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>-0.270231</td>\n",
       "      <td>-0.180069</td>\n",
       "      <td>-0.142122</td>\n",
       "      <td>-0.11419</td>\n",
       "      <td>-0.223447</td>\n",
       "      <td>-0.075783</td>\n",
       "      <td>-0.092435</td>\n",
       "      <td>-0.224600</td>\n",
       "      <td>-0.106363</td>\n",
       "      <td>-0.175304</td>\n",
       "      <td>-0.089559</td>\n",
       "      <td>-0.136536</td>\n",
       "      <td>4.086675</td>\n",
       "      <td>-0.115861</td>\n",
       "      <td>-0.06169</td>\n",
       "      <td>-0.144503</td>\n",
       "      <td>-0.101061</td>\n",
       "      <td>-0.117099</td>\n",
       "      <td>-0.117305</td>\n",
       "      <td>-1.005962</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.116068</td>\n",
       "      <td>-0.201799</td>\n",
       "      <td>-0.137069</td>\n",
       "      <td>-0.266926</td>\n",
       "      <td>-0.095227</td>\n",
       "      <td>-0.231078</td>\n",
       "      <td>-0.297110</td>\n",
       "      <td>-0.348854</td>\n",
       "      <td>-0.218202</td>\n",
       "      <td>-0.315486</td>\n",
       "      <td>-0.320039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26707 rows  130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               household_adults  household_children  \\\n",
       "respondent_id                                         \n",
       "358                    0.151034            2.684344   \n",
       "20097                  0.151034           -0.571215   \n",
       "24982                  0.151034           -0.571215   \n",
       "12299                  0.151034           -0.571215   \n",
       "8759                  -1.184580           -0.571215   \n",
       "...                         ...                 ...   \n",
       "10407                 -1.184580            0.513971   \n",
       "7443                   0.151034           -0.571215   \n",
       "16022                  0.151034           -0.571215   \n",
       "2569                   0.151034           -0.571215   \n",
       "14084                 -1.184580           -0.571215   \n",
       "\n",
       "               behavioral_antiviral_meds  behavioral_avoidance  \\\n",
       "respondent_id                                                    \n",
       "358                            -0.225289             -1.634308   \n",
       "20097                          -0.225289             -1.634308   \n",
       "24982                          -0.225289              0.611880   \n",
       "12299                           4.438752              0.611880   \n",
       "8759                           -0.225289             -1.634308   \n",
       "...                                  ...                   ...   \n",
       "10407                           4.438752              0.611880   \n",
       "7443                           -0.225289             -1.634308   \n",
       "16022                          -0.225289              0.611880   \n",
       "2569                           -0.225289             -1.634308   \n",
       "14084                          -0.225289              0.611880   \n",
       "\n",
       "               behavioral_face_mask  behavioral_wash_hands  \\\n",
       "respondent_id                                                \n",
       "358                       -0.272716              -2.175076   \n",
       "20097                     -0.272716               0.459754   \n",
       "24982                     -0.272716               0.459754   \n",
       "12299                     -0.272716               0.459754   \n",
       "8759                      -0.272716               0.459754   \n",
       "...                             ...                    ...   \n",
       "10407                     -0.272716               0.459754   \n",
       "7443                      -0.272716               0.459754   \n",
       "16022                     -0.272716               0.459754   \n",
       "2569                      -0.272716              -2.175076   \n",
       "14084                     -0.272716               0.459754   \n",
       "\n",
       "               behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "respondent_id                                                         \n",
       "358                              -0.745177                -0.710112   \n",
       "20097                            -0.745177                -0.710112   \n",
       "24982                            -0.745177                 1.408228   \n",
       "12299                            -0.745177                -0.710112   \n",
       "8759                              1.341963                 1.408228   \n",
       "...                                    ...                      ...   \n",
       "10407                            -0.745177                -0.710112   \n",
       "7443                             -0.745177                -0.710112   \n",
       "16022                             1.341963                 1.408228   \n",
       "2569                             -0.745177                -0.710112   \n",
       "14084                            -0.745177                -0.710112   \n",
       "\n",
       "               behavioral_touch_face  doctor_recc_h1n1  doctor_recc_seasonal  \\\n",
       "respondent_id                                                                  \n",
       "358                         0.685345         -0.505114             -0.657829   \n",
       "20097                      -1.459119         -0.505114             -0.657829   \n",
       "24982                       0.685345          1.979750              1.520152   \n",
       "12299                       0.685345          1.979750              1.520152   \n",
       "8759                        0.685345          1.979750              1.520152   \n",
       "...                              ...               ...                   ...   \n",
       "10407                       0.685345          1.979750              1.520152   \n",
       "7443                        0.685345          1.979750              1.520152   \n",
       "16022                       0.685345         -0.505114             -0.657829   \n",
       "2569                       -1.459119         -0.505114             -0.657829   \n",
       "14084                       0.685345          1.979750              1.520152   \n",
       "\n",
       "               chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "respondent_id                                                               \n",
       "358                        -0.609424             -0.296643      -0.351129   \n",
       "20097                      -0.609424             -0.296643      -0.351129   \n",
       "24982                      -0.609424             -0.296643      -0.351129   \n",
       "12299                      -0.609424             -0.296643       2.847960   \n",
       "8759                        1.640894             -0.296643      -0.351129   \n",
       "...                              ...                   ...            ...   \n",
       "10407                      -0.609424             -0.296643      -0.351129   \n",
       "7443                       -0.609424              3.371054      -0.351129   \n",
       "16022                      -0.609424             -0.296643      -0.351129   \n",
       "2569                       -0.609424             -0.296643      -0.351129   \n",
       "14084                      -0.609424             -0.296643       2.847960   \n",
       "\n",
       "               health_insurance  homeowner  missing_doctor_recc  \\\n",
       "respondent_id                                                     \n",
       "358                    0.263489   0.530918            -0.297483   \n",
       "20097                  0.263489   0.530918            -0.297483   \n",
       "24982                  0.263489   0.530918            -0.297483   \n",
       "12299                 -3.795227   0.530918            -0.297483   \n",
       "8759                  -3.795227  -1.883529            -0.297483   \n",
       "...                         ...        ...                  ...   \n",
       "10407                  0.263489   0.530918            -0.297483   \n",
       "7443                   0.263489   0.530918            -0.297483   \n",
       "16022                  0.263489   0.530918            -0.297483   \n",
       "2569                   0.263489   0.530918            -0.297483   \n",
       "14084                  0.263489   0.530918            -0.297483   \n",
       "\n",
       "               missing_health_insurance  missing_homeowner  missing_household  \\\n",
       "respondent_id                                                                   \n",
       "358                           -0.922967          -0.288821          -0.097454   \n",
       "20097                         -0.922967          -0.288821          -0.097454   \n",
       "24982                         -0.922967          -0.288821          -0.097454   \n",
       "12299                         -0.922967          -0.288821          -0.097454   \n",
       "8759                          -0.922967          -0.288821          -0.097454   \n",
       "...                                 ...                ...                ...   \n",
       "10407                          1.083462           3.462346          -0.097454   \n",
       "7443                           1.083462          -0.288821          -0.097454   \n",
       "16022                          1.083462          -0.288821          -0.097454   \n",
       "2569                          -0.922967          -0.288821          -0.097454   \n",
       "14084                          1.083462          -0.288821          -0.097454   \n",
       "\n",
       "               missing_opinion  missing_demographics  h1n1_concern_1.0  \\\n",
       "respondent_id                                                            \n",
       "358                  -0.165412             -0.264604          1.510254   \n",
       "20097                -0.165412             -0.264604          1.510254   \n",
       "24982                -0.165412             -0.264604         -0.662140   \n",
       "12299                -0.165412             -0.264604         -0.662140   \n",
       "8759                 -0.165412             -0.264604         -0.662140   \n",
       "...                        ...                   ...               ...   \n",
       "10407                -0.165412              3.779226         -0.662140   \n",
       "7443                 -0.165412             -0.264604         -0.662140   \n",
       "16022                -0.165412             -0.264604         -0.662140   \n",
       "2569                 -0.165412             -0.264604         -0.662140   \n",
       "14084                -0.165412             -0.264604         -0.662140   \n",
       "\n",
       "               h1n1_concern_2.0  h1n1_concern_3.0  h1n1_knowledge_1.0  \\\n",
       "respondent_id                                                           \n",
       "358                    -0.81578         -0.455790           -1.103584   \n",
       "20097                  -0.81578         -0.455790            0.906139   \n",
       "24982                   1.22582         -0.455790            0.906139   \n",
       "12299                  -0.81578          2.193993            0.906139   \n",
       "8759                   -0.81578          2.193993           -1.103584   \n",
       "...                         ...               ...                 ...   \n",
       "10407                  -0.81578          2.193993            0.906139   \n",
       "7443                    1.22582         -0.455790           -1.103584   \n",
       "16022                   1.22582         -0.455790            0.906139   \n",
       "2569                    1.22582         -0.455790            0.906139   \n",
       "14084                  -0.81578          2.193993           -1.103584   \n",
       "\n",
       "               h1n1_knowledge_2.0  opinion_h1n1_vacc_effective_2.0  \\\n",
       "respondent_id                                                        \n",
       "358                      1.341553                         3.695083   \n",
       "20097                   -0.745405                         3.695083   \n",
       "24982                   -0.745405                        -0.270630   \n",
       "12299                   -0.745405                        -0.270630   \n",
       "8759                     1.341553                        -0.270630   \n",
       "...                           ...                              ...   \n",
       "10407                   -0.745405                        -0.270630   \n",
       "7443                     1.341553                        -0.270630   \n",
       "16022                   -0.745405                        -0.270630   \n",
       "2569                    -0.745405                        -0.270630   \n",
       "14084                    1.341553                        -0.270630   \n",
       "\n",
       "               opinion_h1n1_vacc_effective_3.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.463186   \n",
       "20097                                -0.463186   \n",
       "24982                                -0.463186   \n",
       "12299                                -0.463186   \n",
       "8759                                 -0.463186   \n",
       "...                                        ...   \n",
       "10407                                -0.463186   \n",
       "7443                                 -0.463186   \n",
       "16022                                -0.463186   \n",
       "2569                                  2.158959   \n",
       "14084                                -0.463186   \n",
       "\n",
       "               opinion_h1n1_vacc_effective_4.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.909914   \n",
       "20097                                -0.909914   \n",
       "24982                                -0.909914   \n",
       "12299                                -0.909914   \n",
       "8759                                 -0.909914   \n",
       "...                                        ...   \n",
       "10407                                 1.099005   \n",
       "7443                                  1.099005   \n",
       "16022                                 1.099005   \n",
       "2569                                 -0.909914   \n",
       "14084                                 1.099005   \n",
       "\n",
       "               opinion_h1n1_vacc_effective_5.0  opinion_h1n1_risk_2.0  \\\n",
       "respondent_id                                                           \n",
       "358                                  -0.606319              -0.792031   \n",
       "20097                                -0.606319              -0.792031   \n",
       "24982                                -0.606319               1.262576   \n",
       "12299                                 1.649297              -0.792031   \n",
       "8759                                  1.649297              -0.792031   \n",
       "...                                        ...                    ...   \n",
       "10407                                -0.606319              -0.792031   \n",
       "7443                                 -0.606319               1.262576   \n",
       "16022                                -0.606319               1.262576   \n",
       "2569                                 -0.606319               1.262576   \n",
       "14084                                -0.606319              -0.792031   \n",
       "\n",
       "               opinion_h1n1_risk_3.0  opinion_h1n1_risk_4.0  \\\n",
       "respondent_id                                                 \n",
       "358                        -0.211405               1.991556   \n",
       "20097                      -0.211405              -0.502120   \n",
       "24982                      -0.211405              -0.502120   \n",
       "12299                      -0.211405               1.991556   \n",
       "8759                       -0.211405               1.991556   \n",
       "...                              ...                    ...   \n",
       "10407                      -0.211405               1.991556   \n",
       "7443                       -0.211405              -0.502120   \n",
       "16022                      -0.211405              -0.502120   \n",
       "2569                       -0.211405              -0.502120   \n",
       "14084                      -0.211405              -0.502120   \n",
       "\n",
       "               opinion_h1n1_risk_5.0  opinion_h1n1_sick_from_vacc_2.0  \\\n",
       "respondent_id                                                           \n",
       "358                        -0.266624                         1.347591   \n",
       "20097                      -0.266624                         1.347591   \n",
       "24982                      -0.266624                        -0.742065   \n",
       "12299                      -0.266624                        -0.742065   \n",
       "8759                       -0.266624                        -0.742065   \n",
       "...                              ...                              ...   \n",
       "10407                      -0.266624                        -0.742065   \n",
       "7443                       -0.266624                         1.347591   \n",
       "16022                      -0.266624                         1.347591   \n",
       "2569                       -0.266624                        -0.742065   \n",
       "14084                       3.750599                        -0.742065   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc_3.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.075783   \n",
       "20097                                -0.075783   \n",
       "24982                                -0.075783   \n",
       "12299                                -0.075783   \n",
       "8759                                 -0.075783   \n",
       "...                                        ...   \n",
       "10407                                -0.075783   \n",
       "7443                                 -0.075783   \n",
       "16022                                -0.075783   \n",
       "2569                                 -0.075783   \n",
       "14084                                -0.075783   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc_4.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.527078   \n",
       "20097                                -0.527078   \n",
       "24982                                -0.527078   \n",
       "12299                                -0.527078   \n",
       "8759                                 -0.527078   \n",
       "...                                        ...   \n",
       "10407                                 1.897253   \n",
       "7443                                 -0.527078   \n",
       "16022                                -0.527078   \n",
       "2569                                 -0.527078   \n",
       "14084                                -0.527078   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc_5.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.300085   \n",
       "20097                                -0.300085   \n",
       "24982                                 3.332389   \n",
       "12299                                 3.332389   \n",
       "8759                                  3.332389   \n",
       "...                                        ...   \n",
       "10407                                -0.300085   \n",
       "7443                                 -0.300085   \n",
       "16022                                -0.300085   \n",
       "2569                                 -0.300085   \n",
       "14084                                 3.332389   \n",
       "\n",
       "               opinion_seas_vacc_effective_2.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.298507   \n",
       "20097                                 3.350006   \n",
       "24982                                -0.298507   \n",
       "12299                                -0.298507   \n",
       "8759                                 -0.298507   \n",
       "...                                        ...   \n",
       "10407                                -0.298507   \n",
       "7443                                 -0.298507   \n",
       "16022                                -0.298507   \n",
       "2569                                 -0.298507   \n",
       "14084                                -0.298507   \n",
       "\n",
       "               opinion_seas_vacc_effective_3.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.217613   \n",
       "20097                                -0.217613   \n",
       "24982                                -0.217613   \n",
       "12299                                -0.217613   \n",
       "8759                                 -0.217613   \n",
       "...                                        ...   \n",
       "10407                                -0.217613   \n",
       "7443                                 -0.217613   \n",
       "16022                                -0.217613   \n",
       "2569                                 -0.217613   \n",
       "14084                                -0.217613   \n",
       "\n",
       "               opinion_seas_vacc_effective_4.0  \\\n",
       "respondent_id                                    \n",
       "358                                   1.095276   \n",
       "20097                                -0.913012   \n",
       "24982                                 1.095276   \n",
       "12299                                -0.913012   \n",
       "8759                                 -0.913012   \n",
       "...                                        ...   \n",
       "10407                                 1.095276   \n",
       "7443                                 -0.913012   \n",
       "16022                                 1.095276   \n",
       "2569                                 -0.913012   \n",
       "14084                                -0.913012   \n",
       "\n",
       "               opinion_seas_vacc_effective_5.0  opinion_seas_risk_2.0  \\\n",
       "respondent_id                                                           \n",
       "358                                  -0.769124              -0.740928   \n",
       "20097                                -0.769124               1.349659   \n",
       "24982                                -0.769124              -0.740928   \n",
       "12299                                 1.300180              -0.740928   \n",
       "8759                                  1.300180              -0.740928   \n",
       "...                                        ...                    ...   \n",
       "10407                                -0.769124              -0.740928   \n",
       "7443                                  1.300180              -0.740928   \n",
       "16022                                -0.769124               1.349659   \n",
       "2569                                  1.300180               1.349659   \n",
       "14084                                 1.300180              -0.740928   \n",
       "\n",
       "               opinion_seas_risk_3.0  opinion_seas_risk_4.0  \\\n",
       "respondent_id                                                 \n",
       "358                        -0.162401               1.584643   \n",
       "20097                      -0.162401              -0.631057   \n",
       "24982                      -0.162401              -0.631057   \n",
       "12299                      -0.162401              -0.631057   \n",
       "8759                       -0.162401              -0.631057   \n",
       "...                              ...                    ...   \n",
       "10407                      -0.162401               1.584643   \n",
       "7443                       -0.162401               1.584643   \n",
       "16022                      -0.162401              -0.631057   \n",
       "2569                       -0.162401              -0.631057   \n",
       "14084                      -0.162401              -0.631057   \n",
       "\n",
       "               opinion_seas_risk_5.0  opinion_seas_sick_from_vacc_2.0  \\\n",
       "respondent_id                                                           \n",
       "358                        -0.352473                         1.505430   \n",
       "20097                      -0.352473                        -0.664262   \n",
       "24982                      -0.352473                        -0.664262   \n",
       "12299                       2.837099                        -0.664262   \n",
       "8759                        2.837099                        -0.664262   \n",
       "...                              ...                              ...   \n",
       "10407                      -0.352473                        -0.664262   \n",
       "7443                       -0.352473                        -0.664262   \n",
       "16022                      -0.352473                         1.505430   \n",
       "2569                       -0.352473                        -0.664262   \n",
       "14084                       2.837099                        -0.664262   \n",
       "\n",
       "               opinion_seas_sick_from_vacc_3.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.057334   \n",
       "20097                                -0.057334   \n",
       "24982                                -0.057334   \n",
       "12299                                -0.057334   \n",
       "8759                                 -0.057334   \n",
       "...                                        ...   \n",
       "10407                                -0.057334   \n",
       "7443                                 -0.057334   \n",
       "16022                                -0.057334   \n",
       "2569                                 -0.057334   \n",
       "14084                                -0.057334   \n",
       "\n",
       "               opinion_seas_sick_from_vacc_4.0  \\\n",
       "respondent_id                                    \n",
       "358                                  -0.468841   \n",
       "20097                                 2.132921   \n",
       "24982                                -0.468841   \n",
       "12299                                -0.468841   \n",
       "8759                                 -0.468841   \n",
       "...                                        ...   \n",
       "10407                                 2.132921   \n",
       "7443                                 -0.468841   \n",
       "16022                                -0.468841   \n",
       "2569                                 -0.468841   \n",
       "14084                                -0.468841   \n",
       "\n",
       "               opinion_seas_sick_from_vacc_5.0  age_group_35_to_44 Years  \\\n",
       "respondent_id                                                              \n",
       "358                                  -0.261962                  2.431921   \n",
       "20097                                -0.261962                 -0.411198   \n",
       "24982                                -0.261962                 -0.411198   \n",
       "12299                                 3.817350                  2.431921   \n",
       "8759                                  3.817350                 -0.411198   \n",
       "...                                        ...                       ...   \n",
       "10407                                -0.261962                 -0.411198   \n",
       "7443                                 -0.261962                 -0.411198   \n",
       "16022                                -0.261962                 -0.411198   \n",
       "2569                                 -0.261962                 -0.411198   \n",
       "14084                                 3.817350                 -0.411198   \n",
       "\n",
       "               age_group_45_to_54 Years  age_group_55_to_64 Years  \\\n",
       "respondent_id                                                       \n",
       "358                           -0.494875                  -0.51153   \n",
       "20097                          2.020711                  -0.51153   \n",
       "24982                          2.020711                  -0.51153   \n",
       "12299                         -0.494875                  -0.51153   \n",
       "8759                           2.020711                  -0.51153   \n",
       "...                                 ...                       ...   \n",
       "10407                         -0.494875                  -0.51153   \n",
       "7443                          -0.494875                   1.95492   \n",
       "16022                         -0.494875                   1.95492   \n",
       "2569                          -0.494875                  -0.51153   \n",
       "14084                         -0.494875                   1.95492   \n",
       "\n",
       "               age_group_Over_65  education_< 12 Years  \\\n",
       "respondent_id                                            \n",
       "358                    -0.587638             -0.309077   \n",
       "20097                  -0.587638             -0.309077   \n",
       "24982                  -0.587638             -0.309077   \n",
       "12299                  -0.587638             -0.309077   \n",
       "8759                   -0.587638             -0.309077   \n",
       "...                          ...                   ...   \n",
       "10407                  -0.587638             -0.309077   \n",
       "7443                   -0.587638             -0.309077   \n",
       "16022                  -0.587638             -0.309077   \n",
       "2569                    1.701728             -0.309077   \n",
       "14084                  -0.587638             -0.309077   \n",
       "\n",
       "               education_College Graduate  education_Some College  \\\n",
       "respondent_id                                                       \n",
       "358                              1.144325               -0.598381   \n",
       "20097                            1.144325               -0.598381   \n",
       "24982                           -0.873877                1.671176   \n",
       "12299                           -0.873877                1.671176   \n",
       "8759                            -0.873877               -0.598381   \n",
       "...                                   ...                     ...   \n",
       "10407                            1.144325               -0.598381   \n",
       "7443                            -0.873877                1.671176   \n",
       "16022                            1.144325               -0.598381   \n",
       "2569                             1.144325               -0.598381   \n",
       "14084                           -0.873877               -0.598381   \n",
       "\n",
       "               race_Hispanic  race_Other or Multiple  race_White  sex_Male  \\\n",
       "respondent_id                                                                \n",
       "358                -0.265918               -0.253912    0.507084 -0.828332   \n",
       "20097              -0.265918               -0.253912    0.507084 -0.828332   \n",
       "24982              -0.265918               -0.253912    0.507084  1.207246   \n",
       "12299              -0.265918               -0.253912   -1.972059 -0.828332   \n",
       "8759               -0.265918               -0.253912    0.507084 -0.828332   \n",
       "...                      ...                     ...         ...       ...   \n",
       "10407              -0.265918               -0.253912    0.507084 -0.828332   \n",
       "7443               -0.265918               -0.253912    0.507084 -0.828332   \n",
       "16022              -0.265918               -0.253912   -1.972059 -0.828332   \n",
       "2569               -0.265918               -0.253912    0.507084 -0.828332   \n",
       "14084              -0.265918               -0.253912    0.507084 -0.828332   \n",
       "\n",
       "               income_poverty_Above Poverty  income_poverty_Below Poverty  \\\n",
       "respondent_id                                                               \n",
       "358                                1.046039                     -0.333030   \n",
       "20097                             -0.955987                     -0.333030   \n",
       "24982                             -0.955987                     -0.333030   \n",
       "12299                             -0.955987                      3.002734   \n",
       "8759                              -0.955987                      3.002734   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.955987                     -0.333030   \n",
       "7443                               1.046039                     -0.333030   \n",
       "16022                             -0.955987                     -0.333030   \n",
       "2569                              -0.955987                     -0.333030   \n",
       "14084                              1.046039                     -0.333030   \n",
       "\n",
       "               income_poverty_unknown  marital_status_Not Married  \\\n",
       "respondent_id                                                       \n",
       "358                         -0.444737                   -0.881482   \n",
       "20097                       -0.444737                    1.134453   \n",
       "24982                       -0.444737                   -0.881482   \n",
       "12299                       -0.444737                    1.134453   \n",
       "8759                        -0.444737                    1.134453   \n",
       "...                               ...                         ...   \n",
       "10407                        2.248519                   -0.881482   \n",
       "7443                        -0.444737                   -0.881482   \n",
       "16022                       -0.444737                   -0.881482   \n",
       "2569                        -0.444737                   -0.881482   \n",
       "14084                       -0.444737                    1.134453   \n",
       "\n",
       "               employment_status_Not in Labor Force  \\\n",
       "respondent_id                                         \n",
       "358                                       -0.786876   \n",
       "20097                                     -0.786876   \n",
       "24982                                     -0.786876   \n",
       "12299                                     -0.786876   \n",
       "8759                                       1.270848   \n",
       "...                                             ...   \n",
       "10407                                     -0.786876   \n",
       "7443                                       1.270848   \n",
       "16022                                      1.270848   \n",
       "2569                                       1.270848   \n",
       "14084                                     -0.786876   \n",
       "\n",
       "               employment_status_Unemployed  hhs_geo_region_bhuqouqj  \\\n",
       "respondent_id                                                          \n",
       "358                               -0.238403                -0.346655   \n",
       "20097                              4.194571                -0.346655   \n",
       "24982                             -0.238403                -0.346655   \n",
       "12299                             -0.238403                -0.346655   \n",
       "8759                              -0.238403                 2.884710   \n",
       "...                                     ...                      ...   \n",
       "10407                             -0.238403                -0.346655   \n",
       "7443                              -0.238403                -0.346655   \n",
       "16022                             -0.238403                -0.346655   \n",
       "2569                              -0.238403                -0.346655   \n",
       "14084                             -0.238403                -0.346655   \n",
       "\n",
       "               hhs_geo_region_dqpwygqj  hhs_geo_region_fpwskwrf  \\\n",
       "respondent_id                                                     \n",
       "358                          -0.207877                -0.370681   \n",
       "20097                        -0.207877                 2.697740   \n",
       "24982                        -0.207877                -0.370681   \n",
       "12299                        -0.207877                 2.697740   \n",
       "8759                         -0.207877                -0.370681   \n",
       "...                                ...                      ...   \n",
       "10407                        -0.207877                 2.697740   \n",
       "7443                         -0.207877                -0.370681   \n",
       "16022                        -0.207877                -0.370681   \n",
       "2569                         -0.207877                 2.697740   \n",
       "14084                        -0.207877                -0.370681   \n",
       "\n",
       "               hhs_geo_region_kbazzjca  hhs_geo_region_lrircsnp  \\\n",
       "respondent_id                                                     \n",
       "358                           2.886121                -0.289677   \n",
       "20097                        -0.346486                -0.289677   \n",
       "24982                        -0.346486                -0.289677   \n",
       "12299                        -0.346486                -0.289677   \n",
       "8759                         -0.346486                -0.289677   \n",
       "...                                ...                      ...   \n",
       "10407                        -0.346486                -0.289677   \n",
       "7443                         -0.346486                -0.289677   \n",
       "16022                        -0.346486                -0.289677   \n",
       "2569                         -0.346486                -0.289677   \n",
       "14084                        -0.346486                 3.452126   \n",
       "\n",
       "               hhs_geo_region_lzgpxyit  hhs_geo_region_mlyzmhmf  \\\n",
       "respondent_id                                                     \n",
       "358                          -0.438531                -0.303409   \n",
       "20097                        -0.438531                -0.303409   \n",
       "24982                         2.280338                -0.303409   \n",
       "12299                        -0.438531                -0.303409   \n",
       "8759                         -0.438531                -0.303409   \n",
       "...                                ...                      ...   \n",
       "10407                        -0.438531                -0.303409   \n",
       "7443                          2.280338                -0.303409   \n",
       "16022                         2.280338                -0.303409   \n",
       "2569                         -0.438531                -0.303409   \n",
       "14084                        -0.438531                -0.303409   \n",
       "\n",
       "               hhs_geo_region_oxchjgsf  hhs_geo_region_qufhixun  \\\n",
       "respondent_id                                                     \n",
       "358                           -0.34784                -0.363621   \n",
       "20097                         -0.34784                -0.363621   \n",
       "24982                         -0.34784                -0.363621   \n",
       "12299                         -0.34784                -0.363621   \n",
       "8759                          -0.34784                -0.363621   \n",
       "...                                ...                      ...   \n",
       "10407                         -0.34784                -0.363621   \n",
       "7443                          -0.34784                -0.363621   \n",
       "16022                         -0.34784                -0.363621   \n",
       "2569                          -0.34784                -0.363621   \n",
       "14084                         -0.34784                -0.363621   \n",
       "\n",
       "               census_msa_MSA, Principle City  census_msa_Non-MSA  \\\n",
       "respondent_id                                                       \n",
       "358                                 -0.644346            1.637401   \n",
       "20097                                1.551961           -0.610724   \n",
       "24982                               -0.644346            1.637401   \n",
       "12299                               -0.644346            1.637401   \n",
       "8759                                 1.551961           -0.610724   \n",
       "...                                       ...                 ...   \n",
       "10407                               -0.644346           -0.610724   \n",
       "7443                                -0.644346           -0.610724   \n",
       "16022                               -0.644346           -0.610724   \n",
       "2569                                -0.644346           -0.610724   \n",
       "14084                               -0.644346            1.637401   \n",
       "\n",
       "               employment_industry_atmlpfrs  employment_industry_cfqqtusy  \\\n",
       "respondent_id                                                               \n",
       "358                               -0.190343                     -0.112495   \n",
       "20097                             -0.190343                     -0.112495   \n",
       "24982                             -0.190343                      8.889248   \n",
       "12299                             -0.190343                     -0.112495   \n",
       "8759                              -0.190343                     -0.112495   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.190343                     -0.112495   \n",
       "7443                              -0.190343                     -0.112495   \n",
       "16022                             -0.190343                     -0.112495   \n",
       "2569                              -0.190343                     -0.112495   \n",
       "14084                             -0.190343                     -0.112495   \n",
       "\n",
       "               employment_industry_dotnnunm  employment_industry_fcxhlnwr  \\\n",
       "respondent_id                                                               \n",
       "358                               -0.083803                     -0.322168   \n",
       "20097                             -0.083803                     -0.322168   \n",
       "24982                             -0.083803                     -0.322168   \n",
       "12299                             -0.083803                      3.103972   \n",
       "8759                              -0.083803                     -0.322168   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.083803                     -0.322168   \n",
       "7443                              -0.083803                     -0.322168   \n",
       "16022                             -0.083803                     -0.322168   \n",
       "2569                              -0.083803                     -0.322168   \n",
       "14084                             -0.083803                      3.103972   \n",
       "\n",
       "               employment_industry_haxffmxo  employment_industry_ldnlellj  \\\n",
       "respondent_id                                                               \n",
       "358                               -0.075783                     -0.220312   \n",
       "20097                             -0.075783                     -0.220312   \n",
       "24982                             -0.075783                     -0.220312   \n",
       "12299                             -0.075783                     -0.220312   \n",
       "8759                              -0.075783                     -0.220312   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.075783                     -0.220312   \n",
       "7443                              -0.075783                     -0.220312   \n",
       "16022                             -0.075783                     -0.220312   \n",
       "2569                              -0.075783                     -0.220312   \n",
       "14084                             -0.075783                     -0.220312   \n",
       "\n",
       "               employment_industry_mcubkhph  employment_industry_mfikgejo  \\\n",
       "respondent_id                                                               \n",
       "358                               -0.102469                     -0.151763   \n",
       "20097                             -0.102469                     -0.151763   \n",
       "24982                             -0.102469                     -0.151763   \n",
       "12299                             -0.102469                     -0.151763   \n",
       "8759                              -0.102469                     -0.151763   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.102469                     -0.151763   \n",
       "7443                              -0.102469                     -0.151763   \n",
       "16022                             -0.102469                     -0.151763   \n",
       "2569                              -0.102469                     -0.151763   \n",
       "14084                             -0.102469                     -0.151763   \n",
       "\n",
       "               employment_industry_msuufmds  employment_industry_nduyfdeo  \\\n",
       "respondent_id                                                               \n",
       "358                               -0.065403                     -0.105686   \n",
       "20097                             -0.065403                     -0.105686   \n",
       "24982                             -0.065403                     -0.105686   \n",
       "12299                             -0.065403                     -0.105686   \n",
       "8759                              -0.065403                     -0.105686   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.065403                     -0.105686   \n",
       "7443                              -0.065403                     -0.105686   \n",
       "16022                             -0.065403                     -0.105686   \n",
       "2569                              -0.065403                     -0.105686   \n",
       "14084                             -0.065403                     -0.105686   \n",
       "\n",
       "               employment_industry_phxvnwax  employment_industry_pxcmvdjn  \\\n",
       "respondent_id                                                               \n",
       "358                               -0.055666                     -0.199527   \n",
       "20097                             -0.055666                     -0.199527   \n",
       "24982                             -0.055666                     -0.199527   \n",
       "12299                             -0.055666                     -0.199527   \n",
       "8759                              -0.055666                     -0.199527   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.055666                     -0.199527   \n",
       "7443                              -0.055666                     -0.199527   \n",
       "16022                             -0.055666                     -0.199527   \n",
       "2569                              -0.055666                     -0.199527   \n",
       "14084                             -0.055666                     -0.199527   \n",
       "\n",
       "               employment_industry_qnlwzans  employment_industry_rucpziij  \\\n",
       "respondent_id                                                               \n",
       "358                                -0.02164                     -0.138128   \n",
       "20097                              -0.02164                     -0.138128   \n",
       "24982                              -0.02164                     -0.138128   \n",
       "12299                              -0.02164                     -0.138128   \n",
       "8759                               -0.02164                     -0.138128   \n",
       "...                                     ...                           ...   \n",
       "10407                              -0.02164                     -0.138128   \n",
       "7443                               -0.02164                     -0.138128   \n",
       "16022                              -0.02164                     -0.138128   \n",
       "2569                               -0.02164                     -0.138128   \n",
       "14084                              -0.02164                     -0.138128   \n",
       "\n",
       "               employment_industry_saaquncn  employment_industry_unknown  \\\n",
       "respondent_id                                                              \n",
       "358                               -0.112068                    -0.996496   \n",
       "20097                             -0.112068                     1.003517   \n",
       "24982                             -0.112068                    -0.996496   \n",
       "12299                             -0.112068                    -0.996496   \n",
       "8759                              -0.112068                     1.003517   \n",
       "...                                     ...                          ...   \n",
       "10407                             -0.112068                     1.003517   \n",
       "7443                              -0.112068                     1.003517   \n",
       "16022                             -0.112068                     1.003517   \n",
       "2569                              -0.112068                     1.003517   \n",
       "14084                             -0.112068                    -0.996496   \n",
       "\n",
       "               employment_industry_vjjrobsf  employment_industry_wlfvacwt  \\\n",
       "respondent_id                                                               \n",
       "358                               -0.142976                     -0.092177   \n",
       "20097                             -0.142976                     -0.092177   \n",
       "24982                             -0.142976                     -0.092177   \n",
       "12299                             -0.142976                     -0.092177   \n",
       "8759                              -0.142976                     -0.092177   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.142976                     -0.092177   \n",
       "7443                              -0.142976                     -0.092177   \n",
       "16022                             -0.142976                     -0.092177   \n",
       "2569                              -0.142976                     -0.092177   \n",
       "14084                             -0.142976                     -0.092177   \n",
       "\n",
       "               employment_industry_wxleyezf  employment_industry_xicduogh  \\\n",
       "respondent_id                                                               \n",
       "358                                3.700533                     -0.180069   \n",
       "20097                             -0.270231                     -0.180069   \n",
       "24982                             -0.270231                     -0.180069   \n",
       "12299                             -0.270231                     -0.180069   \n",
       "8759                              -0.270231                     -0.180069   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.270231                     -0.180069   \n",
       "7443                              -0.270231                     -0.180069   \n",
       "16022                             -0.270231                     -0.180069   \n",
       "2569                              -0.270231                     -0.180069   \n",
       "14084                             -0.270231                     -0.180069   \n",
       "\n",
       "               employment_industry_xqicxuve  employment_occupation_ccgxvspp  \\\n",
       "respondent_id                                                                 \n",
       "358                               -0.142122                        -0.11419   \n",
       "20097                             -0.142122                        -0.11419   \n",
       "24982                             -0.142122                        -0.11419   \n",
       "12299                             -0.142122                        -0.11419   \n",
       "8759                              -0.142122                        -0.11419   \n",
       "...                                     ...                             ...   \n",
       "10407                             -0.142122                        -0.11419   \n",
       "7443                              -0.142122                        -0.11419   \n",
       "16022                             -0.142122                        -0.11419   \n",
       "2569                              -0.142122                        -0.11419   \n",
       "14084                             -0.142122                        -0.11419   \n",
       "\n",
       "               employment_occupation_cmhcxjea  employment_occupation_dcjcmpih  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.223447                       -0.075783   \n",
       "20097                               -0.223447                       -0.075783   \n",
       "24982                               -0.223447                       -0.075783   \n",
       "12299                               -0.223447                       -0.075783   \n",
       "8759                                -0.223447                       -0.075783   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.223447                       -0.075783   \n",
       "7443                                -0.223447                       -0.075783   \n",
       "16022                               -0.223447                       -0.075783   \n",
       "2569                                -0.223447                       -0.075783   \n",
       "14084                               -0.223447                       -0.075783   \n",
       "\n",
       "               employment_occupation_dlvbwzss  employment_occupation_emcorrxb  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.092435                        4.452369   \n",
       "20097                               -0.092435                       -0.224600   \n",
       "24982                               -0.092435                       -0.224600   \n",
       "12299                               -0.092435                       -0.224600   \n",
       "8759                                -0.092435                       -0.224600   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.092435                       -0.224600   \n",
       "7443                                -0.092435                       -0.224600   \n",
       "16022                               -0.092435                       -0.224600   \n",
       "2569                                -0.092435                       -0.224600   \n",
       "14084                               -0.092435                       -0.224600   \n",
       "\n",
       "               employment_occupation_haliazsg  employment_occupation_hfxkjkmi  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.106363                       -0.175304   \n",
       "20097                               -0.106363                       -0.175304   \n",
       "24982                               -0.106363                       -0.175304   \n",
       "12299                                9.401771                       -0.175304   \n",
       "8759                                -0.106363                       -0.175304   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.106363                       -0.175304   \n",
       "7443                                -0.106363                       -0.175304   \n",
       "16022                               -0.106363                       -0.175304   \n",
       "2569                                -0.106363                       -0.175304   \n",
       "14084                               -0.106363                       -0.175304   \n",
       "\n",
       "               employment_occupation_hodpvpew  employment_occupation_kldqjyjy  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.089559                       -0.136536   \n",
       "20097                               -0.089559                       -0.136536   \n",
       "24982                               -0.089559                        7.324066   \n",
       "12299                               -0.089559                       -0.136536   \n",
       "8759                                -0.089559                       -0.136536   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.089559                       -0.136536   \n",
       "7443                                -0.089559                       -0.136536   \n",
       "16022                               -0.089559                       -0.136536   \n",
       "2569                                -0.089559                       -0.136536   \n",
       "14084                               -0.089559                       -0.136536   \n",
       "\n",
       "               employment_occupation_mxkfnird  employment_occupation_oijqvulv  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.244698                       -0.115861   \n",
       "20097                               -0.244698                       -0.115861   \n",
       "24982                               -0.244698                       -0.115861   \n",
       "12299                               -0.244698                       -0.115861   \n",
       "8759                                -0.244698                       -0.115861   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.244698                       -0.115861   \n",
       "7443                                -0.244698                       -0.115861   \n",
       "16022                               -0.244698                       -0.115861   \n",
       "2569                                -0.244698                       -0.115861   \n",
       "14084                                4.086675                       -0.115861   \n",
       "\n",
       "               employment_occupation_pvmttkik  employment_occupation_qxajmpny  \\\n",
       "respondent_id                                                                   \n",
       "358                                  -0.06169                       -0.144503   \n",
       "20097                                -0.06169                       -0.144503   \n",
       "24982                                -0.06169                       -0.144503   \n",
       "12299                                -0.06169                       -0.144503   \n",
       "8759                                 -0.06169                       -0.144503   \n",
       "...                                       ...                             ...   \n",
       "10407                                -0.06169                       -0.144503   \n",
       "7443                                 -0.06169                       -0.144503   \n",
       "16022                                -0.06169                       -0.144503   \n",
       "2569                                 -0.06169                       -0.144503   \n",
       "14084                                -0.06169                       -0.144503   \n",
       "\n",
       "               employment_occupation_rcertsgn  employment_occupation_tfqavkke  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.101061                       -0.117099   \n",
       "20097                               -0.101061                       -0.117099   \n",
       "24982                               -0.101061                       -0.117099   \n",
       "12299                               -0.101061                       -0.117099   \n",
       "8759                                -0.101061                       -0.117099   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.101061                       -0.117099   \n",
       "7443                                -0.101061                       -0.117099   \n",
       "16022                               -0.101061                       -0.117099   \n",
       "2569                                -0.101061                       -0.117099   \n",
       "14084                               -0.101061                       -0.117099   \n",
       "\n",
       "               employment_occupation_ukymxvdu  employment_occupation_unknown  \\\n",
       "respondent_id                                                                  \n",
       "358                                 -0.117305                      -1.005962   \n",
       "20097                               -0.117305                       0.994073   \n",
       "24982                               -0.117305                      -1.005962   \n",
       "12299                               -0.117305                      -1.005962   \n",
       "8759                                -0.117305                       0.994073   \n",
       "...                                       ...                            ...   \n",
       "10407                               -0.117305                       0.994073   \n",
       "7443                                -0.117305                       0.994073   \n",
       "16022                               -0.117305                       0.994073   \n",
       "2569                                -0.117305                       0.994073   \n",
       "14084                               -0.117305                      -1.005962   \n",
       "\n",
       "               employment_occupation_uqqtjvyb  employment_occupation_vlluhbov  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.132753                       -0.116068   \n",
       "20097                               -0.132753                       -0.116068   \n",
       "24982                               -0.132753                       -0.116068   \n",
       "12299                               -0.132753                       -0.116068   \n",
       "8759                                -0.132753                       -0.116068   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.132753                       -0.116068   \n",
       "7443                                -0.132753                       -0.116068   \n",
       "16022                               -0.132753                       -0.116068   \n",
       "2569                                -0.132753                       -0.116068   \n",
       "14084                               -0.132753                       -0.116068   \n",
       "\n",
       "               employment_occupation_xgwztkwe  employment_occupation_xqwwgdyp  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.201799                       -0.137069   \n",
       "20097                               -0.201799                       -0.137069   \n",
       "24982                               -0.201799                       -0.137069   \n",
       "12299                               -0.201799                       -0.137069   \n",
       "8759                                -0.201799                       -0.137069   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.201799                       -0.137069   \n",
       "7443                                -0.201799                       -0.137069   \n",
       "16022                               -0.201799                       -0.137069   \n",
       "2569                                -0.201799                       -0.137069   \n",
       "14084                               -0.201799                       -0.137069   \n",
       "\n",
       "               employment_occupation_xtkaffoo  employment_occupation_xzmlyyjv  \\\n",
       "respondent_id                                                                   \n",
       "358                                 -0.266926                       -0.095227   \n",
       "20097                               -0.266926                       -0.095227   \n",
       "24982                               -0.266926                       -0.095227   \n",
       "12299                               -0.266926                       -0.095227   \n",
       "8759                                -0.266926                       -0.095227   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.266926                       -0.095227   \n",
       "7443                                -0.266926                       -0.095227   \n",
       "16022                               -0.266926                       -0.095227   \n",
       "2569                                -0.266926                       -0.095227   \n",
       "14084                               -0.266926                       -0.095227   \n",
       "\n",
       "               doctor_recc_seasonal age_group_45_to_54 Years  \\\n",
       "respondent_id                                                  \n",
       "358                                                -0.231078   \n",
       "20097                                              -0.231078   \n",
       "24982                                               4.327541   \n",
       "12299                                              -0.231078   \n",
       "8759                                                4.327541   \n",
       "...                                                      ...   \n",
       "10407                                              -0.231078   \n",
       "7443                                               -0.231078   \n",
       "16022                                              -0.231078   \n",
       "2569                                               -0.231078   \n",
       "14084                                              -0.231078   \n",
       "\n",
       "               doctor_recc_seasonal education_Some College  \\\n",
       "respondent_id                                                \n",
       "358                                              -0.297110   \n",
       "20097                                            -0.297110   \n",
       "24982                                             3.365759   \n",
       "12299                                             3.365759   \n",
       "8759                                             -0.297110   \n",
       "...                                                    ...   \n",
       "10407                                            -0.297110   \n",
       "7443                                              3.365759   \n",
       "16022                                            -0.297110   \n",
       "2569                                             -0.297110   \n",
       "14084                                            -0.297110   \n",
       "\n",
       "               doctor_recc_seasonal sex_Male  \\\n",
       "respondent_id                                  \n",
       "358                                -0.348854   \n",
       "20097                              -0.348854   \n",
       "24982                               2.866531   \n",
       "12299                              -0.348854   \n",
       "8759                               -0.348854   \n",
       "...                                      ...   \n",
       "10407                              -0.348854   \n",
       "7443                               -0.348854   \n",
       "16022                              -0.348854   \n",
       "2569                               -0.348854   \n",
       "14084                              -0.348854   \n",
       "\n",
       "               doctor_recc_seasonal income_poverty_unknown  \\\n",
       "respondent_id                                                \n",
       "358                                              -0.218202   \n",
       "20097                                            -0.218202   \n",
       "24982                                            -0.218202   \n",
       "12299                                            -0.218202   \n",
       "8759                                             -0.218202   \n",
       "...                                                    ...   \n",
       "10407                                             4.582913   \n",
       "7443                                             -0.218202   \n",
       "16022                                            -0.218202   \n",
       "2569                                             -0.218202   \n",
       "14084                                            -0.218202   \n",
       "\n",
       "               age_group_Over_65 education_College Graduate  \\\n",
       "respondent_id                                                 \n",
       "358                                               -0.315486   \n",
       "20097                                             -0.315486   \n",
       "24982                                             -0.315486   \n",
       "12299                                             -0.315486   \n",
       "8759                                              -0.315486   \n",
       "...                                                     ...   \n",
       "10407                                             -0.315486   \n",
       "7443                                              -0.315486   \n",
       "16022                                             -0.315486   \n",
       "2569                                               3.169709   \n",
       "14084                                             -0.315486   \n",
       "\n",
       "               age_group_Over_65 sex_Male  seasonal_vaccine  \n",
       "respondent_id                                                \n",
       "358                             -0.320039                 0  \n",
       "20097                           -0.320039                 0  \n",
       "24982                           -0.320039                 1  \n",
       "12299                           -0.320039                 1  \n",
       "8759                            -0.320039                 1  \n",
       "...                                   ...               ...  \n",
       "10407                           -0.320039                 1  \n",
       "7443                            -0.320039                 1  \n",
       "16022                           -0.320039                 1  \n",
       "2569                            -0.320039                 1  \n",
       "14084                           -0.320039                 1  \n",
       "\n",
       "[26707 rows x 130 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates a downsampled object storing the data with no scaling or interactions.\n",
    "unscaled = DataPreprocessor(df, target_col2, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "unscaled.data_preprocessing(balance_class=False, scale_type=False)\n",
    "\n",
    "#creates a downsampled object storing the data with scaling and no interactions.\n",
    "scaled = DataPreprocessor(df, target_col2, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "scaled.data_preprocessing(balance_class=False, scale_type=\"standard\")\n",
    "\n",
    "#creates a downsampled object storing the data with scaling and no interactions and minimizes features.\n",
    "select_features = ['opinion_seas_vacc_effective_5.0', 'doctor_recc_seasonal', 'opinion_seas_risk_4.0', 'age_group_Over_65',\n",
    "                   'opinion_seas_risk_5.0', 'household_adults', 'household_children', 'chronic_med_condition']\n",
    "reduced = DataPreprocessor(df, target_col2, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "reduced.data_preprocessing(balance_class=False, scale_type=\"standard\")\n",
    "reduced.column_drop(reduced.cols)\n",
    "reduced.column_drop(select_features, reverse=True)\n",
    "\n",
    "#creates a downsampled object storing the data with scaling select interactions.\n",
    "interactions = DataPreprocessor(df, target_col2, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "interactions.data_preprocessing(balance_class=False, scale_type=\"standard\", poly_degree=2)\n",
    "interactions.column_drop(interactions.cols_polynomial)\n",
    "interactions.column_drop(['doctor_recc_seasonal education_Some College',\n",
    "                  'doctor_recc_seasonal sex_Male',\n",
    "                          'age_group_Over_65 education_College Graduate',\n",
    "                          'age_group_Over_65 sex_Male',\n",
    "                          'doctor_recc_seasonal age_group_45_to_54 Years',\n",
    "                          'doctor_recc_seasonal income_poverty_unknown'], reverse=True)\n",
    "interactions.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with the dummy variables and the downsample class imblanace correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the Evaluation DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Details':[],\n",
    "                           'Accuracy':[],\n",
    "                           'Precision':[],\n",
    "                           'FP':[],\n",
    "                           'Recall':[],\n",
    "                           'FN':[],\n",
    "                           'F1-Score':[],\n",
    "                           'AUC':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"2\"></span>2. Logistic Regression\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_to_df(model, X_test, y_test, eval_df, title, description):\n",
    "    \"\"\"Evaluates a model, updating a dataframe that stores the results.\"\"\"\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(f'{title}: {description}')\n",
    "    print('Confusion Matrix :')\n",
    "    print(cm)\n",
    "    print('Test Accuracy Score :',metrics.accuracy_score(y_test, y_pred))\n",
    "    print('Report : ')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    acc = float(format(metrics.accuracy_score(y_test, y_pred, sample_weight=None), '.3f'))\n",
    "    prec = float(format(metrics.precision_score(y_test, y_pred),'.3f'))\n",
    "    fp = cm[0,1]\n",
    "    rec = float(format(metrics.recall_score(y_test, y_pred),'.3f'))\n",
    "    fn = cm[1,0]\n",
    "    auc = float(format(metrics.roc_auc_score(y_test, y_pred),'.3f'))\n",
    "    f1 = float(format(metrics.f1_score(y_test, y_pred),'.3f'))\n",
    "\n",
    "    r = eval_df.shape[0]\n",
    "    eval_df.loc[r] = [title,description,acc,prec,fp,rec,fn,auc,f1]\n",
    "    return eval_df.sort_values(by = 'AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression-1: All Features, Not Scaled\n",
      "Confusion Matrix :\n",
      "[[2384  491]\n",
      " [ 618 1849]]\n",
      "Test Accuracy Score : 0.7923998502433546\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      2875\n",
      "           1       0.79      0.75      0.77      2467\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.79</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                   Details  Accuracy  Precision  \\\n",
       "0  Logistic Regression-1  All Features, Not Scaled     0.792       0.79   \n",
       "\n",
       "      FP  Recall     FN  F1-Score    AUC  \n",
       "0  491.0   0.749  618.0     0.789  0.769  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logisitic Regression 1: All Features, Not Scaled\n",
    "logreg1 = LogisticRegression().fit(unscaled.get_X_train(), unscaled.y_train)\n",
    "\n",
    "evaluate_to_df(logreg1, unscaled.get_X_test(), unscaled.y_test, evaluation, 'Logistic Regression-1', 'All Features, Not Scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression-2: All Features, Scaled\n",
      "Confusion Matrix :\n",
      "[[2381  494]\n",
      " [ 614 1853]]\n",
      "Test Accuracy Score : 0.7925870460501685\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      2875\n",
      "           1       0.79      0.75      0.77      2467\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n",
      "Logistic Regression-3: Select Features, Scaled\n",
      "Confusion Matrix :\n",
      "[[2153  722]\n",
      " [1220 1247]]\n",
      "Test Accuracy Score : 0.636465743167353\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69      2875\n",
      "           1       0.63      0.51      0.56      2467\n",
      "\n",
      "    accuracy                           0.64      5342\n",
      "   macro avg       0.64      0.63      0.63      5342\n",
      "weighted avg       0.64      0.64      0.63      5342\n",
      "\n",
      "Logistic Regression-4: All Features, Scaled, with Interactions\n",
      "Confusion Matrix :\n",
      "[[2380  495]\n",
      " [ 624 1843]]\n",
      "Test Accuracy Score : 0.7905278921752152\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      2875\n",
      "           1       0.79      0.75      0.77      2467\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "1  Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "   Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1      0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0      0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3      0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "2      0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logisitic Regression 2: All Features, Scaled\n",
    "logreg2 = LogisticRegression().fit(scaled.get_X_train(), scaled.y_train)\n",
    "evaluate_to_df(logreg2, scaled.get_X_test(), scaled.y_test, evaluation, 'Logistic Regression-2', 'All Features, Scaled')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "#Logistic Regression: Select Features, Scaled\n",
    "logreg3 = LogisticRegression().fit(reduced.get_X_train(), reduced.y_train)\n",
    "evaluate_to_df(logreg3, reduced.get_X_test(), reduced.y_test, evaluation, 'Logistic Regression-3', 'Select Features, Scaled')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "#Logistic Regression: Select Features, Scaled, with Interactions\n",
    "logreg4 = LogisticRegression().fit(interactions.get_X_train(), interactions.y_train)\n",
    "evaluate_to_df(logreg4, interactions.get_X_test(), interactions.y_test, evaluation, 'Logistic Regression-4', 'All Features, Scaled, with Interactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"3\"></span>3. K-Nearest Neighbor (K-NN)\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor: Baseline K=1\n",
      "Confusion Matrix :\n",
      "[[2163  712]\n",
      " [ 844 1623]]\n",
      "Test Accuracy Score : 0.7087233245975291\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.74      2875\n",
      "           1       0.70      0.66      0.68      2467\n",
      "\n",
      "    accuracy                           0.71      5342\n",
      "   macro avg       0.71      0.71      0.71      5342\n",
      "weighted avg       0.71      0.71      0.71      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "1  Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "   Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1      0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0      0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3      0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "4      0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "2      0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier()\n",
    "# Fit the classifier\n",
    "knn1.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(knn1, interactions.get_X_test(), interactions.y_test, evaluation, 'K-Nearest Neighbor', 'Baseline K=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X_train, y_train, X_test, y_test, min_k=1, max_k=25):\n",
    "    best_k = 0\n",
    "    best_score = 0.0\n",
    "    for k in range(min_k, max_k+1, 2):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        preds = knn.predict(X_test)\n",
    "        f1 = metrics.f1_score(y_test, preds)\n",
    "        if f1 > best_score:\n",
    "            best_k = k\n",
    "            best_score = f1\n",
    "    print(\"Best Value for k: {}\".format(best_k))\n",
    "    print(\"F1-Score: {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value for k: 9\n",
      "F1-Score: 0.6918690601900739\n"
     ]
    }
   ],
   "source": [
    "find_best_k(interactions.get_X_train(), interactions.y_train, interactions.get_X_test(), interactions.y_test, min_k=1, max_k=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6654452790119493, 0.645511776277989, 0.6913354344340027, 0.6850918247372408, 0.7079882587855718, 0.7046047198596215, 0.7184381953390526, 0.7143343026474295, 0.7257101228213287, 0.7208079407750783]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = list(range(1, 11))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(interactions.get_X_train(), interactions.y_train)\n",
    "    y_predict = knn.predict(interactions.get_X_test())\n",
    "    score = metrics.f1_score(interactions.y_test, y_predict, average='weighted')\n",
    "    k_scores.append(score)\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Optimized, K = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor: Optimized K=9\n",
      "Confusion Matrix :\n",
      "[[2245  630]\n",
      " [ 829 1638]]\n",
      "Test Accuracy Score : 0.72688131785848\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.78      0.75      2875\n",
      "           1       0.72      0.66      0.69      2467\n",
      "\n",
      "    accuracy                           0.73      5342\n",
      "   macro avg       0.73      0.72      0.72      5342\n",
      "weighted avg       0.73      0.73      0.73      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "1  Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "   Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1      0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0      0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3      0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "5      0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4      0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "2      0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate KNeighborsClassifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=9)\n",
    "# Fit the classifier\n",
    "knn2.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(knn2, interactions.get_X_test(), interactions.y_test, evaluation, 'K-Nearest Neighbor', 'Optimized K=9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"4\"></span>4. Decision Tree\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree-1: Baseline\n",
      "Confusion Matrix :\n",
      "[[2032  843]\n",
      " [ 826 1641]]\n",
      "Test Accuracy Score : 0.6875701984275552\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      2875\n",
      "           1       0.66      0.67      0.66      2467\n",
      "\n",
      "    accuracy                           0.69      5342\n",
      "   macro avg       0.69      0.69      0.69      5342\n",
      "weighted avg       0.69      0.69      0.69      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "1  Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6        Decision Tree-1                                 Baseline     0.688   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "   Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1      0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0      0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3      0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "5      0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4      0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6      0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2      0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a DecisionTreeClassifier\n",
    "dt1 = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# fit the model\n",
    "dt1.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(dt1, interactions.get_X_test(), interactions.y_test, evaluation, 'Decision Tree-1', 'Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['opinion_seas_vacc_effective_5.0', 0.13479197245437696],\n",
       "       ['doctor_recc_seasonal', 0.09144543319646882],\n",
       "       ['opinion_seas_risk_4.0', 0.028665419051574312],\n",
       "       ['age_group_Over_65', 0.024219874183675452],\n",
       "       ['opinion_seas_risk_5.0', 0.021303855023276166],\n",
       "       ['household_adults', 0.018899343811409845],\n",
       "       ['household_children', 0.015484617089010697],\n",
       "       ['chronic_med_condition', 0.01524968144656484]], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance\n",
    "importance = pd.DataFrame(dt1.feature_importances_, index=interactions.get_X_train().columns).reset_index().sort_values(by = 0, ascending=False)\n",
    "importance.head(8).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(model, df, figsize=(14, 12), palette=None, font_scale=1, ascending=False, rows=12, style=\"darkgrid\"):\n",
    "    sns.set_style(style)\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    sns.set(font_scale=font_scale)\n",
    "    importance = pd.DataFrame(model.feature_importances_, index=df.columns).reset_index()\n",
    "    importance.columns = pd.Index([\"Feature\", \"Importance\"])\n",
    "    sns.barplot(y=\"Feature\", x=\"Importance\", data=importance.sort_values(\"Importance\",ascending=ascending).iloc[0:rows],\n",
    "                palette=palette, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance Graph\n",
    "pal = sns.color_palette((\"#102CA8\",))\n",
    "show_feature_importances(dt1, interactions.get_X_train(), figsize=(14, 12), palette=pal, font_scale=1, ascending=False, rows=12, style=\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Ideal Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6776971682658554, 0.721226304703955, 0.726421717762696, 0.7310554645448162, 0.7479054528434356, 0.7511350339340043, 0.756704891177159, 0.753007254856073, 0.7494500351041422]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = cross_val_score(dt1, interactions.get_X_train(), interactions.y_train, cv = 5)\n",
    "score.mean()\n",
    "depth_range = range(1,10)\n",
    "val = []\n",
    "for depth in depth_range:\n",
    "    ctree = DecisionTreeClassifier(max_depth = depth)\n",
    "    depth_score = cross_val_score(ctree, interactions.get_X_train(), interactions.y_train, cv = 5)\n",
    "    val.append(depth_score.mean())\n",
    "print(val)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(depth_range, val)\n",
    "plt.xlabel('range of depth')\n",
    "plt.ylabel('cross validated values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Decision Tree: Depth 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree-2: Optimized: Depth 7\n",
      "Confusion Matrix :\n",
      "[[2308  567]\n",
      " [ 719 1748]]\n",
      "Test Accuracy Score : 0.7592661924372894\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78      2875\n",
      "           1       0.76      0.71      0.73      2467\n",
      "\n",
      "    accuracy                           0.76      5342\n",
      "   macro avg       0.76      0.76      0.76      5342\n",
      "weighted avg       0.76      0.76      0.76      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "1  Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "7        Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6        Decision Tree-1                                 Baseline     0.688   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "   Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1      0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0      0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3      0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "7      0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "5      0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4      0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6      0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2      0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a DecisionTreeClassifier\n",
    "dt2 = DecisionTreeClassifier(criterion='gini', max_depth=7)\n",
    "\n",
    "# fit the model\n",
    "dt2.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(dt2, interactions.get_X_test(), interactions.y_test, evaluation, 'Decision Tree-2', 'Optimized: Depth 7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Depth 7 with Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree-3: Depth 7, Select Features\n",
      "Confusion Matrix :\n",
      "[[2346  529]\n",
      " [ 763 1704]]\n",
      "Test Accuracy Score : 0.7581430175964058\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78      2875\n",
      "           1       0.76      0.69      0.73      2467\n",
      "\n",
      "    accuracy                           0.76      5342\n",
      "   macro avg       0.76      0.75      0.75      5342\n",
      "weighted avg       0.76      0.76      0.76      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "1  Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "7        Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "8        Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6        Decision Tree-1                                 Baseline     0.688   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "   Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1      0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0      0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3      0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "7      0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "8      0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5      0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4      0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6      0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2      0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt3 = DecisionTreeClassifier(criterion='gini', max_depth=7)\n",
    "\n",
    "# fit the model\n",
    "dt3.fit(reduced.get_X_train(), reduced.y_train)\n",
    "\n",
    "evaluate_to_df(dt3, reduced.get_X_test(), reduced.y_test, evaluation, 'Decision Tree-3', 'Depth 7, Select Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"5\"></span>5. Random Forest\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest-1: 100 Est, Max Depth 5\n",
      "Confusion Matrix :\n",
      "[[2388  487]\n",
      " [ 768 1699]]\n",
      "Test Accuracy Score : 0.7650692624485211\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79      2875\n",
      "           1       0.78      0.69      0.73      2467\n",
      "\n",
      "    accuracy                           0.77      5342\n",
      "   macro avg       0.77      0.76      0.76      5342\n",
      "weighted avg       0.77      0.77      0.76      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "1  Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "7        Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9        Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8        Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6        Decision Tree-1                                 Baseline     0.688   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "   Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1      0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0      0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3      0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "7      0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9      0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8      0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5      0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4      0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6      0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2      0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1 = RandomForestClassifier(n_estimators=100, max_depth= 5)\n",
    "forest1.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(forest1, interactions.get_X_test(), interactions.y_test, evaluation, 'Random Forest-1', '100 Est, Max Depth 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Optimization: GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(max_depth=5),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 6, 10],\n",
       "                         'min_samples_leaf': [2, 3, 5, 7],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 30, 100]})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 6, 10],\n",
    "    'min_samples_split': [ 2, 5, 10],\n",
    "    'min_samples_leaf': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "#Instantiate the gridsearch object\n",
    "rf_grid_search = GridSearchCV(forest1, param_grid, cv=3)\n",
    "\n",
    "# Fit to the data\n",
    "rf_grid_search.fit(interactions.get_X_train(), interactions.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest-2: Optimized Hyperparameters\n",
      "Confusion Matrix :\n",
      "[[2328  547]\n",
      " [ 609 1858]]\n",
      "Test Accuracy Score : 0.7836016473231\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      2875\n",
      "           1       0.77      0.75      0.76      2467\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.773</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "1   Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.784   \n",
       "7         Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8         Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6         Decision Tree-1                                 Baseline     0.688   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "    Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1       0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0       0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3       0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "10      0.773  547.0   0.753   609.0     0.781  0.763  \n",
       "7       0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9       0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8       0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5       0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4       0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6       0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2       0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
    "                                              class_weight=None,\n",
    "                                              criterion='gini', max_depth=None,\n",
    "                                              max_features='auto',\n",
    "                                              max_leaf_nodes=None,\n",
    "                                              max_samples=None,\n",
    "                                              min_impurity_decrease=0.0,\n",
    "                                              min_impurity_split=None,\n",
    "                                              min_samples_leaf=2,\n",
    "                                              min_samples_split=5,\n",
    "                                              min_weight_fraction_leaf=0.0,\n",
    "                                              n_estimators=100,\n",
    "                                              oob_score=False,\n",
    "                                              random_state=None, verbose=0,\n",
    "                                              warm_start=False)\n",
    "forest2.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(forest2, interactions.get_X_test(), interactions.y_test, evaluation, 'Random Forest-2', 'Optimized Hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"6\"></span>6. AdaBoost\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost-1: Baseline\n",
      "Confusion Matrix :\n",
      "[[2383  492]\n",
      " [ 641 1826]]\n",
      "Test Accuracy Score : 0.7879071508798203\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81      2875\n",
      "           1       0.79      0.74      0.76      2467\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.78      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.773</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.788</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "1   Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.784   \n",
       "11             AdaBoost-1                                 Baseline     0.788   \n",
       "7         Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8         Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6         Decision Tree-1                                 Baseline     0.688   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "    Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1       0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0       0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3       0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "10      0.773  547.0   0.753   609.0     0.781  0.763  \n",
       "11      0.788  492.0   0.740   641.0     0.785  0.763  \n",
       "7       0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9       0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8       0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5       0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4       0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6       0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2       0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_clf = AdaBoostClassifier(random_state=42)\n",
    "ada1 = adaboost_clf.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(ada1, interactions.get_X_test(), interactions.y_test, evaluation, 'AdaBoost-1', 'Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Optimization: GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "base_estimator: DecisionTreeClassifier(max_depth=1)\n",
      "learning_rate: 0.2\n",
      "n_estimators: 250\n",
      "\n",
      "Training Accuracy: 77.84%\n",
      "Validation accuracy: 78.29%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.2],\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=5)],\n",
    "    'n_estimators': [5, 30, 100, 250],\n",
    "}\n",
    "\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "grid_ada = GridSearchCV(ada_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_ada.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "best_parameters = grid_ada.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_ada.predict(interactions.get_X_train())\n",
    "val_preds = grid_ada.predict(interactions.get_X_test())\n",
    "training_accuracy = accuracy_score(interactions.y_train, training_preds)\n",
    "val_accuracy = accuracy_score(interactions.y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost-2: Optimized\n",
      "Confusion Matrix :\n",
      "[[2387  488]\n",
      " [ 672 1795]]\n",
      "Test Accuracy Score : 0.7828528640958442\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.80      2875\n",
      "           1       0.79      0.73      0.76      2467\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.773</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.788</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.786</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "1   Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.784   \n",
       "11             AdaBoost-1                                 Baseline     0.788   \n",
       "12             AdaBoost-2                                Optimized     0.783   \n",
       "7         Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8         Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6         Decision Tree-1                                 Baseline     0.688   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "    Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1       0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0       0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3       0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "10      0.773  547.0   0.753   609.0     0.781  0.763  \n",
       "11      0.788  492.0   0.740   641.0     0.785  0.763  \n",
       "12      0.786  488.0   0.728   672.0     0.779  0.756  \n",
       "7       0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9       0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8       0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5       0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4       0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6       0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2       0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best'), learning_rate=0.2, n_estimators=250, random_state=42)\n",
    "ada2 = adaboost_clf.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(ada2, interactions.get_X_test(), interactions.y_test, evaluation, 'AdaBoost-2', 'Optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"7\"></span>7. XGBoost\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = interactions.get_X_train().rename(columns=lambda x: x.replace('<', '_'))\n",
    "X_test_scaled = interactions.get_X_test().rename(columns=lambda x: x.replace('<', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoosting-1: Baseline\n",
      "Confusion Matrix :\n",
      "[[2312  563]\n",
      " [ 608 1859]]\n",
      "Test Accuracy Score : 0.7807937102208911\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.80      0.80      2875\n",
      "           1       0.77      0.75      0.76      2467\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.773</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.788</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.768</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.786</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "1   Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.784   \n",
       "11             AdaBoost-1                                 Baseline     0.788   \n",
       "13           XGBoosting-1                                 Baseline     0.781   \n",
       "12             AdaBoost-2                                Optimized     0.783   \n",
       "7         Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8         Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6         Decision Tree-1                                 Baseline     0.688   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "    Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "1       0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0       0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3       0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "10      0.773  547.0   0.753   609.0     0.781  0.763  \n",
       "11      0.788  492.0   0.740   641.0     0.785  0.763  \n",
       "13      0.768  563.0   0.754   608.0     0.779  0.760  \n",
       "12      0.786  488.0   0.728   672.0     0.779  0.756  \n",
       "7       0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9       0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8       0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5       0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4       0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6       0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2       0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = xgb.XGBClassifier()\n",
    "clf1.fit(X_train_scaled, interactions.y_train)\n",
    "\n",
    "evaluate_to_df(clf1, X_test_scaled, interactions.y_test, evaluation, 'XGBoosting-1', 'Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Optimization: GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "colsample_bytree: 0.4\n",
      "learning_rate: 0.1\n",
      "max_depth: 3\n",
      "min_child_weight: 1\n",
      "n_estimators: 300\n",
      "\n",
      "Training Accuracy: 79.93%\n",
      "Validation accuracy: 79.31%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators':[100,300,500],\n",
    "              'learning_rate':[0.1,0.5,0.01],\n",
    "              'max_depth':[3,5,7],\n",
    "              'colsample_bytree':[0.5,0.4,0.3],\n",
    "              'min_child_weight':[1,2,3]\n",
    "             }\n",
    "\n",
    "clf_xg = xgb.XGBClassifier()\n",
    "grid_clf = GridSearchCV(clf_xg, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_clf.fit(X_train_scaled, interactions.y_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_clf.predict(X_train_scaled)\n",
    "val_preds = grid_clf.predict(X_test_scaled)\n",
    "training_accuracy = accuracy_score(interactions.y_train, training_preds)\n",
    "val_accuracy = accuracy_score(interactions.y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoosting-2: Optimized\n",
      "Confusion Matrix :\n",
      "[[2382  493]\n",
      " [ 612 1855]]\n",
      "Test Accuracy Score : 0.7931486334706103\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      2875\n",
      "           1       0.79      0.75      0.77      2467\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoosting-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>493.0</td>\n",
       "      <td>0.752</td>\n",
       "      <td>612.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.773</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.788</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.768</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.786</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "14           XGBoosting-2                                Optimized     0.793   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.784   \n",
       "11             AdaBoost-1                                 Baseline     0.788   \n",
       "13           XGBoosting-1                                 Baseline     0.781   \n",
       "12             AdaBoost-2                                Optimized     0.783   \n",
       "7         Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8         Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6         Decision Tree-1                                 Baseline     0.688   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "\n",
       "    Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "14      0.790  493.0   0.752   612.0     0.790  0.771  \n",
       "1       0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0       0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3       0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "10      0.773  547.0   0.753   609.0     0.781  0.763  \n",
       "11      0.788  492.0   0.740   641.0     0.785  0.763  \n",
       "13      0.768  563.0   0.754   608.0     0.779  0.760  \n",
       "12      0.786  488.0   0.728   672.0     0.779  0.756  \n",
       "7       0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9       0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8       0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5       0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4       0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6       0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2       0.633  722.0   0.505  1220.0     0.627  0.562  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = xgb.XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=300, min_child_weight=1, colsample_bytree=0.4)\n",
    "clf2.fit(X_train_scaled, interactions.y_train)\n",
    "\n",
    "evaluate_to_df(clf2, X_test_scaled, interactions.y_test, evaluation, 'XGBoosting-2', 'Optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"8\"></span>8. Support Vector Machine\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Poly, c=.01\n",
      "Confusion Matrix :\n",
      "[[2870    5]\n",
      " [2439   28]]\n",
      "Test Accuracy Score : 0.5424934481467615\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70      2875\n",
      "           1       0.85      0.01      0.02      2467\n",
      "\n",
      "    accuracy                           0.54      5342\n",
      "   macro avg       0.69      0.50      0.36      5342\n",
      "weighted avg       0.68      0.54      0.39      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoosting-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>493.0</td>\n",
       "      <td>0.752</td>\n",
       "      <td>612.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.773</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.788</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.768</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.786</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Poly, c=.01</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.848</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "14           XGBoosting-2                                Optimized     0.793   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.784   \n",
       "11             AdaBoost-1                                 Baseline     0.788   \n",
       "13           XGBoosting-1                                 Baseline     0.781   \n",
       "12             AdaBoost-2                                Optimized     0.783   \n",
       "7         Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8         Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6         Decision Tree-1                                 Baseline     0.688   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "15                    SVM                              Poly, c=.01     0.542   \n",
       "\n",
       "    Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "14      0.790  493.0   0.752   612.0     0.790  0.771  \n",
       "1       0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0       0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3       0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "10      0.773  547.0   0.753   609.0     0.781  0.763  \n",
       "11      0.788  492.0   0.740   641.0     0.785  0.763  \n",
       "13      0.768  563.0   0.754   608.0     0.779  0.760  \n",
       "12      0.786  488.0   0.728   672.0     0.779  0.756  \n",
       "7       0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9       0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8       0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5       0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4       0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6       0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2       0.633  722.0   0.505  1220.0     0.627  0.562  \n",
       "15      0.848    5.0   0.011  2439.0     0.505  0.022  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc1 = SVC(kernel='poly', C=.01)  \n",
    "svc1.fit(interactions.get_X_train(), interactions.y_train) \n",
    "\n",
    "evaluate_to_df(svc1, interactions.get_X_test(), interactions.y_test, evaluation, 'SVM', 'Poly, c=.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"9\"></span>9. Best Model\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Accuracy and Area Under the Curve (AUC), our best model appears to be the optimized XG Boost with an accuracy of 0.793, a harmonic F1-Score of .790 and an Area Under the Curve of 0.771."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoosting-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>493.0</td>\n",
       "      <td>0.752</td>\n",
       "      <td>612.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.790</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.751</td>\n",
       "      <td>614.0</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.790</td>\n",
       "      <td>491.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>618.0</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.788</td>\n",
       "      <td>495.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>624.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.773</td>\n",
       "      <td>547.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>609.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.788</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.740</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.768</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.786</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 7</td>\n",
       "      <td>0.759</td>\n",
       "      <td>0.755</td>\n",
       "      <td>567.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>719.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.777</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.689</td>\n",
       "      <td>768.0</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 7, Select Features</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.763</td>\n",
       "      <td>529.0</td>\n",
       "      <td>0.691</td>\n",
       "      <td>763.0</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.722</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.664</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.695</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.658</td>\n",
       "      <td>844.0</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.661</td>\n",
       "      <td>843.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.633</td>\n",
       "      <td>722.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Poly, c=.01</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.848</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "14           XGBoosting-2                                Optimized     0.793   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.793   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.792   \n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.791   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.784   \n",
       "11             AdaBoost-1                                 Baseline     0.788   \n",
       "13           XGBoosting-1                                 Baseline     0.781   \n",
       "12             AdaBoost-2                                Optimized     0.783   \n",
       "7         Decision Tree-2                       Optimized: Depth 7     0.759   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.765   \n",
       "8         Decision Tree-3                 Depth 7, Select Features     0.758   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.727   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.709   \n",
       "6         Decision Tree-1                                 Baseline     0.688   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.636   \n",
       "15                    SVM                              Poly, c=.01     0.542   \n",
       "\n",
       "    Precision     FP  Recall      FN  F1-Score    AUC  \n",
       "14      0.790  493.0   0.752   612.0     0.790  0.771  \n",
       "1       0.790  494.0   0.751   614.0     0.790  0.770  \n",
       "0       0.790  491.0   0.749   618.0     0.789  0.769  \n",
       "3       0.788  495.0   0.747   624.0     0.787  0.767  \n",
       "10      0.773  547.0   0.753   609.0     0.781  0.763  \n",
       "11      0.788  492.0   0.740   641.0     0.785  0.763  \n",
       "13      0.768  563.0   0.754   608.0     0.779  0.760  \n",
       "12      0.786  488.0   0.728   672.0     0.779  0.756  \n",
       "7       0.755  567.0   0.709   719.0     0.756  0.731  \n",
       "9       0.777  487.0   0.689   768.0     0.760  0.730  \n",
       "8       0.763  529.0   0.691   763.0     0.753  0.725  \n",
       "5       0.722  630.0   0.664   829.0     0.722  0.692  \n",
       "4       0.695  712.0   0.658   844.0     0.705  0.676  \n",
       "6       0.661  843.0   0.665   826.0     0.686  0.663  \n",
       "2       0.633  722.0   0.505  1220.0     0.627  0.562  \n",
       "15      0.848    5.0   0.011  2439.0     0.505  0.022  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by = 'AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_graph(model, X_test, y_test, font_scale=2, style=\"darkgrid\", palette=None, figsize=(14, 12)):\n",
    "    sns.set_style(style)\n",
    "    sns.set(font_scale=font_scale)\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    converted_pal = matplotlib.colors.ListedColormap(sns.color_palette(palette))\n",
    "    plot_confusion_matrix(model, X_test, y_test, cmap=converted_pal, ax=ax)\n",
    "    for text in ax.texts:\n",
    "        label = text.get_text()\n",
    "        label = int(float(label))\n",
    "        text.set_text(f\"{label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression 2: All Features, Scaled\n",
      "Confusion Matrix :\n",
      "[[2382  493]\n",
      " [ 612 1855]]\n",
      "Test Accuracy Score : 0.7931486334706103\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81      2875\n",
      "           1       0.79      0.75      0.77      2467\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.79      0.79      0.79      5342\n",
      "weighted avg       0.79      0.79      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#XG Boost: Select Features, Scaled, with Interactions optimized hyperparameters\n",
    "xgb_pred1 = clf2.predict(X_test_scaled)\n",
    "\n",
    "cm = metrics.confusion_matrix(interactions.y_test, xgb_pred1)\n",
    "print('Logisitic Regression 2: All Features, Scaled')\n",
    "print('Confusion Matrix :')\n",
    "print(cm) \n",
    "print('Test Accuracy Score :',metrics.accuracy_score(interactions.y_test, xgb_pred1))\n",
    "print('Report : ')\n",
    "print(classification_report(interactions.y_test, xgb_pred1))\n",
    "\n",
    "palette = sns.light_palette(\"#EE823E\")\n",
    "confusion_matrix_graph(clf2, X_test_scaled, interactions.y_test, font_scale=1, palette=palette, figsize=(14,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(interactions.y_test, xgb_pred1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for vaccination classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance Graph\n",
    "pal = sns.color_palette((\"#102CA8\",))\n",
    "show_feature_importances(clf2, interactions.get_X_train(), figsize=(14, 12), palette=pal, font_scale=1, ascending=False, rows=12, style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the the limited adjustment of hyperparameters, the XG boost algorithm created the best performing model. Based on the feature importances, it appears that the strongest factor is a persons strong belief that the vaccine is effective. A doctor's recommendation, being an at risk demographic, or being a healthcare worker also are (not surprisingly) strong factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
