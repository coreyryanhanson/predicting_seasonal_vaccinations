{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Vaccination: Modeling H1N1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by Corey Hanson & Frank Flavell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/pred_vacc_model_h1n1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U.S. Department of Health & Human Services alomg with the National Center for Health Statistics launched a national telephone survey to gather data from a sample of the U.S. population in order to make predictions about H1N1 and Seasonal Flu vaccinations.\n",
    "\n",
    "**Target:**\n",
    "  * H1N1 Vaccination: Did the survey respondant receive the vaccine or not?\n",
    "  * Seasonal Flue Vaccination: Did the survey respondant receive the vaccine or not?\n",
    "\n",
    "We have been tasked with developing a classification model to make the predictions based on the survey results.  The specific end goal has not yet been determined, as this information may have many different uses in policy making, business, and non-profit health work.  Therefore, we are keeping an open mind when modeling to determine a few different possible models that would be appropriate in different contexts.\n",
    "\n",
    "The survey data can be found at this link: [National 2009 H1N1 Survey](https://www.drivendata.org/competitions/66/flu-shot-learning/page/210/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents<span id=\"0\"></span>\n",
    "\n",
    "1. [**Train/ Test Split, Class Imbalance & Standardization**](#1)\n",
    "    * User Defined Function for splitting, standardizing and correcting class imbalance\n",
    "    * Train/test set relabeling\n",
    "2. [**Logisitic Regression**](#2)\n",
    "    * Baseline\n",
    "    * Optimized Models\n",
    "3. [**K-Nearest Neighbor**](#3)\n",
    "    * Baseline\n",
    "    * Determine Best K\n",
    "    * Optimized Model\n",
    "4. [**Decision Tree**](#4)\n",
    "    * Baseline\n",
    "    * Determine Best Depth\n",
    "    * Optimized Model\n",
    "5. [**Random Forest**](#5)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Model\n",
    "6. [**AdaBoost**](#6)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Model\n",
    "7. [**XGBoost**](#7)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Models\n",
    "8. [**Support Vector Machine**](#8)\n",
    "    * Baseline\n",
    "    * GridSearch\n",
    "    * Optimized Models\n",
    "9. [**Best Model**](#9)\n",
    "    * Analysis\n",
    "    * Recommendations\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "\n",
    "from cleaning_functions import *\n",
    "from eda import *\n",
    "\n",
    "from random_lumberjacks.src.random_lumberjacks.model.model_classes import *\n",
    "from random_lumberjacks.src.random_lumberjacks.visualization.visualization_functions import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>homeowner</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>missing_doctor_recc</th>\n",
       "      <th>missing_health_insurance</th>\n",
       "      <th>missing_homeowner</th>\n",
       "      <th>missing_household</th>\n",
       "      <th>missing_opinion</th>\n",
       "      <th>missing_demographics</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55_to_64 Years</td>\n",
       "      <td>&lt; 12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35_to_44 Years</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18_to_34 Years</td>\n",
       "      <td>College Graduate</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Over_65</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45_to_54 Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "respondent_id                                                            \n",
       "0                       1.0             0.0                        0.0   \n",
       "1                       3.0             2.0                        0.0   \n",
       "2                       1.0             1.0                        0.0   \n",
       "3                       1.0             1.0                        0.0   \n",
       "4                       2.0             1.0                        0.0   \n",
       "\n",
       "               behavioral_avoidance  behavioral_face_mask  \\\n",
       "respondent_id                                               \n",
       "0                               0.0                   0.0   \n",
       "1                               1.0                   0.0   \n",
       "2                               1.0                   0.0   \n",
       "3                               1.0                   0.0   \n",
       "4                               1.0                   0.0   \n",
       "\n",
       "               behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "respondent_id                                                       \n",
       "0                                0.0                          0.0   \n",
       "1                                1.0                          0.0   \n",
       "2                                0.0                          0.0   \n",
       "3                                1.0                          1.0   \n",
       "4                                1.0                          1.0   \n",
       "\n",
       "               behavioral_outside_home  behavioral_touch_face  \\\n",
       "respondent_id                                                   \n",
       "0                                  1.0                    1.0   \n",
       "1                                  1.0                    1.0   \n",
       "2                                  0.0                    0.0   \n",
       "3                                  0.0                    0.0   \n",
       "4                                  0.0                    1.0   \n",
       "\n",
       "               doctor_recc_h1n1  doctor_recc_seasonal  chronic_med_condition  \\\n",
       "respondent_id                                                                  \n",
       "0                           0.0                   0.0                    0.0   \n",
       "1                           0.0                   0.0                    0.0   \n",
       "2                           0.0                   0.0                    1.0   \n",
       "3                           0.0                   1.0                    1.0   \n",
       "4                           0.0                   0.0                    0.0   \n",
       "\n",
       "               child_under_6_months  health_worker  health_insurance  \\\n",
       "respondent_id                                                          \n",
       "0                               0.0            0.0               1.0   \n",
       "1                               0.0            0.0               1.0   \n",
       "2                               0.0            0.0               1.0   \n",
       "3                               0.0            0.0               1.0   \n",
       "4                               0.0            0.0               1.0   \n",
       "\n",
       "               opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
       "respondent_id                                                   \n",
       "0                                      3.0                1.0   \n",
       "1                                      5.0                4.0   \n",
       "2                                      3.0                1.0   \n",
       "3                                      3.0                3.0   \n",
       "4                                      3.0                3.0   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "respondent_id                                                             \n",
       "0                                      2.0                          2.0   \n",
       "1                                      4.0                          4.0   \n",
       "2                                      1.0                          4.0   \n",
       "3                                      5.0                          5.0   \n",
       "4                                      2.0                          3.0   \n",
       "\n",
       "               opinion_seas_risk  opinion_seas_sick_from_vacc       age_group  \\\n",
       "respondent_id                                                                   \n",
       "0                            1.0                          2.0  55_to_64 Years   \n",
       "1                            2.0                          4.0  35_to_44 Years   \n",
       "2                            1.0                          2.0  18_to_34 Years   \n",
       "3                            4.0                          1.0         Over_65   \n",
       "4                            1.0                          4.0  45_to_54 Years   \n",
       "\n",
       "                      education   race     sex income_poverty marital_status  \\\n",
       "respondent_id                                                                  \n",
       "0                    < 12 Years  White  Female  Below Poverty    Not Married   \n",
       "1                      12 Years  White    Male  Below Poverty    Not Married   \n",
       "2              College Graduate  White    Male  Above Poverty    Not Married   \n",
       "3                      12 Years  White  Female  Below Poverty    Not Married   \n",
       "4                  Some College  White  Female  Above Poverty        Married   \n",
       "\n",
       "               homeowner   employment_status hhs_geo_region  \\\n",
       "respondent_id                                                 \n",
       "0                    1.0  Not in Labor Force       oxchjgsf   \n",
       "1                    0.0            Employed       bhuqouqj   \n",
       "2                    1.0            Employed       qufhixun   \n",
       "3                    0.0  Not in Labor Force       lrircsnp   \n",
       "4                    1.0            Employed       qufhixun   \n",
       "\n",
       "                             census_msa  household_adults  household_children  \\\n",
       "respondent_id                                                                   \n",
       "0                               Non-MSA               0.0                 0.0   \n",
       "1              MSA, Not Principle  City               0.0                 0.0   \n",
       "2              MSA, Not Principle  City               2.0                 0.0   \n",
       "3                   MSA, Principle City               0.0                 0.0   \n",
       "4              MSA, Not Principle  City               1.0                 0.0   \n",
       "\n",
       "              employment_industry employment_occupation  h1n1_vaccine  \\\n",
       "respondent_id                                                           \n",
       "0                         unknown               unknown             0   \n",
       "1                        pxcmvdjn              xgwztkwe             0   \n",
       "2                        rucpziij              xtkaffoo             0   \n",
       "3                         unknown               unknown             0   \n",
       "4                        wxleyezf              emcorrxb             0   \n",
       "\n",
       "               seasonal_vaccine  missing_doctor_recc  \\\n",
       "respondent_id                                          \n",
       "0                             0                    0   \n",
       "1                             1                    0   \n",
       "2                             0                    1   \n",
       "3                             1                    0   \n",
       "4                             0                    0   \n",
       "\n",
       "               missing_health_insurance  missing_homeowner  missing_household  \\\n",
       "respondent_id                                                                   \n",
       "0                                     0                  0                  0   \n",
       "1                                     0                  0                  0   \n",
       "2                                     1                  0                  0   \n",
       "3                                     1                  0                  0   \n",
       "4                                     1                  0                  0   \n",
       "\n",
       "               missing_opinion  missing_demographics  \n",
       "respondent_id                                         \n",
       "0                            0                     0  \n",
       "1                            0                     0  \n",
       "2                            0                     0  \n",
       "3                            0                     0  \n",
       "4                            0                     0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 43 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26707 non-null  float64\n",
      " 1   h1n1_knowledge               26707 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26707 non-null  float64\n",
      " 3   behavioral_avoidance         26707 non-null  float64\n",
      " 4   behavioral_face_mask         26707 non-null  float64\n",
      " 5   behavioral_wash_hands        26707 non-null  float64\n",
      " 6   behavioral_large_gatherings  26707 non-null  float64\n",
      " 7   behavioral_outside_home      26707 non-null  float64\n",
      " 8   behavioral_touch_face        26707 non-null  float64\n",
      " 9   doctor_recc_h1n1             26707 non-null  float64\n",
      " 10  doctor_recc_seasonal         26707 non-null  float64\n",
      " 11  chronic_med_condition        26707 non-null  float64\n",
      " 12  child_under_6_months         26707 non-null  float64\n",
      " 13  health_worker                26707 non-null  float64\n",
      " 14  health_insurance             26707 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26707 non-null  float64\n",
      " 16  opinion_h1n1_risk            26707 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26707 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26707 non-null  float64\n",
      " 19  opinion_seas_risk            26707 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26707 non-null  float64\n",
      " 21  age_group                    26707 non-null  object \n",
      " 22  education                    26707 non-null  object \n",
      " 23  race                         26707 non-null  object \n",
      " 24  sex                          26707 non-null  object \n",
      " 25  income_poverty               26707 non-null  object \n",
      " 26  marital_status               26707 non-null  object \n",
      " 27  homeowner                    26707 non-null  float64\n",
      " 28  employment_status            26707 non-null  object \n",
      " 29  hhs_geo_region               26707 non-null  object \n",
      " 30  census_msa                   26707 non-null  object \n",
      " 31  household_adults             26707 non-null  float64\n",
      " 32  household_children           26707 non-null  float64\n",
      " 33  employment_industry          26707 non-null  object \n",
      " 34  employment_occupation        26707 non-null  object \n",
      " 35  h1n1_vaccine                 26707 non-null  int64  \n",
      " 36  seasonal_vaccine             26707 non-null  int64  \n",
      " 37  missing_doctor_recc          26707 non-null  int64  \n",
      " 38  missing_health_insurance     26707 non-null  int64  \n",
      " 39  missing_homeowner            26707 non-null  int64  \n",
      " 40  missing_household            26707 non-null  int64  \n",
      " 41  missing_opinion              26707 non-null  int64  \n",
      " 42  missing_demographics         26707 non-null  int64  \n",
      "dtypes: float64(24), int64(8), object(11)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>homeowner</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>missing_doctor_recc</th>\n",
       "      <th>missing_health_insurance</th>\n",
       "      <th>missing_homeowner</th>\n",
       "      <th>missing_household</th>\n",
       "      <th>missing_opinion</th>\n",
       "      <th>missing_demographics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "      <td>26707.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.619800</td>\n",
       "      <td>1.261392</td>\n",
       "      <td>0.048714</td>\n",
       "      <td>0.727749</td>\n",
       "      <td>0.068933</td>\n",
       "      <td>0.825888</td>\n",
       "      <td>0.357472</td>\n",
       "      <td>0.336279</td>\n",
       "      <td>0.678811</td>\n",
       "      <td>0.202494</td>\n",
       "      <td>0.303067</td>\n",
       "      <td>0.272962</td>\n",
       "      <td>0.080054</td>\n",
       "      <td>0.108548</td>\n",
       "      <td>0.934998</td>\n",
       "      <td>3.852810</td>\n",
       "      <td>2.337589</td>\n",
       "      <td>2.352380</td>\n",
       "      <td>4.025536</td>\n",
       "      <td>2.705321</td>\n",
       "      <td>2.115737</td>\n",
       "      <td>0.777998</td>\n",
       "      <td>0.887558</td>\n",
       "      <td>0.529599</td>\n",
       "      <td>0.212454</td>\n",
       "      <td>0.465608</td>\n",
       "      <td>0.080878</td>\n",
       "      <td>0.459580</td>\n",
       "      <td>0.076459</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.026398</td>\n",
       "      <td>0.065114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.909016</td>\n",
       "      <td>0.617047</td>\n",
       "      <td>0.215273</td>\n",
       "      <td>0.445127</td>\n",
       "      <td>0.253345</td>\n",
       "      <td>0.379213</td>\n",
       "      <td>0.479264</td>\n",
       "      <td>0.472444</td>\n",
       "      <td>0.466942</td>\n",
       "      <td>0.401866</td>\n",
       "      <td>0.459592</td>\n",
       "      <td>0.445490</td>\n",
       "      <td>0.271382</td>\n",
       "      <td>0.311077</td>\n",
       "      <td>0.246533</td>\n",
       "      <td>1.000195</td>\n",
       "      <td>1.276825</td>\n",
       "      <td>1.353339</td>\n",
       "      <td>1.077131</td>\n",
       "      <td>1.375216</td>\n",
       "      <td>1.319585</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.749980</td>\n",
       "      <td>0.925264</td>\n",
       "      <td>0.409052</td>\n",
       "      <td>0.498825</td>\n",
       "      <td>0.272652</td>\n",
       "      <td>0.498373</td>\n",
       "      <td>0.265737</td>\n",
       "      <td>0.096108</td>\n",
       "      <td>0.160318</td>\n",
       "      <td>0.246732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "count  26707.000000    26707.000000               26707.000000   \n",
       "mean       1.619800        1.261392                   0.048714   \n",
       "std        0.909016        0.617047                   0.215273   \n",
       "min        0.000000        0.000000                   0.000000   \n",
       "25%        1.000000        1.000000                   0.000000   \n",
       "50%        2.000000        1.000000                   0.000000   \n",
       "75%        2.000000        2.000000                   0.000000   \n",
       "max        3.000000        2.000000                   1.000000   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "count          26707.000000          26707.000000           26707.000000   \n",
       "mean               0.727749              0.068933               0.825888   \n",
       "std                0.445127              0.253345               0.379213   \n",
       "min                0.000000              0.000000               0.000000   \n",
       "25%                0.000000              0.000000               1.000000   \n",
       "50%                1.000000              0.000000               1.000000   \n",
       "75%                1.000000              0.000000               1.000000   \n",
       "max                1.000000              1.000000               1.000000   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "count                 26707.000000             26707.000000   \n",
       "mean                      0.357472                 0.336279   \n",
       "std                       0.479264                 0.472444   \n",
       "min                       0.000000                 0.000000   \n",
       "25%                       0.000000                 0.000000   \n",
       "50%                       0.000000                 0.000000   \n",
       "75%                       1.000000                 1.000000   \n",
       "max                       1.000000                 1.000000   \n",
       "\n",
       "       behavioral_touch_face  doctor_recc_h1n1  doctor_recc_seasonal  \\\n",
       "count           26707.000000      26707.000000          26707.000000   \n",
       "mean                0.678811          0.202494              0.303067   \n",
       "std                 0.466942          0.401866              0.459592   \n",
       "min                 0.000000          0.000000              0.000000   \n",
       "25%                 0.000000          0.000000              0.000000   \n",
       "50%                 1.000000          0.000000              0.000000   \n",
       "75%                 1.000000          0.000000              1.000000   \n",
       "max                 1.000000          1.000000              1.000000   \n",
       "\n",
       "       chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "count           26707.000000          26707.000000   26707.000000   \n",
       "mean                0.272962              0.080054       0.108548   \n",
       "std                 0.445490              0.271382       0.311077   \n",
       "min                 0.000000              0.000000       0.000000   \n",
       "25%                 0.000000              0.000000       0.000000   \n",
       "50%                 0.000000              0.000000       0.000000   \n",
       "75%                 1.000000              0.000000       0.000000   \n",
       "max                 1.000000              1.000000       1.000000   \n",
       "\n",
       "       health_insurance  opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
       "count      26707.000000                 26707.000000       26707.000000   \n",
       "mean           0.934998                     3.852810           2.337589   \n",
       "std            0.246533                     1.000195           1.276825   \n",
       "min            0.000000                     1.000000           1.000000   \n",
       "25%            1.000000                     3.000000           1.000000   \n",
       "50%            1.000000                     4.000000           2.000000   \n",
       "75%            1.000000                     5.000000           4.000000   \n",
       "max            1.000000                     5.000000           5.000000   \n",
       "\n",
       "       opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
       "count                 26707.000000                 26707.000000   \n",
       "mean                      2.352380                     4.025536   \n",
       "std                       1.353339                     1.077131   \n",
       "min                       1.000000                     1.000000   \n",
       "25%                       1.000000                     4.000000   \n",
       "50%                       2.000000                     4.000000   \n",
       "75%                       4.000000                     5.000000   \n",
       "max                       5.000000                     5.000000   \n",
       "\n",
       "       opinion_seas_risk  opinion_seas_sick_from_vacc     homeowner  \\\n",
       "count       26707.000000                 26707.000000  26707.000000   \n",
       "mean            2.705321                     2.115737      0.777998   \n",
       "std             1.375216                     1.319585      0.415600   \n",
       "min             1.000000                     1.000000      0.000000   \n",
       "25%             2.000000                     1.000000      1.000000   \n",
       "50%             2.000000                     2.000000      1.000000   \n",
       "75%             4.000000                     2.000000      1.000000   \n",
       "max             5.000000                     5.000000      1.000000   \n",
       "\n",
       "       household_adults  household_children  h1n1_vaccine  seasonal_vaccine  \\\n",
       "count      26707.000000        26707.000000  26707.000000      26707.000000   \n",
       "mean           0.887558            0.529599      0.212454          0.465608   \n",
       "std            0.749980            0.925264      0.409052          0.498825   \n",
       "min            0.000000            0.000000      0.000000          0.000000   \n",
       "25%            0.000000            0.000000      0.000000          0.000000   \n",
       "50%            1.000000            0.000000      0.000000          0.000000   \n",
       "75%            1.000000            1.000000      0.000000          1.000000   \n",
       "max            3.000000            3.000000      1.000000          1.000000   \n",
       "\n",
       "       missing_doctor_recc  missing_health_insurance  missing_homeowner  \\\n",
       "count         26707.000000              26707.000000       26707.000000   \n",
       "mean              0.080878                  0.459580           0.076459   \n",
       "std               0.272652                  0.498373           0.265737   \n",
       "min               0.000000                  0.000000           0.000000   \n",
       "25%               0.000000                  0.000000           0.000000   \n",
       "50%               0.000000                  0.000000           0.000000   \n",
       "75%               0.000000                  1.000000           0.000000   \n",
       "max               1.000000                  1.000000           1.000000   \n",
       "\n",
       "       missing_household  missing_opinion  missing_demographics  \n",
       "count       26707.000000     26707.000000          26707.000000  \n",
       "mean            0.009323         0.026398              0.065114  \n",
       "std             0.096108         0.160318              0.246732  \n",
       "min             0.000000         0.000000              0.000000  \n",
       "25%             0.000000         0.000000              0.000000  \n",
       "50%             0.000000         0.000000              0.000000  \n",
       "75%             0.000000         0.000000              0.000000  \n",
       "max             1.000000         1.000000              1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"1\"></span>1. Train/ Test Split, Class Imbalance & Standardization\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During EDA, we determined that there was a class imblance for the H1N1 Vaccination target variable.  To correct this imbalance, we downsampled the majority class so that our models would run faster during training.\n",
    "\n",
    "The user-defined class below creates an object, 'data', that houses the original dataframe as well as any transformations we added including dummy variables, scaling, class imbalance correction and ploynomial features.  It also takes care of the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating column selection dictionaries for the data from lists of column names.\n",
    "\n",
    "#Lists to go in the dictionaries.\n",
    "binary_columns = ['behavioral_antiviral_meds',\n",
    "       'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands',\n",
    "       'behavioral_large_gatherings', 'behavioral_outside_home',\n",
    "       'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
    "       'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
    "       'health_insurance', 'homeowner']\n",
    "missing_dummies = extract_column_names(df, \"^missing\")\n",
    "target_col1 = \"h1n1_vaccine\"\n",
    "target_col2 = \"seasonal_vaccine\"\n",
    "target_cols = [target_col1, target_col2]\n",
    "untr = ['household_adults', 'household_children',]\n",
    "nom = df.columns.drop([*untr, *binary_columns, *target_cols, *missing_dummies])\n",
    "\n",
    "#The dicts that come into the arguments.\n",
    "categorical = {\n",
    "    \"nominal_features\":nom, \"standard_dummies\": binary_columns, \"impute_dummies\":missing_dummies\n",
    "}\n",
    "\n",
    "continuous = {\"untransformed\":untr}\n",
    "polynomial = {\"method\":\"choose\", \"columns\":['age_group', 'education', 'sex',\n",
    "                                            'doctor_recc_seasonal', 'income_poverty']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Skipping polynomial features\n",
      "Performing downsample\n",
      "No scaling specified\n",
      "Skipping scaling\n",
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Skipping polynomial features\n",
      "Performing downsample\n",
      "Using standard scaler\n",
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Skipping polynomial features\n",
      "Performing downsample\n",
      "Using standard scaler\n",
      "Adding ['household_adults', 'household_children', 'behavioral_antiviral_meds', 'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands', 'behavioral_large_gatherings', 'behavioral_outside_home', 'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal', 'chronic_med_condition', 'child_under_6_months', 'health_worker', 'health_insurance', 'homeowner', 'missing_doctor_recc', 'missing_health_insurance', 'missing_homeowner', 'missing_household', 'missing_opinion', 'missing_demographics', 'h1n1_concern_1.0', 'h1n1_concern_2.0', 'h1n1_concern_3.0', 'h1n1_knowledge_1.0', 'h1n1_knowledge_2.0', 'opinion_h1n1_vacc_effective_2.0', 'opinion_h1n1_vacc_effective_3.0', 'opinion_h1n1_vacc_effective_4.0', 'opinion_h1n1_vacc_effective_5.0', 'opinion_h1n1_risk_2.0', 'opinion_h1n1_risk_3.0', 'opinion_h1n1_risk_4.0', 'opinion_h1n1_risk_5.0', 'opinion_h1n1_sick_from_vacc_2.0', 'opinion_h1n1_sick_from_vacc_3.0', 'opinion_h1n1_sick_from_vacc_4.0', 'opinion_h1n1_sick_from_vacc_5.0', 'opinion_seas_vacc_effective_2.0', 'opinion_seas_vacc_effective_3.0', 'opinion_seas_vacc_effective_4.0', 'opinion_seas_vacc_effective_5.0', 'opinion_seas_risk_2.0', 'opinion_seas_risk_3.0', 'opinion_seas_risk_4.0', 'opinion_seas_risk_5.0', 'opinion_seas_sick_from_vacc_2.0', 'opinion_seas_sick_from_vacc_3.0', 'opinion_seas_sick_from_vacc_4.0', 'opinion_seas_sick_from_vacc_5.0', 'age_group_35_to_44 Years', 'age_group_45_to_54 Years', 'age_group_55_to_64 Years', 'age_group_Over_65', 'education_< 12 Years', 'education_College Graduate', 'education_Some College', 'race_Hispanic', 'race_Other or Multiple', 'race_White', 'sex_Male', 'income_poverty_Above Poverty', 'income_poverty_Below Poverty', 'income_poverty_unknown', 'marital_status_Not Married', 'employment_status_Not in Labor Force', 'employment_status_Unemployed', 'hhs_geo_region_bhuqouqj', 'hhs_geo_region_dqpwygqj', 'hhs_geo_region_fpwskwrf', 'hhs_geo_region_kbazzjca', 'hhs_geo_region_lrircsnp', 'hhs_geo_region_lzgpxyit', 'hhs_geo_region_mlyzmhmf', 'hhs_geo_region_oxchjgsf', 'hhs_geo_region_qufhixun', 'census_msa_MSA, Principle City', 'census_msa_Non-MSA', 'employment_industry_atmlpfrs', 'employment_industry_cfqqtusy', 'employment_industry_dotnnunm', 'employment_industry_fcxhlnwr', 'employment_industry_haxffmxo', 'employment_industry_ldnlellj', 'employment_industry_mcubkhph', 'employment_industry_mfikgejo', 'employment_industry_msuufmds', 'employment_industry_nduyfdeo', 'employment_industry_phxvnwax', 'employment_industry_pxcmvdjn', 'employment_industry_qnlwzans', 'employment_industry_rucpziij', 'employment_industry_saaquncn', 'employment_industry_unknown', 'employment_industry_vjjrobsf', 'employment_industry_wlfvacwt', 'employment_industry_wxleyezf', 'employment_industry_xicduogh', 'employment_industry_xqicxuve', 'employment_occupation_ccgxvspp', 'employment_occupation_cmhcxjea', 'employment_occupation_dcjcmpih', 'employment_occupation_dlvbwzss', 'employment_occupation_emcorrxb', 'employment_occupation_haliazsg', 'employment_occupation_hfxkjkmi', 'employment_occupation_hodpvpew', 'employment_occupation_kldqjyjy', 'employment_occupation_mxkfnird', 'employment_occupation_oijqvulv', 'employment_occupation_pvmttkik', 'employment_occupation_qxajmpny', 'employment_occupation_rcertsgn', 'employment_occupation_tfqavkke', 'employment_occupation_ukymxvdu', 'employment_occupation_unknown', 'employment_occupation_uqqtjvyb', 'employment_occupation_vlluhbov', 'employment_occupation_xgwztkwe', 'employment_occupation_xqwwgdyp', 'employment_occupation_xtkaffoo', 'employment_occupation_xzmlyyjv']\n",
      "Removing ['household_adults', 'doctor_recc_h1n1', 'health_worker', 'missing_health_insurance', 'opinion_h1n1_vacc_effective_5.0', 'opinion_h1n1_risk_4.0', 'opinion_h1n1_risk_5.0', 'marital_status_Not Married']\n",
      "Creating Dummies\n",
      "Warning: employment_industry has 22 unique values\n",
      "Warning: employment_occupation has 24 unique values\n",
      "Getting polynomial features of degree 2\n",
      "\n",
      "['age_group_35_to_44 Years age_group_45_to_54 Years', 'age_group_35_to_44 Years age_group_55_to_64 Years', 'age_group_35_to_44 Years age_group_Over_65', 'age_group_45_to_54 Years age_group_55_to_64 Years', 'age_group_45_to_54 Years age_group_Over_65', 'age_group_55_to_64 Years age_group_Over_65', 'education_< 12 Years education_College Graduate', 'education_< 12 Years education_Some College', 'education_College Graduate education_Some College', 'income_poverty_Above Poverty income_poverty_Below Poverty', 'income_poverty_Above Poverty income_poverty_unknown', 'income_poverty_Below Poverty income_poverty_unknown']\n",
      "were removed for containing 0 values\n",
      "\n",
      "Performing downsample\n",
      "Using standard scaler\n",
      "Adding ['doctor_recc_seasonal^2', 'doctor_recc_seasonal age_group_35_to_44 Years', 'doctor_recc_seasonal age_group_45_to_54 Years', 'doctor_recc_seasonal age_group_55_to_64 Years', 'doctor_recc_seasonal age_group_Over_65', 'doctor_recc_seasonal education_< 12 Years', 'doctor_recc_seasonal education_College Graduate', 'doctor_recc_seasonal education_Some College', 'doctor_recc_seasonal sex_Male', 'doctor_recc_seasonal income_poverty_Above Poverty', 'doctor_recc_seasonal income_poverty_Below Poverty', 'doctor_recc_seasonal income_poverty_unknown', 'age_group_35_to_44 Years^2', 'age_group_35_to_44 Years education_< 12 Years', 'age_group_35_to_44 Years education_College Graduate', 'age_group_35_to_44 Years education_Some College', 'age_group_35_to_44 Years sex_Male', 'age_group_35_to_44 Years income_poverty_Above Poverty', 'age_group_35_to_44 Years income_poverty_Below Poverty', 'age_group_35_to_44 Years income_poverty_unknown', 'age_group_45_to_54 Years^2', 'age_group_45_to_54 Years education_< 12 Years', 'age_group_45_to_54 Years education_College Graduate', 'age_group_45_to_54 Years education_Some College', 'age_group_45_to_54 Years sex_Male', 'age_group_45_to_54 Years income_poverty_Above Poverty', 'age_group_45_to_54 Years income_poverty_Below Poverty', 'age_group_45_to_54 Years income_poverty_unknown', 'age_group_55_to_64 Years^2', 'age_group_55_to_64 Years education_< 12 Years', 'age_group_55_to_64 Years education_College Graduate', 'age_group_55_to_64 Years education_Some College', 'age_group_55_to_64 Years sex_Male', 'age_group_55_to_64 Years income_poverty_Above Poverty', 'age_group_55_to_64 Years income_poverty_Below Poverty', 'age_group_55_to_64 Years income_poverty_unknown', 'age_group_Over_65^2', 'age_group_Over_65 education_< 12 Years', 'age_group_Over_65 education_College Graduate', 'age_group_Over_65 education_Some College', 'age_group_Over_65 sex_Male', 'age_group_Over_65 income_poverty_Above Poverty', 'age_group_Over_65 income_poverty_Below Poverty', 'age_group_Over_65 income_poverty_unknown', 'education_< 12 Years^2', 'education_< 12 Years sex_Male', 'education_< 12 Years income_poverty_Above Poverty', 'education_< 12 Years income_poverty_Below Poverty', 'education_< 12 Years income_poverty_unknown', 'education_College Graduate^2', 'education_College Graduate sex_Male', 'education_College Graduate income_poverty_Above Poverty', 'education_College Graduate income_poverty_Below Poverty', 'education_College Graduate income_poverty_unknown', 'education_Some College^2', 'education_Some College sex_Male', 'education_Some College income_poverty_Above Poverty', 'education_Some College income_poverty_Below Poverty', 'education_Some College income_poverty_unknown', 'sex_Male^2', 'sex_Male income_poverty_Above Poverty', 'sex_Male income_poverty_Below Poverty', 'sex_Male income_poverty_unknown', 'income_poverty_Above Poverty^2', 'income_poverty_Below Poverty^2', 'income_poverty_unknown^2']\n",
      "Removing ['doctor_recc_seasonal education_Some College', 'doctor_recc_seasonal sex_Male']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>homeowner</th>\n",
       "      <th>missing_doctor_recc</th>\n",
       "      <th>missing_health_insurance</th>\n",
       "      <th>missing_homeowner</th>\n",
       "      <th>missing_household</th>\n",
       "      <th>missing_opinion</th>\n",
       "      <th>missing_demographics</th>\n",
       "      <th>h1n1_concern_1.0</th>\n",
       "      <th>h1n1_concern_2.0</th>\n",
       "      <th>h1n1_concern_3.0</th>\n",
       "      <th>h1n1_knowledge_1.0</th>\n",
       "      <th>h1n1_knowledge_2.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_2.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_3.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_4.0</th>\n",
       "      <th>opinion_h1n1_vacc_effective_5.0</th>\n",
       "      <th>opinion_h1n1_risk_2.0</th>\n",
       "      <th>opinion_h1n1_risk_3.0</th>\n",
       "      <th>opinion_h1n1_risk_4.0</th>\n",
       "      <th>opinion_h1n1_risk_5.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_2.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_3.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_4.0</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc_5.0</th>\n",
       "      <th>opinion_seas_vacc_effective_2.0</th>\n",
       "      <th>opinion_seas_vacc_effective_3.0</th>\n",
       "      <th>opinion_seas_vacc_effective_4.0</th>\n",
       "      <th>opinion_seas_vacc_effective_5.0</th>\n",
       "      <th>opinion_seas_risk_2.0</th>\n",
       "      <th>opinion_seas_risk_3.0</th>\n",
       "      <th>opinion_seas_risk_4.0</th>\n",
       "      <th>opinion_seas_risk_5.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_2.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_3.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_4.0</th>\n",
       "      <th>opinion_seas_sick_from_vacc_5.0</th>\n",
       "      <th>age_group_35_to_44 Years</th>\n",
       "      <th>age_group_45_to_54 Years</th>\n",
       "      <th>age_group_55_to_64 Years</th>\n",
       "      <th>age_group_Over_65</th>\n",
       "      <th>education_&lt; 12 Years</th>\n",
       "      <th>education_College Graduate</th>\n",
       "      <th>education_Some College</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>race_Other or Multiple</th>\n",
       "      <th>race_White</th>\n",
       "      <th>sex_Male</th>\n",
       "      <th>income_poverty_Above Poverty</th>\n",
       "      <th>income_poverty_Below Poverty</th>\n",
       "      <th>income_poverty_unknown</th>\n",
       "      <th>marital_status_Not Married</th>\n",
       "      <th>employment_status_Not in Labor Force</th>\n",
       "      <th>employment_status_Unemployed</th>\n",
       "      <th>hhs_geo_region_bhuqouqj</th>\n",
       "      <th>hhs_geo_region_dqpwygqj</th>\n",
       "      <th>hhs_geo_region_fpwskwrf</th>\n",
       "      <th>hhs_geo_region_kbazzjca</th>\n",
       "      <th>hhs_geo_region_lrircsnp</th>\n",
       "      <th>hhs_geo_region_lzgpxyit</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>hhs_geo_region_oxchjgsf</th>\n",
       "      <th>hhs_geo_region_qufhixun</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "      <th>employment_industry_atmlpfrs</th>\n",
       "      <th>employment_industry_cfqqtusy</th>\n",
       "      <th>employment_industry_dotnnunm</th>\n",
       "      <th>employment_industry_fcxhlnwr</th>\n",
       "      <th>employment_industry_haxffmxo</th>\n",
       "      <th>employment_industry_ldnlellj</th>\n",
       "      <th>employment_industry_mcubkhph</th>\n",
       "      <th>employment_industry_mfikgejo</th>\n",
       "      <th>employment_industry_msuufmds</th>\n",
       "      <th>employment_industry_nduyfdeo</th>\n",
       "      <th>employment_industry_phxvnwax</th>\n",
       "      <th>employment_industry_pxcmvdjn</th>\n",
       "      <th>employment_industry_qnlwzans</th>\n",
       "      <th>employment_industry_rucpziij</th>\n",
       "      <th>employment_industry_saaquncn</th>\n",
       "      <th>employment_industry_unknown</th>\n",
       "      <th>employment_industry_vjjrobsf</th>\n",
       "      <th>employment_industry_wlfvacwt</th>\n",
       "      <th>employment_industry_wxleyezf</th>\n",
       "      <th>employment_industry_xicduogh</th>\n",
       "      <th>employment_industry_xqicxuve</th>\n",
       "      <th>employment_occupation_ccgxvspp</th>\n",
       "      <th>employment_occupation_cmhcxjea</th>\n",
       "      <th>employment_occupation_dcjcmpih</th>\n",
       "      <th>employment_occupation_dlvbwzss</th>\n",
       "      <th>employment_occupation_emcorrxb</th>\n",
       "      <th>employment_occupation_haliazsg</th>\n",
       "      <th>employment_occupation_hfxkjkmi</th>\n",
       "      <th>employment_occupation_hodpvpew</th>\n",
       "      <th>employment_occupation_kldqjyjy</th>\n",
       "      <th>employment_occupation_mxkfnird</th>\n",
       "      <th>employment_occupation_oijqvulv</th>\n",
       "      <th>employment_occupation_pvmttkik</th>\n",
       "      <th>employment_occupation_qxajmpny</th>\n",
       "      <th>employment_occupation_rcertsgn</th>\n",
       "      <th>employment_occupation_tfqavkke</th>\n",
       "      <th>employment_occupation_ukymxvdu</th>\n",
       "      <th>employment_occupation_unknown</th>\n",
       "      <th>employment_occupation_uqqtjvyb</th>\n",
       "      <th>employment_occupation_vlluhbov</th>\n",
       "      <th>employment_occupation_xgwztkwe</th>\n",
       "      <th>employment_occupation_xqwwgdyp</th>\n",
       "      <th>employment_occupation_xtkaffoo</th>\n",
       "      <th>employment_occupation_xzmlyyjv</th>\n",
       "      <th>doctor_recc_seasonal education_Some College</th>\n",
       "      <th>doctor_recc_seasonal sex_Male</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12299</th>\n",
       "      <td>0.144861</td>\n",
       "      <td>-0.566274</td>\n",
       "      <td>4.170946</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>-0.722939</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>1.289945</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>2.431594</td>\n",
       "      <td>-4.110321</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>-0.788248</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>-0.834217</td>\n",
       "      <td>2.005463</td>\n",
       "      <td>0.965097</td>\n",
       "      <td>-0.805423</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>-0.861933</td>\n",
       "      <td>1.346931</td>\n",
       "      <td>-0.750922</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>1.683623</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>-0.714225</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>3.094517</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>1.137981</td>\n",
       "      <td>-0.692080</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>2.430524</td>\n",
       "      <td>-0.646513</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>3.795087</td>\n",
       "      <td>2.554328</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>-0.539910</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>-0.897984</td>\n",
       "      <td>1.675103</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>-1.997960</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>-0.934391</td>\n",
       "      <td>3.051984</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>1.165106</td>\n",
       "      <td>-0.794802</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>2.735743</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>-0.428842</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>1.640034</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>2.721506</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>-0.988088</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>8.581034</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.999782</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>2.945054</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>-1.197040</td>\n",
       "      <td>-0.566274</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>-1.718076</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>1.316109</td>\n",
       "      <td>1.383243</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>1.289945</td>\n",
       "      <td>1.514551</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>-4.110321</td>\n",
       "      <td>-1.966582</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>-0.788248</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>-0.834217</td>\n",
       "      <td>2.005463</td>\n",
       "      <td>-1.036166</td>\n",
       "      <td>1.241583</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>-0.861933</td>\n",
       "      <td>1.346931</td>\n",
       "      <td>-0.750922</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>1.683623</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>-0.714225</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>3.094517</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>1.137981</td>\n",
       "      <td>-0.692080</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>2.430524</td>\n",
       "      <td>-0.646513</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>3.795087</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>2.081108</td>\n",
       "      <td>-0.539910</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>-0.897984</td>\n",
       "      <td>-0.596978</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>-0.934391</td>\n",
       "      <td>3.051984</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>1.165106</td>\n",
       "      <td>1.258175</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>2.791613</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>-0.428842</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>1.547569</td>\n",
       "      <td>-0.609744</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>1.012055</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>-0.339552</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6713</th>\n",
       "      <td>0.144861</td>\n",
       "      <td>0.526745</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>-1.718076</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>-0.722939</td>\n",
       "      <td>-1.528318</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>-0.775227</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>-4.110321</td>\n",
       "      <td>-1.966582</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>-0.788248</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>3.864906</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>-0.834217</td>\n",
       "      <td>2.005463</td>\n",
       "      <td>0.965097</td>\n",
       "      <td>-0.805423</td>\n",
       "      <td>4.373966</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>-0.861933</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>1.331696</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>-0.593957</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>1.400120</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>-0.323152</td>\n",
       "      <td>3.822597</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>-0.878750</td>\n",
       "      <td>1.444919</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>-0.411434</td>\n",
       "      <td>1.546758</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>-0.263499</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>-0.539910</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>1.113605</td>\n",
       "      <td>-0.596978</td>\n",
       "      <td>3.671443</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>-1.997960</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>-0.934391</td>\n",
       "      <td>3.051984</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>1.165106</td>\n",
       "      <td>-0.794802</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>2.791613</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>-0.428842</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>1.547569</td>\n",
       "      <td>-0.609744</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>7.706798</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>-0.988088</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>8.917753</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.999782</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>-0.339552</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>-1.197040</td>\n",
       "      <td>1.619764</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>3.286257</td>\n",
       "      <td>-2.345510</td>\n",
       "      <td>1.316109</td>\n",
       "      <td>1.383243</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>1.289945</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>-4.110321</td>\n",
       "      <td>-1.966582</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>-0.788248</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>1.587006</td>\n",
       "      <td>-0.834217</td>\n",
       "      <td>-0.498638</td>\n",
       "      <td>-1.036166</td>\n",
       "      <td>1.241583</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>-0.861933</td>\n",
       "      <td>1.346931</td>\n",
       "      <td>-0.750922</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>-0.593957</td>\n",
       "      <td>2.967776</td>\n",
       "      <td>1.400120</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>-0.323152</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>1.137981</td>\n",
       "      <td>-0.692080</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>2.430524</td>\n",
       "      <td>1.546758</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>-0.263499</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>-0.539910</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>-0.897984</td>\n",
       "      <td>1.675103</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>-1.997960</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>-0.934391</td>\n",
       "      <td>3.051984</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>1.165106</td>\n",
       "      <td>-0.794802</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>2.331864</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>1.640034</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>7.706798</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>-0.988088</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.999782</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>5.106823</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>2.945054</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>0.144861</td>\n",
       "      <td>-0.566274</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>3.286257</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>-0.722939</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>1.289945</td>\n",
       "      <td>1.514551</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>0.243290</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>-0.788248</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>-0.834217</td>\n",
       "      <td>2.005463</td>\n",
       "      <td>0.965097</td>\n",
       "      <td>-0.805423</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>2.426257</td>\n",
       "      <td>-0.861933</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>-0.750922</td>\n",
       "      <td>4.942607</td>\n",
       "      <td>-0.593957</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>1.400120</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>-0.323152</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>1.137981</td>\n",
       "      <td>-0.692080</td>\n",
       "      <td>5.857277</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>-0.411434</td>\n",
       "      <td>-0.646513</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>2.111348</td>\n",
       "      <td>-0.263499</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>-0.539910</td>\n",
       "      <td>1.663408</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>-0.897984</td>\n",
       "      <td>1.675103</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>1.070215</td>\n",
       "      <td>-0.327656</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>-0.858291</td>\n",
       "      <td>1.258175</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>2.331864</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>-0.609744</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>1.012055</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>2.945054</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10407</th>\n",
       "      <td>-1.197040</td>\n",
       "      <td>0.526745</td>\n",
       "      <td>4.170946</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>-0.722939</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>1.289945</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>0.243290</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>1.268636</td>\n",
       "      <td>3.524351</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>3.864906</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>-0.834217</td>\n",
       "      <td>2.005463</td>\n",
       "      <td>0.965097</td>\n",
       "      <td>-0.805423</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>1.160184</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>-0.750922</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>1.683623</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>-0.714225</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>1.814311</td>\n",
       "      <td>-0.323152</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>1.156059</td>\n",
       "      <td>-0.878750</td>\n",
       "      <td>-0.692080</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>1.435981</td>\n",
       "      <td>-0.411434</td>\n",
       "      <td>-0.646513</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>2.111348</td>\n",
       "      <td>-0.263499</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>-0.539910</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>1.113605</td>\n",
       "      <td>-0.596978</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>-0.934391</td>\n",
       "      <td>-0.327656</td>\n",
       "      <td>2.235191</td>\n",
       "      <td>-0.858291</td>\n",
       "      <td>-0.794802</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>2.735743</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>-0.428842</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>-0.609744</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>1.012055</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>-0.339552</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7443</th>\n",
       "      <td>0.144861</td>\n",
       "      <td>-0.566274</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>-1.718076</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>-0.722939</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>1.289945</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>3.090586</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>0.243290</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>1.268636</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>1.198730</td>\n",
       "      <td>-0.498638</td>\n",
       "      <td>-1.036166</td>\n",
       "      <td>1.241583</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>1.160184</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>1.331696</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>-0.593957</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>1.400120</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>-0.323152</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>1.137981</td>\n",
       "      <td>-0.692080</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>1.435981</td>\n",
       "      <td>-0.411434</td>\n",
       "      <td>-0.646513</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>-0.263499</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>1.852161</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>-0.897984</td>\n",
       "      <td>1.675103</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>1.070215</td>\n",
       "      <td>-0.327656</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>-0.858291</td>\n",
       "      <td>1.258175</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>2.331864</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>-0.609744</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>1.012055</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>2.945054</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16022</th>\n",
       "      <td>0.144861</td>\n",
       "      <td>-0.566274</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>1.316109</td>\n",
       "      <td>1.383243</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>-0.684861</td>\n",
       "      <td>-0.775227</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>0.243290</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>1.268636</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>1.198730</td>\n",
       "      <td>-0.498638</td>\n",
       "      <td>0.965097</td>\n",
       "      <td>-0.805423</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>1.160184</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>1.331696</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>-0.593957</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>1.400120</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>-0.323152</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>1.156059</td>\n",
       "      <td>-0.878750</td>\n",
       "      <td>1.444919</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>-0.411434</td>\n",
       "      <td>1.546758</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>-0.263499</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>1.852161</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>1.113605</td>\n",
       "      <td>-0.596978</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>-1.997960</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>-0.934391</td>\n",
       "      <td>-0.327656</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>-0.858291</td>\n",
       "      <td>1.258175</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>2.331864</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>-0.609744</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>1.012055</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>-0.339552</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>0.144861</td>\n",
       "      <td>-0.566274</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>-1.718076</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>-2.345510</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>-0.722939</td>\n",
       "      <td>-1.528318</td>\n",
       "      <td>-0.684861</td>\n",
       "      <td>-0.775227</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>-0.411253</td>\n",
       "      <td>0.243290</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>-0.788248</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>1.198730</td>\n",
       "      <td>-0.498638</td>\n",
       "      <td>0.965097</td>\n",
       "      <td>-0.805423</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>2.426257</td>\n",
       "      <td>-0.861933</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>1.331696</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>-0.593957</td>\n",
       "      <td>-0.336953</td>\n",
       "      <td>-0.714225</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>-0.323152</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>1.137981</td>\n",
       "      <td>1.444919</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>-0.411434</td>\n",
       "      <td>-0.646513</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>-0.263499</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>-0.539910</td>\n",
       "      <td>1.663408</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>1.113605</td>\n",
       "      <td>-0.596978</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>-0.934391</td>\n",
       "      <td>-0.327656</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>-0.858291</td>\n",
       "      <td>1.258175</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>2.735743</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>-0.292389</td>\n",
       "      <td>-0.428842</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>-0.609744</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>-0.367444</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>1.012055</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>-0.241779</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>1.000218</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>-0.339552</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14084</th>\n",
       "      <td>-1.197040</td>\n",
       "      <td>-0.566274</td>\n",
       "      <td>-0.239754</td>\n",
       "      <td>0.582046</td>\n",
       "      <td>-0.304298</td>\n",
       "      <td>0.426347</td>\n",
       "      <td>-0.759815</td>\n",
       "      <td>-0.722939</td>\n",
       "      <td>0.654314</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>1.289945</td>\n",
       "      <td>-0.660262</td>\n",
       "      <td>-0.323563</td>\n",
       "      <td>2.431594</td>\n",
       "      <td>0.243290</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>1.268636</td>\n",
       "      <td>-0.283740</td>\n",
       "      <td>-0.091367</td>\n",
       "      <td>-0.153752</td>\n",
       "      <td>-0.258738</td>\n",
       "      <td>-0.630117</td>\n",
       "      <td>-0.834217</td>\n",
       "      <td>2.005463</td>\n",
       "      <td>-1.036166</td>\n",
       "      <td>1.241583</td>\n",
       "      <td>-0.228625</td>\n",
       "      <td>-0.412158</td>\n",
       "      <td>1.160184</td>\n",
       "      <td>-0.742428</td>\n",
       "      <td>-0.750922</td>\n",
       "      <td>-0.202322</td>\n",
       "      <td>-0.593957</td>\n",
       "      <td>2.967776</td>\n",
       "      <td>-0.714225</td>\n",
       "      <td>-0.069398</td>\n",
       "      <td>-0.551173</td>\n",
       "      <td>3.094517</td>\n",
       "      <td>-0.261602</td>\n",
       "      <td>-0.198796</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>1.137981</td>\n",
       "      <td>-0.692080</td>\n",
       "      <td>-0.170728</td>\n",
       "      <td>-0.696388</td>\n",
       "      <td>2.430524</td>\n",
       "      <td>-0.646513</td>\n",
       "      <td>-0.049013</td>\n",
       "      <td>-0.473631</td>\n",
       "      <td>3.795087</td>\n",
       "      <td>-0.391492</td>\n",
       "      <td>-0.480513</td>\n",
       "      <td>1.852161</td>\n",
       "      <td>-0.601175</td>\n",
       "      <td>-0.293704</td>\n",
       "      <td>-0.897984</td>\n",
       "      <td>-0.596978</td>\n",
       "      <td>-0.272372</td>\n",
       "      <td>-0.256816</td>\n",
       "      <td>0.500511</td>\n",
       "      <td>-0.818908</td>\n",
       "      <td>1.070215</td>\n",
       "      <td>-0.327656</td>\n",
       "      <td>-0.447389</td>\n",
       "      <td>1.165106</td>\n",
       "      <td>-0.794802</td>\n",
       "      <td>-0.226507</td>\n",
       "      <td>-0.358216</td>\n",
       "      <td>-0.202031</td>\n",
       "      <td>-0.365531</td>\n",
       "      <td>-0.346297</td>\n",
       "      <td>3.420102</td>\n",
       "      <td>-0.428842</td>\n",
       "      <td>-0.310664</td>\n",
       "      <td>-0.34531</td>\n",
       "      <td>-0.365723</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>1.640034</td>\n",
       "      <td>-0.176389</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.076203</td>\n",
       "      <td>2.721506</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.210074</td>\n",
       "      <td>-0.093168</td>\n",
       "      <td>-0.135705</td>\n",
       "      <td>-0.064472</td>\n",
       "      <td>-0.101713</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.192494</td>\n",
       "      <td>-0.01808</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.1146</td>\n",
       "      <td>-0.988088</td>\n",
       "      <td>-0.136121</td>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.282843</td>\n",
       "      <td>-0.167662</td>\n",
       "      <td>-0.13403</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.265385</td>\n",
       "      <td>-0.097246</td>\n",
       "      <td>-0.10006</td>\n",
       "      <td>-0.235662</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.159591</td>\n",
       "      <td>-0.088911</td>\n",
       "      <td>-0.133185</td>\n",
       "      <td>4.136002</td>\n",
       "      <td>-0.113128</td>\n",
       "      <td>-0.05821</td>\n",
       "      <td>-0.129756</td>\n",
       "      <td>-0.084446</td>\n",
       "      <td>-0.112136</td>\n",
       "      <td>-0.108597</td>\n",
       "      <td>-0.999782</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.120784</td>\n",
       "      <td>-0.195816</td>\n",
       "      <td>-0.125345</td>\n",
       "      <td>-0.26184</td>\n",
       "      <td>-0.089531</td>\n",
       "      <td>-0.339552</td>\n",
       "      <td>-0.399229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14522 rows  126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               household_adults  household_children  \\\n",
       "respondent_id                                         \n",
       "12299                  0.144861           -0.566274   \n",
       "8759                  -1.197040           -0.566274   \n",
       "6713                   0.144861            0.526745   \n",
       "7993                  -1.197040            1.619764   \n",
       "8635                   0.144861           -0.566274   \n",
       "...                         ...                 ...   \n",
       "10407                 -1.197040            0.526745   \n",
       "7443                   0.144861           -0.566274   \n",
       "16022                  0.144861           -0.566274   \n",
       "2569                   0.144861           -0.566274   \n",
       "14084                 -1.197040           -0.566274   \n",
       "\n",
       "               behavioral_antiviral_meds  behavioral_avoidance  \\\n",
       "respondent_id                                                    \n",
       "12299                           4.170946              0.582046   \n",
       "8759                           -0.239754             -1.718076   \n",
       "6713                           -0.239754             -1.718076   \n",
       "7993                           -0.239754              0.582046   \n",
       "8635                           -0.239754              0.582046   \n",
       "...                                  ...                   ...   \n",
       "10407                           4.170946              0.582046   \n",
       "7443                           -0.239754             -1.718076   \n",
       "16022                          -0.239754              0.582046   \n",
       "2569                           -0.239754             -1.718076   \n",
       "14084                          -0.239754              0.582046   \n",
       "\n",
       "               behavioral_face_mask  behavioral_wash_hands  \\\n",
       "respondent_id                                                \n",
       "12299                     -0.304298               0.426347   \n",
       "8759                      -0.304298               0.426347   \n",
       "6713                      -0.304298               0.426347   \n",
       "7993                       3.286257              -2.345510   \n",
       "8635                       3.286257               0.426347   \n",
       "...                             ...                    ...   \n",
       "10407                     -0.304298               0.426347   \n",
       "7443                      -0.304298               0.426347   \n",
       "16022                     -0.304298               0.426347   \n",
       "2569                      -0.304298              -2.345510   \n",
       "14084                     -0.304298               0.426347   \n",
       "\n",
       "               behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "respondent_id                                                         \n",
       "12299                            -0.759815                -0.722939   \n",
       "8759                              1.316109                 1.383243   \n",
       "6713                             -0.759815                -0.722939   \n",
       "7993                              1.316109                 1.383243   \n",
       "8635                             -0.759815                -0.722939   \n",
       "...                                    ...                      ...   \n",
       "10407                            -0.759815                -0.722939   \n",
       "7443                             -0.759815                -0.722939   \n",
       "16022                             1.316109                 1.383243   \n",
       "2569                             -0.759815                -0.722939   \n",
       "14084                            -0.759815                -0.722939   \n",
       "\n",
       "               behavioral_touch_face  doctor_recc_h1n1  doctor_recc_seasonal  \\\n",
       "respondent_id                                                                  \n",
       "12299                       0.654314          1.460150              1.289945   \n",
       "8759                        0.654314          1.460150              1.289945   \n",
       "6713                       -1.528318          1.460150             -0.775227   \n",
       "7993                        0.654314          1.460150              1.289945   \n",
       "8635                        0.654314          1.460150              1.289945   \n",
       "...                              ...               ...                   ...   \n",
       "10407                       0.654314          1.460150              1.289945   \n",
       "7443                        0.654314          1.460150              1.289945   \n",
       "16022                       0.654314         -0.684861             -0.775227   \n",
       "2569                       -1.528318         -0.684861             -0.775227   \n",
       "14084                       0.654314          1.460150              1.289945   \n",
       "\n",
       "               chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "respondent_id                                                               \n",
       "12299                      -0.660262             -0.323563       2.431594   \n",
       "8759                        1.514551             -0.323563      -0.411253   \n",
       "6713                       -0.660262             -0.323563      -0.411253   \n",
       "7993                       -0.660262             -0.323563      -0.411253   \n",
       "8635                        1.514551             -0.323563      -0.411253   \n",
       "...                              ...                   ...            ...   \n",
       "10407                      -0.660262             -0.323563      -0.411253   \n",
       "7443                       -0.660262              3.090586      -0.411253   \n",
       "16022                      -0.660262             -0.323563      -0.411253   \n",
       "2569                       -0.660262             -0.323563      -0.411253   \n",
       "14084                      -0.660262             -0.323563       2.431594   \n",
       "\n",
       "               health_insurance  homeowner  missing_doctor_recc  \\\n",
       "respondent_id                                                     \n",
       "12299                 -4.110321   0.508496            -0.260173   \n",
       "8759                  -4.110321  -1.966582            -0.260173   \n",
       "6713                  -4.110321  -1.966582            -0.260173   \n",
       "7993                  -4.110321  -1.966582            -0.260173   \n",
       "8635                   0.243290   0.508496            -0.260173   \n",
       "...                         ...        ...                  ...   \n",
       "10407                  0.243290   0.508496            -0.260173   \n",
       "7443                   0.243290   0.508496            -0.260173   \n",
       "16022                  0.243290   0.508496            -0.260173   \n",
       "2569                   0.243290   0.508496            -0.260173   \n",
       "14084                  0.243290   0.508496            -0.260173   \n",
       "\n",
       "               missing_health_insurance  missing_homeowner  missing_household  \\\n",
       "respondent_id                                                                   \n",
       "12299                         -0.788248          -0.283740          -0.091367   \n",
       "8759                          -0.788248          -0.283740          -0.091367   \n",
       "6713                          -0.788248          -0.283740          -0.091367   \n",
       "7993                          -0.788248          -0.283740          -0.091367   \n",
       "8635                          -0.788248          -0.283740          -0.091367   \n",
       "...                                 ...                ...                ...   \n",
       "10407                          1.268636           3.524351          -0.091367   \n",
       "7443                           1.268636          -0.283740          -0.091367   \n",
       "16022                          1.268636          -0.283740          -0.091367   \n",
       "2569                          -0.788248          -0.283740          -0.091367   \n",
       "14084                          1.268636          -0.283740          -0.091367   \n",
       "\n",
       "               missing_opinion  missing_demographics  h1n1_concern_1.0  \\\n",
       "respondent_id                                                            \n",
       "12299                -0.153752             -0.258738         -0.630117   \n",
       "8759                 -0.153752             -0.258738         -0.630117   \n",
       "6713                 -0.153752              3.864906         -0.630117   \n",
       "7993                 -0.153752             -0.258738          1.587006   \n",
       "8635                 -0.153752             -0.258738         -0.630117   \n",
       "...                        ...                   ...               ...   \n",
       "10407                -0.153752              3.864906         -0.630117   \n",
       "7443                 -0.153752             -0.258738         -0.630117   \n",
       "16022                -0.153752             -0.258738         -0.630117   \n",
       "2569                 -0.153752             -0.258738         -0.630117   \n",
       "14084                -0.153752             -0.258738         -0.630117   \n",
       "\n",
       "               h1n1_concern_2.0  h1n1_concern_3.0  h1n1_knowledge_1.0  \\\n",
       "respondent_id                                                           \n",
       "12299                 -0.834217          2.005463            0.965097   \n",
       "8759                  -0.834217          2.005463           -1.036166   \n",
       "6713                  -0.834217          2.005463            0.965097   \n",
       "7993                  -0.834217         -0.498638           -1.036166   \n",
       "8635                  -0.834217          2.005463            0.965097   \n",
       "...                         ...               ...                 ...   \n",
       "10407                 -0.834217          2.005463            0.965097   \n",
       "7443                   1.198730         -0.498638           -1.036166   \n",
       "16022                  1.198730         -0.498638            0.965097   \n",
       "2569                   1.198730         -0.498638            0.965097   \n",
       "14084                 -0.834217          2.005463           -1.036166   \n",
       "\n",
       "               h1n1_knowledge_2.0  opinion_h1n1_vacc_effective_2.0  \\\n",
       "respondent_id                                                        \n",
       "12299                   -0.805423                        -0.228625   \n",
       "8759                     1.241583                        -0.228625   \n",
       "6713                    -0.805423                         4.373966   \n",
       "7993                     1.241583                        -0.228625   \n",
       "8635                    -0.805423                        -0.228625   \n",
       "...                           ...                              ...   \n",
       "10407                   -0.805423                        -0.228625   \n",
       "7443                     1.241583                        -0.228625   \n",
       "16022                   -0.805423                        -0.228625   \n",
       "2569                    -0.805423                        -0.228625   \n",
       "14084                    1.241583                        -0.228625   \n",
       "\n",
       "               opinion_h1n1_vacc_effective_3.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.412158   \n",
       "8759                                 -0.412158   \n",
       "6713                                 -0.412158   \n",
       "7993                                 -0.412158   \n",
       "8635                                  2.426257   \n",
       "...                                        ...   \n",
       "10407                                -0.412158   \n",
       "7443                                 -0.412158   \n",
       "16022                                -0.412158   \n",
       "2569                                  2.426257   \n",
       "14084                                -0.412158   \n",
       "\n",
       "               opinion_h1n1_vacc_effective_4.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.861933   \n",
       "8759                                 -0.861933   \n",
       "6713                                 -0.861933   \n",
       "7993                                 -0.861933   \n",
       "8635                                 -0.861933   \n",
       "...                                        ...   \n",
       "10407                                 1.160184   \n",
       "7443                                  1.160184   \n",
       "16022                                 1.160184   \n",
       "2569                                 -0.861933   \n",
       "14084                                 1.160184   \n",
       "\n",
       "               opinion_h1n1_vacc_effective_5.0  opinion_h1n1_risk_2.0  \\\n",
       "respondent_id                                                           \n",
       "12299                                 1.346931              -0.750922   \n",
       "8759                                  1.346931              -0.750922   \n",
       "6713                                 -0.742428               1.331696   \n",
       "7993                                  1.346931              -0.750922   \n",
       "8635                                 -0.742428              -0.750922   \n",
       "...                                        ...                    ...   \n",
       "10407                                -0.742428              -0.750922   \n",
       "7443                                 -0.742428               1.331696   \n",
       "16022                                -0.742428               1.331696   \n",
       "2569                                 -0.742428               1.331696   \n",
       "14084                                -0.742428              -0.750922   \n",
       "\n",
       "               opinion_h1n1_risk_3.0  opinion_h1n1_risk_4.0  \\\n",
       "respondent_id                                                 \n",
       "12299                      -0.202322               1.683623   \n",
       "8759                       -0.202322               1.683623   \n",
       "6713                       -0.202322              -0.593957   \n",
       "7993                       -0.202322              -0.593957   \n",
       "8635                        4.942607              -0.593957   \n",
       "...                              ...                    ...   \n",
       "10407                      -0.202322               1.683623   \n",
       "7443                       -0.202322              -0.593957   \n",
       "16022                      -0.202322              -0.593957   \n",
       "2569                       -0.202322              -0.593957   \n",
       "14084                      -0.202322              -0.593957   \n",
       "\n",
       "               opinion_h1n1_risk_5.0  opinion_h1n1_sick_from_vacc_2.0  \\\n",
       "respondent_id                                                           \n",
       "12299                      -0.336953                        -0.714225   \n",
       "8759                       -0.336953                        -0.714225   \n",
       "6713                       -0.336953                         1.400120   \n",
       "7993                        2.967776                         1.400120   \n",
       "8635                       -0.336953                         1.400120   \n",
       "...                              ...                              ...   \n",
       "10407                      -0.336953                        -0.714225   \n",
       "7443                       -0.336953                         1.400120   \n",
       "16022                      -0.336953                         1.400120   \n",
       "2569                       -0.336953                        -0.714225   \n",
       "14084                       2.967776                        -0.714225   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc_3.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.069398   \n",
       "8759                                 -0.069398   \n",
       "6713                                 -0.069398   \n",
       "7993                                 -0.069398   \n",
       "8635                                 -0.069398   \n",
       "...                                        ...   \n",
       "10407                                -0.069398   \n",
       "7443                                 -0.069398   \n",
       "16022                                -0.069398   \n",
       "2569                                 -0.069398   \n",
       "14084                                -0.069398   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc_4.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.551173   \n",
       "8759                                 -0.551173   \n",
       "6713                                 -0.551173   \n",
       "7993                                 -0.551173   \n",
       "8635                                 -0.551173   \n",
       "...                                        ...   \n",
       "10407                                 1.814311   \n",
       "7443                                 -0.551173   \n",
       "16022                                -0.551173   \n",
       "2569                                 -0.551173   \n",
       "14084                                -0.551173   \n",
       "\n",
       "               opinion_h1n1_sick_from_vacc_5.0  \\\n",
       "respondent_id                                    \n",
       "12299                                 3.094517   \n",
       "8759                                  3.094517   \n",
       "6713                                 -0.323152   \n",
       "7993                                 -0.323152   \n",
       "8635                                 -0.323152   \n",
       "...                                        ...   \n",
       "10407                                -0.323152   \n",
       "7443                                 -0.323152   \n",
       "16022                                -0.323152   \n",
       "2569                                 -0.323152   \n",
       "14084                                 3.094517   \n",
       "\n",
       "               opinion_seas_vacc_effective_2.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.261602   \n",
       "8759                                 -0.261602   \n",
       "6713                                  3.822597   \n",
       "7993                                 -0.261602   \n",
       "8635                                 -0.261602   \n",
       "...                                        ...   \n",
       "10407                                -0.261602   \n",
       "7443                                 -0.261602   \n",
       "16022                                -0.261602   \n",
       "2569                                 -0.261602   \n",
       "14084                                -0.261602   \n",
       "\n",
       "               opinion_seas_vacc_effective_3.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.198796   \n",
       "8759                                 -0.198796   \n",
       "6713                                 -0.198796   \n",
       "7993                                 -0.198796   \n",
       "8635                                 -0.198796   \n",
       "...                                        ...   \n",
       "10407                                -0.198796   \n",
       "7443                                 -0.198796   \n",
       "16022                                -0.198796   \n",
       "2569                                 -0.198796   \n",
       "14084                                -0.198796   \n",
       "\n",
       "               opinion_seas_vacc_effective_4.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.865008   \n",
       "8759                                 -0.865008   \n",
       "6713                                 -0.865008   \n",
       "7993                                 -0.865008   \n",
       "8635                                 -0.865008   \n",
       "...                                        ...   \n",
       "10407                                 1.156059   \n",
       "7443                                 -0.865008   \n",
       "16022                                 1.156059   \n",
       "2569                                 -0.865008   \n",
       "14084                                -0.865008   \n",
       "\n",
       "               opinion_seas_vacc_effective_5.0  opinion_seas_risk_2.0  \\\n",
       "respondent_id                                                           \n",
       "12299                                 1.137981              -0.692080   \n",
       "8759                                  1.137981              -0.692080   \n",
       "6713                                 -0.878750               1.444919   \n",
       "7993                                  1.137981              -0.692080   \n",
       "8635                                  1.137981              -0.692080   \n",
       "...                                        ...                    ...   \n",
       "10407                                -0.878750              -0.692080   \n",
       "7443                                  1.137981              -0.692080   \n",
       "16022                                -0.878750               1.444919   \n",
       "2569                                  1.137981               1.444919   \n",
       "14084                                 1.137981              -0.692080   \n",
       "\n",
       "               opinion_seas_risk_3.0  opinion_seas_risk_4.0  \\\n",
       "respondent_id                                                 \n",
       "12299                      -0.170728              -0.696388   \n",
       "8759                       -0.170728              -0.696388   \n",
       "6713                       -0.170728              -0.696388   \n",
       "7993                       -0.170728              -0.696388   \n",
       "8635                        5.857277              -0.696388   \n",
       "...                              ...                    ...   \n",
       "10407                      -0.170728               1.435981   \n",
       "7443                       -0.170728               1.435981   \n",
       "16022                      -0.170728              -0.696388   \n",
       "2569                       -0.170728              -0.696388   \n",
       "14084                      -0.170728              -0.696388   \n",
       "\n",
       "               opinion_seas_risk_5.0  opinion_seas_sick_from_vacc_2.0  \\\n",
       "respondent_id                                                           \n",
       "12299                       2.430524                        -0.646513   \n",
       "8759                        2.430524                        -0.646513   \n",
       "6713                       -0.411434                         1.546758   \n",
       "7993                        2.430524                         1.546758   \n",
       "8635                       -0.411434                        -0.646513   \n",
       "...                              ...                              ...   \n",
       "10407                      -0.411434                        -0.646513   \n",
       "7443                       -0.411434                        -0.646513   \n",
       "16022                      -0.411434                         1.546758   \n",
       "2569                       -0.411434                        -0.646513   \n",
       "14084                       2.430524                        -0.646513   \n",
       "\n",
       "               opinion_seas_sick_from_vacc_3.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.049013   \n",
       "8759                                 -0.049013   \n",
       "6713                                 -0.049013   \n",
       "7993                                 -0.049013   \n",
       "8635                                 -0.049013   \n",
       "...                                        ...   \n",
       "10407                                -0.049013   \n",
       "7443                                 -0.049013   \n",
       "16022                                -0.049013   \n",
       "2569                                 -0.049013   \n",
       "14084                                -0.049013   \n",
       "\n",
       "               opinion_seas_sick_from_vacc_4.0  \\\n",
       "respondent_id                                    \n",
       "12299                                -0.473631   \n",
       "8759                                 -0.473631   \n",
       "6713                                 -0.473631   \n",
       "7993                                 -0.473631   \n",
       "8635                                  2.111348   \n",
       "...                                        ...   \n",
       "10407                                 2.111348   \n",
       "7443                                 -0.473631   \n",
       "16022                                -0.473631   \n",
       "2569                                 -0.473631   \n",
       "14084                                -0.473631   \n",
       "\n",
       "               opinion_seas_sick_from_vacc_5.0  age_group_35_to_44 Years  \\\n",
       "respondent_id                                                              \n",
       "12299                                 3.795087                  2.554328   \n",
       "8759                                  3.795087                 -0.391492   \n",
       "6713                                 -0.263499                 -0.391492   \n",
       "7993                                 -0.263499                 -0.391492   \n",
       "8635                                 -0.263499                 -0.391492   \n",
       "...                                        ...                       ...   \n",
       "10407                                -0.263499                 -0.391492   \n",
       "7443                                 -0.263499                 -0.391492   \n",
       "16022                                -0.263499                 -0.391492   \n",
       "2569                                 -0.263499                 -0.391492   \n",
       "14084                                 3.795087                 -0.391492   \n",
       "\n",
       "               age_group_45_to_54 Years  age_group_55_to_64 Years  \\\n",
       "respondent_id                                                       \n",
       "12299                         -0.480513                 -0.539910   \n",
       "8759                           2.081108                 -0.539910   \n",
       "6713                          -0.480513                 -0.539910   \n",
       "7993                          -0.480513                 -0.539910   \n",
       "8635                          -0.480513                 -0.539910   \n",
       "...                                 ...                       ...   \n",
       "10407                         -0.480513                 -0.539910   \n",
       "7443                          -0.480513                  1.852161   \n",
       "16022                         -0.480513                  1.852161   \n",
       "2569                          -0.480513                 -0.539910   \n",
       "14084                         -0.480513                  1.852161   \n",
       "\n",
       "               age_group_Over_65  education_< 12 Years  \\\n",
       "respondent_id                                            \n",
       "12299                  -0.601175             -0.293704   \n",
       "8759                   -0.601175             -0.293704   \n",
       "6713                   -0.601175             -0.293704   \n",
       "7993                   -0.601175             -0.293704   \n",
       "8635                    1.663408             -0.293704   \n",
       "...                          ...                   ...   \n",
       "10407                  -0.601175             -0.293704   \n",
       "7443                   -0.601175             -0.293704   \n",
       "16022                  -0.601175             -0.293704   \n",
       "2569                    1.663408             -0.293704   \n",
       "14084                  -0.601175             -0.293704   \n",
       "\n",
       "               education_College Graduate  education_Some College  \\\n",
       "respondent_id                                                       \n",
       "12299                           -0.897984                1.675103   \n",
       "8759                            -0.897984               -0.596978   \n",
       "6713                             1.113605               -0.596978   \n",
       "7993                            -0.897984                1.675103   \n",
       "8635                            -0.897984                1.675103   \n",
       "...                                   ...                     ...   \n",
       "10407                            1.113605               -0.596978   \n",
       "7443                            -0.897984                1.675103   \n",
       "16022                            1.113605               -0.596978   \n",
       "2569                             1.113605               -0.596978   \n",
       "14084                           -0.897984               -0.596978   \n",
       "\n",
       "               race_Hispanic  race_Other or Multiple  race_White  sex_Male  \\\n",
       "respondent_id                                                                \n",
       "12299              -0.272372               -0.256816   -1.997960 -0.818908   \n",
       "8759               -0.272372               -0.256816    0.500511 -0.818908   \n",
       "6713                3.671443               -0.256816   -1.997960 -0.818908   \n",
       "7993               -0.272372               -0.256816   -1.997960 -0.818908   \n",
       "8635               -0.272372               -0.256816    0.500511 -0.818908   \n",
       "...                      ...                     ...         ...       ...   \n",
       "10407              -0.272372               -0.256816    0.500511 -0.818908   \n",
       "7443               -0.272372               -0.256816    0.500511 -0.818908   \n",
       "16022              -0.272372               -0.256816   -1.997960 -0.818908   \n",
       "2569               -0.272372               -0.256816    0.500511 -0.818908   \n",
       "14084              -0.272372               -0.256816    0.500511 -0.818908   \n",
       "\n",
       "               income_poverty_Above Poverty  income_poverty_Below Poverty  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.934391                      3.051984   \n",
       "8759                              -0.934391                      3.051984   \n",
       "6713                              -0.934391                      3.051984   \n",
       "7993                              -0.934391                      3.051984   \n",
       "8635                               1.070215                     -0.327656   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.934391                     -0.327656   \n",
       "7443                               1.070215                     -0.327656   \n",
       "16022                             -0.934391                     -0.327656   \n",
       "2569                              -0.934391                     -0.327656   \n",
       "14084                              1.070215                     -0.327656   \n",
       "\n",
       "               income_poverty_unknown  marital_status_Not Married  \\\n",
       "respondent_id                                                       \n",
       "12299                       -0.447389                    1.165106   \n",
       "8759                        -0.447389                    1.165106   \n",
       "6713                        -0.447389                    1.165106   \n",
       "7993                        -0.447389                    1.165106   \n",
       "8635                        -0.447389                   -0.858291   \n",
       "...                               ...                         ...   \n",
       "10407                        2.235191                   -0.858291   \n",
       "7443                        -0.447389                   -0.858291   \n",
       "16022                       -0.447389                   -0.858291   \n",
       "2569                        -0.447389                   -0.858291   \n",
       "14084                       -0.447389                    1.165106   \n",
       "\n",
       "               employment_status_Not in Labor Force  \\\n",
       "respondent_id                                         \n",
       "12299                                     -0.794802   \n",
       "8759                                       1.258175   \n",
       "6713                                      -0.794802   \n",
       "7993                                      -0.794802   \n",
       "8635                                       1.258175   \n",
       "...                                             ...   \n",
       "10407                                     -0.794802   \n",
       "7443                                       1.258175   \n",
       "16022                                      1.258175   \n",
       "2569                                       1.258175   \n",
       "14084                                     -0.794802   \n",
       "\n",
       "               employment_status_Unemployed  hhs_geo_region_bhuqouqj  \\\n",
       "respondent_id                                                          \n",
       "12299                             -0.226507                -0.358216   \n",
       "8759                              -0.226507                 2.791613   \n",
       "6713                              -0.226507                 2.791613   \n",
       "7993                              -0.226507                -0.358216   \n",
       "8635                              -0.226507                -0.358216   \n",
       "...                                     ...                      ...   \n",
       "10407                             -0.226507                -0.358216   \n",
       "7443                              -0.226507                -0.358216   \n",
       "16022                             -0.226507                -0.358216   \n",
       "2569                              -0.226507                -0.358216   \n",
       "14084                             -0.226507                -0.358216   \n",
       "\n",
       "               hhs_geo_region_dqpwygqj  hhs_geo_region_fpwskwrf  \\\n",
       "respondent_id                                                     \n",
       "12299                        -0.202031                 2.735743   \n",
       "8759                         -0.202031                -0.365531   \n",
       "6713                         -0.202031                -0.365531   \n",
       "7993                         -0.202031                -0.365531   \n",
       "8635                         -0.202031                -0.365531   \n",
       "...                                ...                      ...   \n",
       "10407                        -0.202031                 2.735743   \n",
       "7443                         -0.202031                -0.365531   \n",
       "16022                        -0.202031                -0.365531   \n",
       "2569                         -0.202031                 2.735743   \n",
       "14084                        -0.202031                -0.365531   \n",
       "\n",
       "               hhs_geo_region_kbazzjca  hhs_geo_region_lrircsnp  \\\n",
       "respondent_id                                                     \n",
       "12299                        -0.346297                -0.292389   \n",
       "8759                         -0.346297                -0.292389   \n",
       "6713                         -0.346297                -0.292389   \n",
       "7993                         -0.346297                -0.292389   \n",
       "8635                         -0.346297                -0.292389   \n",
       "...                                ...                      ...   \n",
       "10407                        -0.346297                -0.292389   \n",
       "7443                         -0.346297                -0.292389   \n",
       "16022                        -0.346297                -0.292389   \n",
       "2569                         -0.346297                -0.292389   \n",
       "14084                        -0.346297                 3.420102   \n",
       "\n",
       "               hhs_geo_region_lzgpxyit  hhs_geo_region_mlyzmhmf  \\\n",
       "respondent_id                                                     \n",
       "12299                        -0.428842                -0.310664   \n",
       "8759                         -0.428842                -0.310664   \n",
       "6713                         -0.428842                -0.310664   \n",
       "7993                          2.331864                -0.310664   \n",
       "8635                          2.331864                -0.310664   \n",
       "...                                ...                      ...   \n",
       "10407                        -0.428842                -0.310664   \n",
       "7443                          2.331864                -0.310664   \n",
       "16022                         2.331864                -0.310664   \n",
       "2569                         -0.428842                -0.310664   \n",
       "14084                        -0.428842                -0.310664   \n",
       "\n",
       "               hhs_geo_region_oxchjgsf  hhs_geo_region_qufhixun  \\\n",
       "respondent_id                                                     \n",
       "12299                         -0.34531                -0.365723   \n",
       "8759                          -0.34531                -0.365723   \n",
       "6713                          -0.34531                -0.365723   \n",
       "7993                          -0.34531                -0.365723   \n",
       "8635                          -0.34531                -0.365723   \n",
       "...                                ...                      ...   \n",
       "10407                         -0.34531                -0.365723   \n",
       "7443                          -0.34531                -0.365723   \n",
       "16022                         -0.34531                -0.365723   \n",
       "2569                          -0.34531                -0.365723   \n",
       "14084                         -0.34531                -0.365723   \n",
       "\n",
       "               census_msa_MSA, Principle City  census_msa_Non-MSA  \\\n",
       "respondent_id                                                       \n",
       "12299                               -0.646175            1.640034   \n",
       "8759                                 1.547569           -0.609744   \n",
       "6713                                 1.547569           -0.609744   \n",
       "7993                                -0.646175            1.640034   \n",
       "8635                                -0.646175           -0.609744   \n",
       "...                                       ...                 ...   \n",
       "10407                               -0.646175           -0.609744   \n",
       "7443                                -0.646175           -0.609744   \n",
       "16022                               -0.646175           -0.609744   \n",
       "2569                                -0.646175           -0.609744   \n",
       "14084                               -0.646175            1.640034   \n",
       "\n",
       "               employment_industry_atmlpfrs  employment_industry_cfqqtusy  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.176389                     -0.108597   \n",
       "8759                              -0.176389                     -0.108597   \n",
       "6713                              -0.176389                     -0.108597   \n",
       "7993                              -0.176389                     -0.108597   \n",
       "8635                              -0.176389                     -0.108597   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.176389                     -0.108597   \n",
       "7443                              -0.176389                     -0.108597   \n",
       "16022                             -0.176389                     -0.108597   \n",
       "2569                              -0.176389                     -0.108597   \n",
       "14084                             -0.176389                     -0.108597   \n",
       "\n",
       "               employment_industry_dotnnunm  employment_industry_fcxhlnwr  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.076203                      2.721506   \n",
       "8759                              -0.076203                     -0.367444   \n",
       "6713                              -0.076203                     -0.367444   \n",
       "7993                              -0.076203                     -0.367444   \n",
       "8635                              -0.076203                     -0.367444   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.076203                     -0.367444   \n",
       "7443                              -0.076203                     -0.367444   \n",
       "16022                             -0.076203                     -0.367444   \n",
       "2569                              -0.076203                     -0.367444   \n",
       "14084                             -0.076203                      2.721506   \n",
       "\n",
       "               employment_industry_haxffmxo  employment_industry_ldnlellj  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.097246                     -0.210074   \n",
       "8759                              -0.097246                     -0.210074   \n",
       "6713                              -0.097246                     -0.210074   \n",
       "7993                              -0.097246                     -0.210074   \n",
       "8635                              -0.097246                     -0.210074   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.097246                     -0.210074   \n",
       "7443                              -0.097246                     -0.210074   \n",
       "16022                             -0.097246                     -0.210074   \n",
       "2569                              -0.097246                     -0.210074   \n",
       "14084                             -0.097246                     -0.210074   \n",
       "\n",
       "               employment_industry_mcubkhph  employment_industry_mfikgejo  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.093168                     -0.135705   \n",
       "8759                              -0.093168                     -0.135705   \n",
       "6713                              -0.093168                     -0.135705   \n",
       "7993                              -0.093168                     -0.135705   \n",
       "8635                              -0.093168                     -0.135705   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.093168                     -0.135705   \n",
       "7443                              -0.093168                     -0.135705   \n",
       "16022                             -0.093168                     -0.135705   \n",
       "2569                              -0.093168                     -0.135705   \n",
       "14084                             -0.093168                     -0.135705   \n",
       "\n",
       "               employment_industry_msuufmds  employment_industry_nduyfdeo  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.064472                     -0.101713   \n",
       "8759                              -0.064472                     -0.101713   \n",
       "6713                              -0.064472                     -0.101713   \n",
       "7993                              -0.064472                     -0.101713   \n",
       "8635                              -0.064472                     -0.101713   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.064472                     -0.101713   \n",
       "7443                              -0.064472                     -0.101713   \n",
       "16022                             -0.064472                     -0.101713   \n",
       "2569                              -0.064472                     -0.101713   \n",
       "14084                             -0.064472                     -0.101713   \n",
       "\n",
       "               employment_industry_phxvnwax  employment_industry_pxcmvdjn  \\\n",
       "respondent_id                                                               \n",
       "12299                              -0.05821                     -0.192494   \n",
       "8759                               -0.05821                     -0.192494   \n",
       "6713                               -0.05821                     -0.192494   \n",
       "7993                               -0.05821                     -0.192494   \n",
       "8635                               -0.05821                     -0.192494   \n",
       "...                                     ...                           ...   \n",
       "10407                              -0.05821                     -0.192494   \n",
       "7443                               -0.05821                     -0.192494   \n",
       "16022                              -0.05821                     -0.192494   \n",
       "2569                               -0.05821                     -0.192494   \n",
       "14084                              -0.05821                     -0.192494   \n",
       "\n",
       "               employment_industry_qnlwzans  employment_industry_rucpziij  \\\n",
       "respondent_id                                                               \n",
       "12299                              -0.01808                     -0.129756   \n",
       "8759                               -0.01808                     -0.129756   \n",
       "6713                               -0.01808                      7.706798   \n",
       "7993                               -0.01808                      7.706798   \n",
       "8635                               -0.01808                     -0.129756   \n",
       "...                                     ...                           ...   \n",
       "10407                              -0.01808                     -0.129756   \n",
       "7443                               -0.01808                     -0.129756   \n",
       "16022                              -0.01808                     -0.129756   \n",
       "2569                               -0.01808                     -0.129756   \n",
       "14084                              -0.01808                     -0.129756   \n",
       "\n",
       "               employment_industry_saaquncn  employment_industry_unknown  \\\n",
       "respondent_id                                                              \n",
       "12299                               -0.1146                    -0.988088   \n",
       "8759                                -0.1146                     1.012055   \n",
       "6713                                -0.1146                    -0.988088   \n",
       "7993                                -0.1146                    -0.988088   \n",
       "8635                                -0.1146                     1.012055   \n",
       "...                                     ...                          ...   \n",
       "10407                               -0.1146                     1.012055   \n",
       "7443                                -0.1146                     1.012055   \n",
       "16022                               -0.1146                     1.012055   \n",
       "2569                                -0.1146                     1.012055   \n",
       "14084                               -0.1146                    -0.988088   \n",
       "\n",
       "               employment_industry_vjjrobsf  employment_industry_wlfvacwt  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.136121                     -0.087024   \n",
       "8759                              -0.136121                     -0.087024   \n",
       "6713                              -0.136121                     -0.087024   \n",
       "7993                              -0.136121                     -0.087024   \n",
       "8635                              -0.136121                     -0.087024   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.136121                     -0.087024   \n",
       "7443                              -0.136121                     -0.087024   \n",
       "16022                             -0.136121                     -0.087024   \n",
       "2569                              -0.136121                     -0.087024   \n",
       "14084                             -0.136121                     -0.087024   \n",
       "\n",
       "               employment_industry_wxleyezf  employment_industry_xicduogh  \\\n",
       "respondent_id                                                               \n",
       "12299                             -0.282843                     -0.167662   \n",
       "8759                              -0.282843                     -0.167662   \n",
       "6713                              -0.282843                     -0.167662   \n",
       "7993                              -0.282843                     -0.167662   \n",
       "8635                              -0.282843                     -0.167662   \n",
       "...                                     ...                           ...   \n",
       "10407                             -0.282843                     -0.167662   \n",
       "7443                              -0.282843                     -0.167662   \n",
       "16022                             -0.282843                     -0.167662   \n",
       "2569                              -0.282843                     -0.167662   \n",
       "14084                             -0.282843                     -0.167662   \n",
       "\n",
       "               employment_industry_xqicxuve  employment_occupation_ccgxvspp  \\\n",
       "respondent_id                                                                 \n",
       "12299                              -0.13403                       -0.116536   \n",
       "8759                               -0.13403                       -0.116536   \n",
       "6713                               -0.13403                       -0.116536   \n",
       "7993                               -0.13403                       -0.116536   \n",
       "8635                               -0.13403                       -0.116536   \n",
       "...                                     ...                             ...   \n",
       "10407                              -0.13403                       -0.116536   \n",
       "7443                               -0.13403                       -0.116536   \n",
       "16022                              -0.13403                       -0.116536   \n",
       "2569                               -0.13403                       -0.116536   \n",
       "14084                              -0.13403                       -0.116536   \n",
       "\n",
       "               employment_occupation_cmhcxjea  employment_occupation_dcjcmpih  \\\n",
       "respondent_id                                                                   \n",
       "12299                               -0.265385                       -0.097246   \n",
       "8759                                -0.265385                       -0.097246   \n",
       "6713                                -0.265385                       -0.097246   \n",
       "7993                                -0.265385                       -0.097246   \n",
       "8635                                -0.265385                       -0.097246   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.265385                       -0.097246   \n",
       "7443                                -0.265385                       -0.097246   \n",
       "16022                               -0.265385                       -0.097246   \n",
       "2569                                -0.265385                       -0.097246   \n",
       "14084                               -0.265385                       -0.097246   \n",
       "\n",
       "               employment_occupation_dlvbwzss  employment_occupation_emcorrxb  \\\n",
       "respondent_id                                                                   \n",
       "12299                                -0.10006                       -0.235662   \n",
       "8759                                 -0.10006                       -0.235662   \n",
       "6713                                 -0.10006                       -0.235662   \n",
       "7993                                 -0.10006                       -0.235662   \n",
       "8635                                 -0.10006                       -0.235662   \n",
       "...                                       ...                             ...   \n",
       "10407                                -0.10006                       -0.235662   \n",
       "7443                                 -0.10006                       -0.235662   \n",
       "16022                                -0.10006                       -0.235662   \n",
       "2569                                 -0.10006                       -0.235662   \n",
       "14084                                -0.10006                       -0.235662   \n",
       "\n",
       "               employment_occupation_haliazsg  employment_occupation_hfxkjkmi  \\\n",
       "respondent_id                                                                   \n",
       "12299                                8.581034                       -0.159591   \n",
       "8759                                -0.116536                       -0.159591   \n",
       "6713                                -0.116536                       -0.159591   \n",
       "7993                                -0.116536                       -0.159591   \n",
       "8635                                -0.116536                       -0.159591   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.116536                       -0.159591   \n",
       "7443                                -0.116536                       -0.159591   \n",
       "16022                               -0.116536                       -0.159591   \n",
       "2569                                -0.116536                       -0.159591   \n",
       "14084                               -0.116536                       -0.159591   \n",
       "\n",
       "               employment_occupation_hodpvpew  employment_occupation_kldqjyjy  \\\n",
       "respondent_id                                                                   \n",
       "12299                               -0.088911                       -0.133185   \n",
       "8759                                -0.088911                       -0.133185   \n",
       "6713                                -0.088911                       -0.133185   \n",
       "7993                                -0.088911                       -0.133185   \n",
       "8635                                -0.088911                       -0.133185   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.088911                       -0.133185   \n",
       "7443                                -0.088911                       -0.133185   \n",
       "16022                               -0.088911                       -0.133185   \n",
       "2569                                -0.088911                       -0.133185   \n",
       "14084                               -0.088911                       -0.133185   \n",
       "\n",
       "               employment_occupation_mxkfnird  employment_occupation_oijqvulv  \\\n",
       "respondent_id                                                                   \n",
       "12299                               -0.241779                       -0.113128   \n",
       "8759                                -0.241779                       -0.113128   \n",
       "6713                                -0.241779                       -0.113128   \n",
       "7993                                -0.241779                       -0.113128   \n",
       "8635                                -0.241779                       -0.113128   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.241779                       -0.113128   \n",
       "7443                                -0.241779                       -0.113128   \n",
       "16022                               -0.241779                       -0.113128   \n",
       "2569                                -0.241779                       -0.113128   \n",
       "14084                                4.136002                       -0.113128   \n",
       "\n",
       "               employment_occupation_pvmttkik  employment_occupation_qxajmpny  \\\n",
       "respondent_id                                                                   \n",
       "12299                                -0.05821                       -0.129756   \n",
       "8759                                 -0.05821                       -0.129756   \n",
       "6713                                 -0.05821                       -0.129756   \n",
       "7993                                 -0.05821                       -0.129756   \n",
       "8635                                 -0.05821                       -0.129756   \n",
       "...                                       ...                             ...   \n",
       "10407                                -0.05821                       -0.129756   \n",
       "7443                                 -0.05821                       -0.129756   \n",
       "16022                                -0.05821                       -0.129756   \n",
       "2569                                 -0.05821                       -0.129756   \n",
       "14084                                -0.05821                       -0.129756   \n",
       "\n",
       "               employment_occupation_rcertsgn  employment_occupation_tfqavkke  \\\n",
       "respondent_id                                                                   \n",
       "12299                               -0.084446                       -0.112136   \n",
       "8759                                -0.084446                       -0.112136   \n",
       "6713                                -0.084446                        8.917753   \n",
       "7993                                -0.084446                       -0.112136   \n",
       "8635                                -0.084446                       -0.112136   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.084446                       -0.112136   \n",
       "7443                                -0.084446                       -0.112136   \n",
       "16022                               -0.084446                       -0.112136   \n",
       "2569                                -0.084446                       -0.112136   \n",
       "14084                               -0.084446                       -0.112136   \n",
       "\n",
       "               employment_occupation_ukymxvdu  employment_occupation_unknown  \\\n",
       "respondent_id                                                                  \n",
       "12299                               -0.108597                      -0.999782   \n",
       "8759                                -0.108597                       1.000218   \n",
       "6713                                -0.108597                      -0.999782   \n",
       "7993                                -0.108597                      -0.999782   \n",
       "8635                                -0.108597                       1.000218   \n",
       "...                                       ...                            ...   \n",
       "10407                               -0.108597                       1.000218   \n",
       "7443                                -0.108597                       1.000218   \n",
       "16022                               -0.108597                       1.000218   \n",
       "2569                                -0.108597                       1.000218   \n",
       "14084                               -0.108597                      -0.999782   \n",
       "\n",
       "               employment_occupation_uqqtjvyb  employment_occupation_vlluhbov  \\\n",
       "respondent_id                                                                   \n",
       "12299                               -0.120784                       -0.120784   \n",
       "8759                                -0.120784                       -0.120784   \n",
       "6713                                -0.120784                       -0.120784   \n",
       "7993                                -0.120784                       -0.120784   \n",
       "8635                                -0.120784                       -0.120784   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.120784                       -0.120784   \n",
       "7443                                -0.120784                       -0.120784   \n",
       "16022                               -0.120784                       -0.120784   \n",
       "2569                                -0.120784                       -0.120784   \n",
       "14084                               -0.120784                       -0.120784   \n",
       "\n",
       "               employment_occupation_xgwztkwe  employment_occupation_xqwwgdyp  \\\n",
       "respondent_id                                                                   \n",
       "12299                               -0.195816                       -0.125345   \n",
       "8759                                -0.195816                       -0.125345   \n",
       "6713                                -0.195816                       -0.125345   \n",
       "7993                                 5.106823                       -0.125345   \n",
       "8635                                -0.195816                       -0.125345   \n",
       "...                                       ...                             ...   \n",
       "10407                               -0.195816                       -0.125345   \n",
       "7443                                -0.195816                       -0.125345   \n",
       "16022                               -0.195816                       -0.125345   \n",
       "2569                                -0.195816                       -0.125345   \n",
       "14084                               -0.195816                       -0.125345   \n",
       "\n",
       "               employment_occupation_xtkaffoo  employment_occupation_xzmlyyjv  \\\n",
       "respondent_id                                                                   \n",
       "12299                                -0.26184                       -0.089531   \n",
       "8759                                 -0.26184                       -0.089531   \n",
       "6713                                 -0.26184                       -0.089531   \n",
       "7993                                 -0.26184                       -0.089531   \n",
       "8635                                 -0.26184                       -0.089531   \n",
       "...                                       ...                             ...   \n",
       "10407                                -0.26184                       -0.089531   \n",
       "7443                                 -0.26184                       -0.089531   \n",
       "16022                                -0.26184                       -0.089531   \n",
       "2569                                 -0.26184                       -0.089531   \n",
       "14084                                -0.26184                       -0.089531   \n",
       "\n",
       "               doctor_recc_seasonal education_Some College  \\\n",
       "respondent_id                                                \n",
       "12299                                             2.945054   \n",
       "8759                                             -0.339552   \n",
       "6713                                             -0.339552   \n",
       "7993                                              2.945054   \n",
       "8635                                              2.945054   \n",
       "...                                                    ...   \n",
       "10407                                            -0.339552   \n",
       "7443                                              2.945054   \n",
       "16022                                            -0.339552   \n",
       "2569                                             -0.339552   \n",
       "14084                                            -0.339552   \n",
       "\n",
       "               doctor_recc_seasonal sex_Male  h1n1_vaccine  \n",
       "respondent_id                                               \n",
       "12299                              -0.399229             1  \n",
       "8759                               -0.399229             1  \n",
       "6713                               -0.399229             1  \n",
       "7993                               -0.399229             1  \n",
       "8635                               -0.399229             1  \n",
       "...                                      ...           ...  \n",
       "10407                              -0.399229             1  \n",
       "7443                               -0.399229             0  \n",
       "16022                              -0.399229             0  \n",
       "2569                               -0.399229             1  \n",
       "14084                              -0.399229             1  \n",
       "\n",
       "[14522 rows x 126 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates a downsampled object storing the data with no scaling or interactions.\n",
    "unscaled = DataPreprocessor(df, target_col1, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "unscaled.data_preprocessing(balance_class='downsample', scale_type=False)\n",
    "\n",
    "#creates a downsampled object storing the data with scaling and no interactions.\n",
    "scaled = DataPreprocessor(df, target_col1, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "scaled.data_preprocessing(balance_class='downsample', scale_type=\"standard\")\n",
    "\n",
    "#creates a downsampled object storing the data with scaling and no interactions and minimizes features.\n",
    "select_features = ['doctor_recc_h1n1', 'opinion_h1n1_vacc_effective_5.0', 'missing_health_insurance', 'opinion_h1n1_risk_4.0',\n",
    "                   'opinion_h1n1_risk_5.0', 'household_adults', 'health_worker', 'marital_status_Not Married']\n",
    "reduced = DataPreprocessor(df, target_col1, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "reduced.data_preprocessing(balance_class='downsample', scale_type=\"standard\")\n",
    "reduced.column_drop(reduced.cols)\n",
    "reduced.column_drop(select_features, reverse=True)\n",
    "\n",
    "#creates a downsampled object storing the data with scaling select interactions.\n",
    "interactions = DataPreprocessor(df, target_col1, categorical, continuous, polynomial, True, True,random_state=124)\n",
    "interactions.data_preprocessing(balance_class='downsample', scale_type=\"standard\", poly_degree=2)\n",
    "interactions.column_drop(interactions.cols_polynomial)\n",
    "interactions.column_drop(['doctor_recc_seasonal education_Some College',\n",
    "                  'doctor_recc_seasonal sex_Male'], reverse=True)\n",
    "interactions.get_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame with the dummy variables and the downsample class imblanace correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the Evaluation DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Details':[],\n",
    "                           'Accuracy':[],\n",
    "                           'Precision':[],\n",
    "                           'FP':[],\n",
    "                           'Recall':[],\n",
    "                           'FN':[],\n",
    "                           'F1-Score':[],\n",
    "                           'AUC':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"2\"></span>2. Logistic Regression\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_to_df(model, X_test, y_test, eval_df, title, description):\n",
    "    \"\"\"Evaluates a model, updating a dataframe that stores the results.\"\"\"\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "    print(f'{title}: {description}')\n",
    "    print('Confusion Matrix :')\n",
    "    print(cm)\n",
    "    print('Test Accuracy Score :',metrics.accuracy_score(y_test, y_pred))\n",
    "    print('Report : ')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    acc = float(format(metrics.accuracy_score(y_test, y_pred, sample_weight=None), '.3f'))\n",
    "    prec = float(format(metrics.precision_score(y_test, y_pred),'.3f'))\n",
    "    fp = cm[0,1]\n",
    "    rec = float(format(metrics.recall_score(y_test, y_pred),'.3f'))\n",
    "    fn = cm[1,0]\n",
    "    auc = float(format(metrics.roc_auc_score(y_test, y_pred),'.3f'))\n",
    "    f1 = float(format(metrics.f1_score(y_test, y_pred),'.3f'))\n",
    "\n",
    "    r = eval_df.shape[0]\n",
    "    eval_df.loc[r] = [title,description,acc,prec,fp,rec,fn,auc,f1]\n",
    "    return eval_df.sort_values(by = 'AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression-1: All Features, Not Scaled\n",
      "Confusion Matrix :\n",
      "[[3429  829]\n",
      " [ 265  819]]\n",
      "Test Accuracy Score : 0.7952077873455634\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86      4258\n",
      "           1       0.50      0.76      0.60      1084\n",
      "\n",
      "    accuracy                           0.80      5342\n",
      "   macro avg       0.71      0.78      0.73      5342\n",
      "weighted avg       0.84      0.80      0.81      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                   Details  Accuracy  Precision  \\\n",
       "0  Logistic Regression-1  All Features, Not Scaled     0.795      0.497   \n",
       "\n",
       "      FP  Recall     FN  F1-Score  AUC  \n",
       "0  829.0   0.756  265.0      0.78  0.6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logisitic Regression 1: All Features, Not Scaled\n",
    "logreg1 = LogisticRegression().fit(unscaled.get_X_train(), unscaled.y_train)\n",
    "\n",
    "evaluate_to_df(logreg1, unscaled.get_X_test(), unscaled.y_test, evaluation, 'Logistic Regression-1', 'All Features, Not Scaled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Optimizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression-2: All Features, Scaled\n",
      "Confusion Matrix :\n",
      "[[3427  831]\n",
      " [ 266  818]]\n",
      "Test Accuracy Score : 0.7946461999251216\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      4258\n",
      "           1       0.50      0.75      0.60      1084\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.71      0.78      0.73      5342\n",
      "weighted avg       0.84      0.79      0.81      5342\n",
      "\n",
      "Logistic Regression-3: Select Features, Scaled\n",
      "Confusion Matrix :\n",
      "[[3357  901]\n",
      " [ 281  803]]\n",
      "Test Accuracy Score : 0.7787345563459378\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85      4258\n",
      "           1       0.47      0.74      0.58      1084\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.70      0.76      0.71      5342\n",
      "weighted avg       0.83      0.78      0.79      5342\n",
      "\n",
      "Logistic Regression-4: All Features, Scaled, with Interactions\n",
      "Confusion Matrix :\n",
      "[[3432  826]\n",
      " [ 264  820]]\n",
      "Test Accuracy Score : 0.7959565705728192\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86      4258\n",
      "           1       0.50      0.76      0.60      1084\n",
      "\n",
      "    accuracy                           0.80      5342\n",
      "   macro avg       0.71      0.78      0.73      5342\n",
      "weighted avg       0.84      0.80      0.81      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1  Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "\n",
       "   Precision     FP  Recall     FN  F1-Score    AUC  \n",
       "3      0.498  826.0   0.756  264.0     0.781  0.601  \n",
       "0      0.497  829.0   0.756  265.0     0.780  0.600  \n",
       "1      0.496  831.0   0.755  266.0     0.780  0.599  \n",
       "2      0.471  901.0   0.741  281.0     0.765  0.576  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logisitic Regression 2: All Features, Scaled\n",
    "logreg2 = LogisticRegression().fit(scaled.get_X_train(), scaled.y_train)\n",
    "evaluate_to_df(logreg2, scaled.get_X_test(), scaled.y_test, evaluation, 'Logistic Regression-2', 'All Features, Scaled')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "#Logistic Regression: Select Features, Scaled\n",
    "logreg3 = LogisticRegression().fit(reduced.get_X_train(), reduced.y_train)\n",
    "evaluate_to_df(logreg3, reduced.get_X_test(), reduced.y_test, evaluation, 'Logistic Regression-3', 'Select Features, Scaled')\n",
    "\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "#Logistic Regression: Select Features, Scaled, with Interactions\n",
    "logreg4 = LogisticRegression().fit(interactions.get_X_train(), interactions.y_train)\n",
    "evaluate_to_df(logreg4, interactions.get_X_test(), interactions.y_test, evaluation, 'Logistic Regression-4', 'All Features, Scaled, with Interactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"3\"></span>3. K-Nearest Neighbor (K-NN)\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor: Baseline K=1\n",
      "Confusion Matrix :\n",
      "[[2875 1383]\n",
      " [ 369  715]]\n",
      "Test Accuracy Score : 0.6720329464619993\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77      4258\n",
      "           1       0.34      0.66      0.45      1084\n",
      "\n",
      "    accuracy                           0.67      5342\n",
      "   macro avg       0.61      0.67      0.61      5342\n",
      "weighted avg       0.78      0.67      0.70      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1  Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "   Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3      0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0      0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1      0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "2      0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "4      0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier()\n",
    "# Fit the classifier\n",
    "knn1.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(knn1, interactions.get_X_test(), interactions.y_test, evaluation, 'K-Nearest Neighbor', 'Baseline K=1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(X_train, y_train, X_test, y_test, min_k=1, max_k=25):\n",
    "    best_k = 0\n",
    "    best_score = 0.0\n",
    "    for k in range(min_k, max_k+1, 2):\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        preds = knn.predict(X_test)\n",
    "        f1 = metrics.f1_score(y_test, preds)\n",
    "        if f1 > best_score:\n",
    "            best_k = k\n",
    "            best_score = f1\n",
    "    print(\"Best Value for k: {}\".format(best_k))\n",
    "    print(\"F1-Score: {}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Value for k: 9\n",
      "F1-Score: 0.47028423772609823\n"
     ]
    }
   ],
   "source": [
    "find_best_k(interactions.get_X_train(), interactions.y_train, interactions.get_X_test(), interactions.y_test, min_k=1, max_k=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6557597159964801, 0.7507862336410064, 0.6932952855612802, 0.7532837166402875, 0.7021245055091099, 0.7494712766400834, 0.7156547495731275, 0.7483425710451154, 0.7202365132357981, 0.7465399674537562]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "k_range = list(range(1, 11))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(interactions.get_X_train(), interactions.y_train)\n",
    "    y_predict = knn.predict(interactions.get_X_test())\n",
    "    score = metrics.f1_score(interactions.y_test, y_predict, average='weighted')\n",
    "    k_scores.append(score)\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Optimized, K = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbor: Optimized K=9\n",
      "Confusion Matrix :\n",
      "[[2974 1284]\n",
      " [ 356  728]]\n",
      "Test Accuracy Score : 0.6929988768251591\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.70      0.78      4258\n",
      "           1       0.36      0.67      0.47      1084\n",
      "\n",
      "    accuracy                           0.69      5342\n",
      "   macro avg       0.63      0.69      0.63      5342\n",
      "weighted avg       0.79      0.69      0.72      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1  Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "   Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3      0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0      0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1      0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "2      0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "5      0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4      0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate KNeighborsClassifier\n",
    "knn2 = KNeighborsClassifier(n_neighbors=9)\n",
    "# Fit the classifier\n",
    "knn2.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(knn2, interactions.get_X_test(), interactions.y_test, evaluation, 'K-Nearest Neighbor', 'Optimized K=9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"4\"></span>4. Decision Tree\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree-1: Baseline\n",
      "Confusion Matrix :\n",
      "[[2813 1445]\n",
      " [ 294  790]]\n",
      "Test Accuracy Score : 0.6744664919505803\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.66      0.76      4258\n",
      "           1       0.35      0.73      0.48      1084\n",
      "\n",
      "    accuracy                           0.67      5342\n",
      "   macro avg       0.63      0.69      0.62      5342\n",
      "weighted avg       0.79      0.67      0.71      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1  Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "6        Decision Tree-1                                 Baseline     0.674   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "   Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3      0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0      0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1      0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "2      0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "6      0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5      0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4      0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a DecisionTreeClassifier\n",
    "dt1 = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "# fit the model\n",
    "dt1.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(dt1, interactions.get_X_test(), interactions.y_test, evaluation, 'Decision Tree-1', 'Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['doctor_recc_h1n1', 0.16969860861804767],\n",
       "       ['opinion_h1n1_vacc_effective_5.0', 0.061120026142828895],\n",
       "       ['missing_health_insurance', 0.05092901460582436],\n",
       "       ['opinion_h1n1_risk_4.0', 0.026921519916768128],\n",
       "       ['household_adults', 0.019049898883747595],\n",
       "       ['opinion_h1n1_risk_5.0', 0.01725275300400127],\n",
       "       ['health_worker', 0.016757923653604092],\n",
       "       ['household_children', 0.015736398852394917]], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature importance\n",
    "importance = pd.DataFrame(dt1.feature_importances_, index=interactions.get_X_train().columns).reset_index().sort_values(by = 0, ascending=False)\n",
    "importance.head(8).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_feature_importances(model, df, figsize=(14, 12), palette=None, font_scale=1, ascending=False, rows=12, style=\"darkgrid\"):\n",
    "    sns.set_style(style)\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    sns.set(font_scale=font_scale)\n",
    "    importance = pd.DataFrame(model.feature_importances_, index=df.columns).reset_index()\n",
    "    importance.columns = pd.Index([\"Feature\", \"Importance\"])\n",
    "    sns.barplot(y=\"Feature\", x=\"Importance\", data=importance.sort_values(\"Importance\",ascending=ascending).iloc[0:rows],\n",
    "                palette=palette, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance Graph\n",
    "pal = sns.color_palette((\"#102CA8\",))\n",
    "show_feature_importances(dt1, interactions.get_X_train(), figsize=(14, 12), palette=pal, font_scale=1, ascending=False, rows=12, style=\"darkgrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Ideal Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6920479302832245, 0.7235294117647058, 0.7441176470588234, 0.7555555555555556, 0.7586056644880175, 0.7630718954248366, 0.7604575163398692, 0.7556644880174292, 0.7544662309368193]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = cross_val_score(dt1, interactions.get_X_train(), interactions.y_train, cv = 5)\n",
    "score.mean()\n",
    "depth_range = range(1,10)\n",
    "val = []\n",
    "for depth in depth_range:\n",
    "    ctree = DecisionTreeClassifier(max_depth = depth)\n",
    "    depth_score = cross_val_score(ctree, interactions.get_X_train(), interactions.y_train, cv = 5)\n",
    "    val.append(depth_score.mean())\n",
    "print(val)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(depth_range, val)\n",
    "plt.xlabel('range of depth')\n",
    "plt.ylabel('cross validated values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Decision Tree: Depth 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree-2: Optimized: Depth 6\n",
      "Confusion Matrix :\n",
      "[[3327  931]\n",
      " [ 274  810]]\n",
      "Test Accuracy Score : 0.7744290527892175\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.85      4258\n",
      "           1       0.47      0.75      0.57      1084\n",
      "\n",
      "    accuracy                           0.77      5342\n",
      "   macro avg       0.69      0.76      0.71      5342\n",
      "weighted avg       0.83      0.77      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1  Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "7        Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "6        Decision Tree-1                                 Baseline     0.674   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "   Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3      0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0      0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1      0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "2      0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "7      0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "6      0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5      0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4      0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a DecisionTreeClassifier\n",
    "dt2 = DecisionTreeClassifier(criterion='gini', max_depth=6)\n",
    "\n",
    "# fit the model\n",
    "dt2.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(dt2, interactions.get_X_test(), interactions.y_test, evaluation, 'Decision Tree-2', 'Optimized: Depth 6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree: Depth 6 with Reduced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree-3: Depth 6, Select Features\n",
      "Confusion Matrix :\n",
      "[[3195 1063]\n",
      " [ 233  851]]\n",
      "Test Accuracy Score : 0.7573942343691501\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83      4258\n",
      "           1       0.44      0.79      0.57      1084\n",
      "\n",
      "    accuracy                           0.76      5342\n",
      "   macro avg       0.69      0.77      0.70      5342\n",
      "weighted avg       0.83      0.76      0.78      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1  Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "7        Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8        Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6        Decision Tree-1                                 Baseline     0.674   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "   Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3      0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0      0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1      0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "2      0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "7      0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "8      0.445  1063.0   0.785  233.0     0.768  0.568  \n",
       "6      0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5      0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4      0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dt3 = DecisionTreeClassifier(criterion='gini', max_depth=6)\n",
    "\n",
    "# fit the model\n",
    "dt3.fit(reduced.get_X_train(), reduced.y_train)\n",
    "\n",
    "evaluate_to_df(dt3, reduced.get_X_test(), reduced.y_test, evaluation, 'Decision Tree-3', 'Depth 6, Select Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"5\"></span>5. Random Forest\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest-1: 100 Est, Max Depth 5\n",
      "Confusion Matrix :\n",
      "[[3330  928]\n",
      " [ 273  811]]\n",
      "Test Accuracy Score : 0.7751778360164733\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.85      4258\n",
      "           1       0.47      0.75      0.57      1084\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.70      0.77      0.71      5342\n",
      "weighted avg       0.83      0.78      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model                                  Details  Accuracy  \\\n",
       "3  Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0  Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1  Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "2  Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9        Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7        Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8        Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6        Decision Tree-1                                 Baseline     0.674   \n",
       "5     K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4     K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "   Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3      0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0      0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1      0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "2      0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "9      0.466   928.0   0.748  273.0     0.765  0.575  \n",
       "7      0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "8      0.445  1063.0   0.785  233.0     0.768  0.568  \n",
       "6      0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5      0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4      0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest1 = RandomForestClassifier(n_estimators=100, max_depth= 5)\n",
    "forest1.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(forest1, interactions.get_X_test(), interactions.y_test, evaluation, 'Random Forest-1', '100 Est, Max Depth 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Optimization: GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(max_depth=5),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 2, 6, 10],\n",
       "                         'min_samples_leaf': [2, 3, 5, 7],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [10, 30, 100]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 30, 100],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 2, 6, 10],\n",
    "    'min_samples_split': [ 2, 5, 10],\n",
    "    'min_samples_leaf': [2, 3, 5, 7]\n",
    "}\n",
    "\n",
    "#Instantiate the gridsearch object\n",
    "rf_grid_search = GridSearchCV(forest1, param_grid, cv=3)\n",
    "\n",
    "# Fit to the data\n",
    "rf_grid_search.fit(interactions.get_X_train(), interactions.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest-2: Optimized Hyperparameters\n",
      "Confusion Matrix :\n",
      "[[3247 1011]\n",
      " [ 233  851]]\n",
      "Test Accuracy Score : 0.7671284163234744\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84      4258\n",
      "           1       0.46      0.79      0.58      1084\n",
      "\n",
      "    accuracy                           0.77      5342\n",
      "   macro avg       0.70      0.77      0.71      5342\n",
      "weighted avg       0.84      0.77      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.767   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7         Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8         Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6         Decision Tree-1                                 Baseline     0.674   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "    Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3       0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0       0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1       0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "10      0.457  1011.0   0.785  233.0     0.774  0.578  \n",
       "2       0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "9       0.466   928.0   0.748  273.0     0.765  0.575  \n",
       "7       0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "8       0.445  1063.0   0.785  233.0     0.768  0.568  \n",
       "6       0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5       0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4       0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2 = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
    "                                              class_weight=None,\n",
    "                                              criterion='gini', max_depth=None,\n",
    "                                              max_features='auto',\n",
    "                                              max_leaf_nodes=None,\n",
    "                                              max_samples=None,\n",
    "                                              min_impurity_decrease=0.0,\n",
    "                                              min_impurity_split=None,\n",
    "                                              min_samples_leaf=2,\n",
    "                                              min_samples_split=2,\n",
    "                                              min_weight_fraction_leaf=0.0,\n",
    "                                              n_estimators=100,\n",
    "                                              oob_score=False,\n",
    "                                              random_state=None, verbose=0,\n",
    "                                              warm_start=False)\n",
    "forest2.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(forest2, interactions.get_X_test(), interactions.y_test, evaluation, 'Random Forest-2', 'Optimized Hyperparameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"6\"></span>6. AdaBoost\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost-1: Baseline\n",
      "Confusion Matrix :\n",
      "[[3413  845]\n",
      " [ 267  817]]\n",
      "Test Accuracy Score : 0.7918382628229128\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      4258\n",
      "           1       0.49      0.75      0.60      1084\n",
      "\n",
      "    accuracy                           0.79      5342\n",
      "   macro avg       0.71      0.78      0.73      5342\n",
      "weighted avg       0.84      0.79      0.81      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.492</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "11             AdaBoost-1                                 Baseline     0.792   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.767   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7         Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8         Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6         Decision Tree-1                                 Baseline     0.674   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "    Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3       0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0       0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1       0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "11      0.492   845.0   0.754  267.0     0.778  0.595  \n",
       "10      0.457  1011.0   0.785  233.0     0.774  0.578  \n",
       "2       0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "9       0.466   928.0   0.748  273.0     0.765  0.575  \n",
       "7       0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "8       0.445  1063.0   0.785  233.0     0.768  0.568  \n",
       "6       0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5       0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4       0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_clf = AdaBoostClassifier(random_state=42)\n",
    "ada1 = adaboost_clf.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(ada1, interactions.get_X_test(), interactions.y_test, evaluation, 'AdaBoost-1', 'Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Optimization: GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "base_estimator: DecisionTreeClassifier(max_depth=1)\n",
      "learning_rate: 0.2\n",
      "n_estimators: 250\n",
      "\n",
      "Training Accuracy: 78.16%\n",
      "Validation accuracy: 79.5%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.1, 0.2],\n",
    "    'base_estimator': [DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=5)],\n",
    "    'n_estimators': [5, 30, 100, 250],\n",
    "}\n",
    "\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "grid_ada = GridSearchCV(ada_clf, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_ada.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "best_parameters = grid_ada.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_ada.predict(interactions.get_X_train())\n",
    "val_preds = grid_ada.predict(interactions.get_X_test())\n",
    "training_accuracy = accuracy_score(interactions.y_train, training_preds)\n",
    "val_accuracy = accuracy_score(interactions.y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost-2: Optimized\n",
      "Confusion Matrix :\n",
      "[[3429  829]\n",
      " [ 266  818]]\n",
      "Test Accuracy Score : 0.7950205915387495\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86      4258\n",
      "           1       0.50      0.75      0.60      1084\n",
      "\n",
      "    accuracy                           0.80      5342\n",
      "   macro avg       0.71      0.78      0.73      5342\n",
      "weighted avg       0.84      0.80      0.81      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.492</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "12             AdaBoost-2                                Optimized     0.795   \n",
       "11             AdaBoost-1                                 Baseline     0.792   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.767   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7         Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8         Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6         Decision Tree-1                                 Baseline     0.674   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "    Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3       0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0       0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1       0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "12      0.497   829.0   0.755  266.0     0.780  0.599  \n",
       "11      0.492   845.0   0.754  267.0     0.778  0.595  \n",
       "10      0.457  1011.0   0.785  233.0     0.774  0.578  \n",
       "2       0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "9       0.466   928.0   0.748  273.0     0.765  0.575  \n",
       "7       0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "8       0.445  1063.0   0.785  233.0     0.768  0.568  \n",
       "6       0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5       0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4       0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaboost_clf = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best'), learning_rate=0.2, n_estimators=250, random_state=42)\n",
    "ada2 = adaboost_clf.fit(interactions.get_X_train(), interactions.y_train)\n",
    "\n",
    "evaluate_to_df(ada2, interactions.get_X_test(), interactions.y_test, evaluation, 'AdaBoost-2', 'Optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"7\"></span>7. XGBoost\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = interactions.get_X_train().rename(columns=lambda x: x.replace('<', '_'))\n",
    "X_test_scaled = interactions.get_X_test().rename(columns=lambda x: x.replace('<', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoosting-1: Baseline\n",
      "Confusion Matrix :\n",
      "[[3314  944]\n",
      " [ 257  827]]\n",
      "Test Accuracy Score : 0.7751778360164733\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      4258\n",
      "           1       0.47      0.76      0.58      1084\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.70      0.77      0.71      5342\n",
      "weighted avg       0.83      0.78      0.79      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.492</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.467</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "12             AdaBoost-2                                Optimized     0.795   \n",
       "11             AdaBoost-1                                 Baseline     0.792   \n",
       "13           XGBoosting-1                                 Baseline     0.775   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.767   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7         Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8         Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6         Decision Tree-1                                 Baseline     0.674   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "    Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3       0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0       0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1       0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "12      0.497   829.0   0.755  266.0     0.780  0.599  \n",
       "11      0.492   845.0   0.754  267.0     0.778  0.595  \n",
       "13      0.467   944.0   0.763  257.0     0.771  0.579  \n",
       "10      0.457  1011.0   0.785  233.0     0.774  0.578  \n",
       "2       0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "9       0.466   928.0   0.748  273.0     0.765  0.575  \n",
       "7       0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "8       0.445  1063.0   0.785  233.0     0.768  0.568  \n",
       "6       0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5       0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4       0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = xgb.XGBClassifier()\n",
    "clf1.fit(X_train_scaled, interactions.y_train)\n",
    "\n",
    "evaluate_to_df(clf1, X_test_scaled, interactions.y_test, evaluation, 'XGBoosting-1', 'Baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Optimization: GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search found the following optimal parameters: \n",
      "colsample_bytree: 0.4\n",
      "learning_rate: 0.1\n",
      "max_depth: 7\n",
      "min_child_weight: 1\n",
      "n_estimators: 300\n",
      "\n",
      "Training Accuracy: 95.96%\n",
      "Validation accuracy: 78.06%\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators':[100,300,500],\n",
    "              'learning_rate':[0.1,0.5,0.01],\n",
    "              'max_depth':[3,5,7],\n",
    "              'colsample_bytree':[0.5,0.4,0.3],\n",
    "              'min_child_weight':[1,2,3]\n",
    "             }\n",
    "\n",
    "clf_xg = xgb.XGBClassifier()\n",
    "grid_clf = GridSearchCV(clf_xg, param_grid, scoring='accuracy', cv=None, n_jobs=1)\n",
    "grid_clf.fit(X_train_scaled, interactions.y_train)\n",
    "\n",
    "best_parameters = grid_clf.best_params_\n",
    "\n",
    "print(\"Grid Search found the following optimal parameters: \")\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "training_preds = grid_clf.predict(X_train_scaled)\n",
    "val_preds = grid_clf.predict(X_test_scaled)\n",
    "training_accuracy = accuracy_score(interactions.y_train, training_preds)\n",
    "val_accuracy = accuracy_score(interactions.y_test, val_preds)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training Accuracy: {:.4}%\".format(training_accuracy * 100))\n",
    "print(\"Validation accuracy: {:.4}%\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoosting-2: Optimized\n",
      "Confusion Matrix :\n",
      "[[3325  933]\n",
      " [ 244  840]]\n",
      "Test Accuracy Score : 0.7796705353800075\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      4258\n",
      "           1       0.47      0.77      0.59      1084\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.70      0.78      0.72      5342\n",
      "weighted avg       0.84      0.78      0.80      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.492</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoosting-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.474</td>\n",
       "      <td>933.0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.467</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "12             AdaBoost-2                                Optimized     0.795   \n",
       "11             AdaBoost-1                                 Baseline     0.792   \n",
       "14           XGBoosting-2                                Optimized     0.780   \n",
       "13           XGBoosting-1                                 Baseline     0.775   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.767   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7         Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8         Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6         Decision Tree-1                                 Baseline     0.674   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "\n",
       "    Precision      FP  Recall     FN  F1-Score    AUC  \n",
       "3       0.498   826.0   0.756  264.0     0.781  0.601  \n",
       "0       0.497   829.0   0.756  265.0     0.780  0.600  \n",
       "1       0.496   831.0   0.755  266.0     0.780  0.599  \n",
       "12      0.497   829.0   0.755  266.0     0.780  0.599  \n",
       "11      0.492   845.0   0.754  267.0     0.778  0.595  \n",
       "14      0.474   933.0   0.775  244.0     0.778  0.588  \n",
       "13      0.467   944.0   0.763  257.0     0.771  0.579  \n",
       "10      0.457  1011.0   0.785  233.0     0.774  0.578  \n",
       "2       0.471   901.0   0.741  281.0     0.765  0.576  \n",
       "9       0.466   928.0   0.748  273.0     0.765  0.575  \n",
       "7       0.465   931.0   0.747  274.0     0.764  0.573  \n",
       "8       0.445  1063.0   0.785  233.0     0.768  0.568  \n",
       "6       0.353  1445.0   0.729  294.0     0.695  0.476  \n",
       "5       0.362  1284.0   0.672  356.0     0.685  0.470  \n",
       "4       0.341  1383.0   0.660  369.0     0.667  0.449  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = xgb.XGBClassifier(max_depth=7, learning_rate=0.1, n_estimators=300, min_child_weight=2, colsample_bytree=0.4)\n",
    "clf2.fit(X_train_scaled, interactions.y_train)\n",
    "\n",
    "evaluate_to_df(clf2, X_test_scaled, interactions.y_test, evaluation, 'XGBoosting-2', 'Optimized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"8\"></span>8. Support Vector Machine\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: Poly, c=.01\n",
      "Confusion Matrix :\n",
      "[[4243   15]\n",
      " [1063   21]]\n",
      "Test Accuracy Score : 0.7982029202545863\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      4258\n",
      "           1       0.58      0.02      0.04      1084\n",
      "\n",
      "    accuracy                           0.80      5342\n",
      "   macro avg       0.69      0.51      0.46      5342\n",
      "weighted avg       0.76      0.80      0.71      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.492</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoosting-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.474</td>\n",
       "      <td>933.0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.467</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Poly, c=.01</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.583</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "12             AdaBoost-2                                Optimized     0.795   \n",
       "11             AdaBoost-1                                 Baseline     0.792   \n",
       "14           XGBoosting-2                                Optimized     0.780   \n",
       "13           XGBoosting-1                                 Baseline     0.775   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.767   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7         Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8         Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6         Decision Tree-1                                 Baseline     0.674   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "15                    SVM                              Poly, c=.01     0.798   \n",
       "\n",
       "    Precision      FP  Recall      FN  F1-Score    AUC  \n",
       "3       0.498   826.0   0.756   264.0     0.781  0.601  \n",
       "0       0.497   829.0   0.756   265.0     0.780  0.600  \n",
       "1       0.496   831.0   0.755   266.0     0.780  0.599  \n",
       "12      0.497   829.0   0.755   266.0     0.780  0.599  \n",
       "11      0.492   845.0   0.754   267.0     0.778  0.595  \n",
       "14      0.474   933.0   0.775   244.0     0.778  0.588  \n",
       "13      0.467   944.0   0.763   257.0     0.771  0.579  \n",
       "10      0.457  1011.0   0.785   233.0     0.774  0.578  \n",
       "2       0.471   901.0   0.741   281.0     0.765  0.576  \n",
       "9       0.466   928.0   0.748   273.0     0.765  0.575  \n",
       "7       0.465   931.0   0.747   274.0     0.764  0.573  \n",
       "8       0.445  1063.0   0.785   233.0     0.768  0.568  \n",
       "6       0.353  1445.0   0.729   294.0     0.695  0.476  \n",
       "5       0.362  1284.0   0.672   356.0     0.685  0.470  \n",
       "4       0.341  1383.0   0.660   369.0     0.667  0.449  \n",
       "15      0.583    15.0   0.019  1063.0     0.508  0.037  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc1 = SVC(kernel='poly', C=.01)  \n",
    "svc1.fit(interactions.get_X_train(), interactions.y_train) \n",
    "\n",
    "evaluate_to_df(svc1, interactions.get_X_test(), interactions.y_test, evaluation, 'SVM', 'Poly, c=.01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span id=\"9\"></span>9. Best Model\n",
    "#### [Return Contents](#0)\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on Accuracy and Area Under the Curve (AUC), our best model appears to be Logistic Regression with an accuracy of .796, a harmonic F1-Score of .781 and an Area Under the Curve of .601.\n",
    "\n",
    "However, it is important to note that this model is very tolerant in terms of the number of false positives with a precision rate of .498 and a total of 826 false positives on the test set.  The model prioritizes false negatives with a recall of .756 and a total of 264 false negatives on the test set.\n",
    "\n",
    "**Fasle Positives** = predicted that people did vaccinate when they didn't.\n",
    "\n",
    "**False Negatives** = predicted that people did not vaccinate when they actually did.\n",
    "\n",
    "This model may not be the best depending on the organizations goals.  For example, if this model is used to achieve a goal like maximizing the number of vaccinations in the population, then you may want a model that minimizes the false positives, meaning that there would be a low tolerance for predicting that someone did vaccinate when they actually did not (false positive) and higher tolerance for predicting that someone did not vaccinate when they actually did (false negative).\n",
    "\n",
    "If this is the case, then the Support Vector Machine actully achieved a higher accuracy even though it performed the worst on the AUC metric. Compared to the Logisitic Regression model, SVM only allowed 15 false positives but with a greater tadeoff of false negatives for a total of 1,063 on the test set.  The low C value of 0.01 means the SVM model is less tolerant of the violation, which in turn gives us a more complex model with a higher variance and a lower bias.\n",
    "\n",
    "On the other hand, if the organizations goals is to minimize resource allocation for a direct mail marketing campaign designed to increase awareness for vaccinations, then the organization may prefer to use the Logisitic Regression model which won't predict everyone who did not vaccinate, but at least the campaign would reach the people who matter most, like the elderly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>FP</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FN</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression-4</td>\n",
       "      <td>All Features, Scaled, with Interactions</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.498</td>\n",
       "      <td>826.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression-1</td>\n",
       "      <td>All Features, Not Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.756</td>\n",
       "      <td>265.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression-2</td>\n",
       "      <td>All Features, Scaled</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.496</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AdaBoost-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.497</td>\n",
       "      <td>829.0</td>\n",
       "      <td>0.755</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AdaBoost-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.492</td>\n",
       "      <td>845.0</td>\n",
       "      <td>0.754</td>\n",
       "      <td>267.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoosting-2</td>\n",
       "      <td>Optimized</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.474</td>\n",
       "      <td>933.0</td>\n",
       "      <td>0.775</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>XGBoosting-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.467</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0.763</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest-2</td>\n",
       "      <td>Optimized Hyperparameters</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.457</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression-3</td>\n",
       "      <td>Select Features, Scaled</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.471</td>\n",
       "      <td>901.0</td>\n",
       "      <td>0.741</td>\n",
       "      <td>281.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest-1</td>\n",
       "      <td>100 Est, Max Depth 5</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.466</td>\n",
       "      <td>928.0</td>\n",
       "      <td>0.748</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree-2</td>\n",
       "      <td>Optimized: Depth 6</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.465</td>\n",
       "      <td>931.0</td>\n",
       "      <td>0.747</td>\n",
       "      <td>274.0</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree-3</td>\n",
       "      <td>Depth 6, Select Features</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.445</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.785</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree-1</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.353</td>\n",
       "      <td>1445.0</td>\n",
       "      <td>0.729</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Optimized K=9</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.362</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>0.672</td>\n",
       "      <td>356.0</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbor</td>\n",
       "      <td>Baseline K=1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.341</td>\n",
       "      <td>1383.0</td>\n",
       "      <td>0.660</td>\n",
       "      <td>369.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Poly, c=.01</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.583</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                  Details  Accuracy  \\\n",
       "3   Logistic Regression-4  All Features, Scaled, with Interactions     0.796   \n",
       "0   Logistic Regression-1                 All Features, Not Scaled     0.795   \n",
       "1   Logistic Regression-2                     All Features, Scaled     0.795   \n",
       "12             AdaBoost-2                                Optimized     0.795   \n",
       "11             AdaBoost-1                                 Baseline     0.792   \n",
       "14           XGBoosting-2                                Optimized     0.780   \n",
       "13           XGBoosting-1                                 Baseline     0.775   \n",
       "10        Random Forest-2                Optimized Hyperparameters     0.767   \n",
       "2   Logistic Regression-3                  Select Features, Scaled     0.779   \n",
       "9         Random Forest-1                     100 Est, Max Depth 5     0.775   \n",
       "7         Decision Tree-2                       Optimized: Depth 6     0.774   \n",
       "8         Decision Tree-3                 Depth 6, Select Features     0.757   \n",
       "6         Decision Tree-1                                 Baseline     0.674   \n",
       "5      K-Nearest Neighbor                            Optimized K=9     0.693   \n",
       "4      K-Nearest Neighbor                             Baseline K=1     0.672   \n",
       "15                    SVM                              Poly, c=.01     0.798   \n",
       "\n",
       "    Precision      FP  Recall      FN  F1-Score    AUC  \n",
       "3       0.498   826.0   0.756   264.0     0.781  0.601  \n",
       "0       0.497   829.0   0.756   265.0     0.780  0.600  \n",
       "1       0.496   831.0   0.755   266.0     0.780  0.599  \n",
       "12      0.497   829.0   0.755   266.0     0.780  0.599  \n",
       "11      0.492   845.0   0.754   267.0     0.778  0.595  \n",
       "14      0.474   933.0   0.775   244.0     0.778  0.588  \n",
       "13      0.467   944.0   0.763   257.0     0.771  0.579  \n",
       "10      0.457  1011.0   0.785   233.0     0.774  0.578  \n",
       "2       0.471   901.0   0.741   281.0     0.765  0.576  \n",
       "9       0.466   928.0   0.748   273.0     0.765  0.575  \n",
       "7       0.465   931.0   0.747   274.0     0.764  0.573  \n",
       "8       0.445  1063.0   0.785   233.0     0.768  0.568  \n",
       "6       0.353  1445.0   0.729   294.0     0.695  0.476  \n",
       "5       0.362  1284.0   0.672   356.0     0.685  0.470  \n",
       "4       0.341  1383.0   0.660   369.0     0.667  0.449  \n",
       "15      0.583    15.0   0.019  1063.0     0.508  0.037  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.sort_values(by = 'AUC', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_graph(model, X_test, y_test, font_scale=2, style=\"darkgrid\", palette=None, figsize=(14, 12)):\n",
    "    sns.set_style(style)\n",
    "    sns.set(font_scale=font_scale)\n",
    "    f, ax = plt.subplots(figsize=figsize)\n",
    "    converted_pal = matplotlib.colors.ListedColormap(sns.color_palette(palette))\n",
    "    plot_confusion_matrix(model, X_test, y_test, cmap=converted_pal, ax=ax)\n",
    "    for text in ax.texts:\n",
    "        label = text.get_text()\n",
    "        label = int(float(label))\n",
    "        text.set_text(f\"{label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression 2: All Features, Scaled\n",
      "Confusion Matrix :\n",
      "[[3432  826]\n",
      " [ 264  820]]\n",
      "Test Accuracy Score : 0.7959565705728192\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86      4258\n",
      "           1       0.50      0.76      0.60      1084\n",
      "\n",
      "    accuracy                           0.80      5342\n",
      "   macro avg       0.71      0.78      0.73      5342\n",
      "weighted avg       0.84      0.80      0.81      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Logistic Regression: Select Features, Scaled, with Interactions\n",
    "log_pred1 = logreg4.predict(interactions.get_X_test())\n",
    "\n",
    "cm = metrics.confusion_matrix(interactions.y_test, log_pred1)\n",
    "print('Logisitic Regression 2: All Features, Scaled')\n",
    "print('Confusion Matrix :')\n",
    "print(cm) \n",
    "print('Test Accuracy Score :',metrics.accuracy_score(interactions.y_test, log_pred1))\n",
    "print('Report : ')\n",
    "print(classification_report(interactions.y_test, log_pred1))\n",
    "\n",
    "palette = sns.light_palette(\"#EE823E\")\n",
    "confusion_matrix_graph(logreg4, interactions.get_X_test(), interactions.y_test, font_scale=1, palette=palette, figsize=(14,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(interactions.y_test, log_pred1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for vaccination classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[4243   15]\n",
      " [1063   21]]\n",
      "Accuracy Score : 0.7982029202545863\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      4258\n",
      "           1       0.58      0.02      0.04      1084\n",
      "\n",
      "    accuracy                           0.80      5342\n",
      "   macro avg       0.69      0.51      0.46      5342\n",
      "weighted avg       0.76      0.80      0.71      5342\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svc_pred1 = svc1.predict(interactions.get_X_test())\n",
    "\n",
    "cm = metrics.confusion_matrix(interactions.y_test, svc_pred1)\n",
    "print('Confusion Matrix :')\n",
    "print(cm) \n",
    "print('Accuracy Score :',metrics.accuracy_score(interactions.y_test, svc_pred1))\n",
    "print('Report : ')\n",
    "print(classification_report(interactions.y_test, svc_pred1))\n",
    "\n",
    "palette = sns.light_palette(\"#EE823E\")\n",
    "confusion_matrix_graph(svc1, interactions.get_X_test(), interactions.y_test, font_scale=1, palette=palette, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(interactions.y_test, svc_pred1)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for vaccination classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
